2022-11-08 11:25:57,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:25:57,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:25:57,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:25:57,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:26:01,647:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-08 11:26:02,124:INFO:PyCaret RegressionExperiment
2022-11-08 11:26:02,124:INFO:Logging name: reg-default-name
2022-11-08 11:26:02,124:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-08 11:26:02,124:INFO:version 3.0.0.rc4
2022-11-08 11:26:02,124:INFO:Initializing setup()
2022-11-08 11:26:02,124:INFO:self.USI: c859
2022-11-08 11:26:02,124:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'transform_target_method_param', 'master_model_container', 'y_test', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:26:02,124:INFO:Checking environment
2022-11-08 11:26:02,124:INFO:python_version: 3.10.4
2022-11-08 11:26:02,125:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:26:02,125:INFO:machine: AMD64
2022-11-08 11:26:02,125:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:26:02,126:INFO:Memory: svmem(total=8503136256, available=1656168448, percent=80.5, used=6846967808, free=1656168448)
2022-11-08 11:26:02,126:INFO:Physical Core: 2
2022-11-08 11:26:02,126:INFO:Logical Core: 4
2022-11-08 11:26:02,126:INFO:Checking libraries
2022-11-08 11:26:02,126:INFO:System:
2022-11-08 11:26:02,126:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:26:02,127:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:26:02,127:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:26:02,127:INFO:PyCaret required dependencies:
2022-11-08 11:26:02,127:INFO:                 pip: 22.2.2
2022-11-08 11:26:02,127:INFO:          setuptools: 58.1.0
2022-11-08 11:26:02,127:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:26:02,127:INFO:             IPython: 8.4.0
2022-11-08 11:26:02,127:INFO:          ipywidgets: 8.0.2
2022-11-08 11:26:02,127:INFO:                tqdm: 4.64.0
2022-11-08 11:26:02,127:INFO:               numpy: 1.22.3
2022-11-08 11:26:02,127:INFO:              pandas: 1.4.2
2022-11-08 11:26:02,127:INFO:              jinja2: 3.1.2
2022-11-08 11:26:02,127:INFO:               scipy: 1.8.1
2022-11-08 11:26:02,127:INFO:              joblib: 1.2.0
2022-11-08 11:26:02,127:INFO:             sklearn: 1.1.2
2022-11-08 11:26:02,127:INFO:                pyod: 1.0.6
2022-11-08 11:26:02,127:INFO:            imblearn: 0.9.1
2022-11-08 11:26:02,127:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:26:02,129:INFO:            lightgbm: 3.3.3
2022-11-08 11:26:02,129:INFO:               numba: 0.55.2
2022-11-08 11:26:02,129:INFO:            requests: 2.28.1
2022-11-08 11:26:02,129:INFO:          matplotlib: 3.5.1
2022-11-08 11:26:02,129:INFO:          scikitplot: 0.3.7
2022-11-08 11:26:02,129:INFO:         yellowbrick: 1.5
2022-11-08 11:26:02,129:INFO:              plotly: 5.11.0
2022-11-08 11:26:02,129:INFO:             kaleido: 0.2.1
2022-11-08 11:26:02,129:INFO:         statsmodels: 0.13.5
2022-11-08 11:26:02,129:INFO:              sktime: 0.13.4
2022-11-08 11:26:02,129:INFO:               tbats: 1.1.1
2022-11-08 11:26:02,129:INFO:            pmdarima: 1.8.5
2022-11-08 11:26:02,130:INFO:              psutil: 5.9.1
2022-11-08 11:26:02,130:INFO:PyCaret optional dependencies:
2022-11-08 11:26:02,157:INFO:                shap: Not installed
2022-11-08 11:26:02,157:INFO:           interpret: Not installed
2022-11-08 11:26:02,157:INFO:                umap: Not installed
2022-11-08 11:26:02,158:INFO:    pandas_profiling: Not installed
2022-11-08 11:26:02,158:INFO:  explainerdashboard: Not installed
2022-11-08 11:26:02,158:INFO:             autoviz: Not installed
2022-11-08 11:26:02,158:INFO:           fairlearn: Not installed
2022-11-08 11:26:02,158:INFO:             xgboost: Not installed
2022-11-08 11:26:02,158:INFO:            catboost: Not installed
2022-11-08 11:26:02,158:INFO:              kmodes: Not installed
2022-11-08 11:26:02,158:INFO:             mlxtend: Not installed
2022-11-08 11:26:02,158:INFO:       statsforecast: Not installed
2022-11-08 11:26:02,158:INFO:        tune_sklearn: Not installed
2022-11-08 11:26:02,158:INFO:                 ray: Not installed
2022-11-08 11:26:02,158:INFO:            hyperopt: Not installed
2022-11-08 11:26:02,158:INFO:              optuna: Not installed
2022-11-08 11:26:02,158:INFO:               skopt: Not installed
2022-11-08 11:26:02,158:INFO:              mlflow: Not installed
2022-11-08 11:26:02,158:INFO:              gradio: Not installed
2022-11-08 11:26:02,158:INFO:             fastapi: Not installed
2022-11-08 11:26:02,158:INFO:             uvicorn: Not installed
2022-11-08 11:26:02,158:INFO:              m2cgen: Not installed
2022-11-08 11:26:02,158:INFO:           evidently: Not installed
2022-11-08 11:26:02,158:INFO:                nltk: 3.7
2022-11-08 11:26:02,158:INFO:            pyLDAvis: Not installed
2022-11-08 11:26:02,158:INFO:              gensim: Not installed
2022-11-08 11:26:02,158:INFO:               spacy: Not installed
2022-11-08 11:26:02,158:INFO:           wordcloud: Not installed
2022-11-08 11:26:02,158:INFO:            textblob: Not installed
2022-11-08 11:26:02,158:INFO:               fugue: Not installed
2022-11-08 11:26:02,158:INFO:           streamlit: Not installed
2022-11-08 11:26:02,158:INFO:             prophet: Not installed
2022-11-08 11:26:02,158:INFO:None
2022-11-08 11:26:02,158:INFO:Set up data.
2022-11-08 11:26:02,186:INFO:Set up train/test split.
2022-11-08 11:26:02,217:INFO:Set up index.
2022-11-08 11:26:02,218:INFO:Set up folding strategy.
2022-11-08 11:26:02,218:INFO:Assigning column types.
2022-11-08 11:26:02,218:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:26:02,224:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,239:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,447:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,459:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,588:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-08 11:26:02,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,738:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,745:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,877:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-08 11:26:02,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,168:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-08 11:26:03,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,461:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:26:03,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,746:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-08 11:26:03,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,034:INFO:Preparing preprocessing pipeline...
2022-11-08 11:26:04,035:INFO:Set up simple imputation.
2022-11-08 11:26:04,035:INFO:Set up variance threshold.
2022-11-08 11:26:04,095:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:26:04,099:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-08 11:26:04,099:INFO:Creating final display dataframe.
2022-11-08 11:26:04,357:INFO:Setup display_container:                Description             Value
0               Session id              4545
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              c859
2022-11-08 11:26:04,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,716:INFO:setup() successfully completed in 2.6s...............
2022-11-08 11:26:35,568:INFO:PyCaret RegressionExperiment
2022-11-08 11:26:35,568:INFO:Logging name: reg-default-name
2022-11-08 11:26:35,568:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-08 11:26:35,568:INFO:version 3.0.0.rc4
2022-11-08 11:26:35,568:INFO:Initializing setup()
2022-11-08 11:26:35,568:INFO:self.USI: a163
2022-11-08 11:26:35,568:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'transform_target_method_param', 'master_model_container', 'y_test', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:26:35,568:INFO:Checking environment
2022-11-08 11:26:35,568:INFO:python_version: 3.10.4
2022-11-08 11:26:35,568:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:26:35,568:INFO:machine: AMD64
2022-11-08 11:26:35,568:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:26:35,576:INFO:Memory: svmem(total=8503136256, available=1827471360, percent=78.5, used=6675664896, free=1827471360)
2022-11-08 11:26:35,576:INFO:Physical Core: 2
2022-11-08 11:26:35,576:INFO:Logical Core: 4
2022-11-08 11:26:35,576:INFO:Checking libraries
2022-11-08 11:26:35,576:INFO:System:
2022-11-08 11:26:35,576:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:26:35,576:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:26:35,576:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:26:35,576:INFO:PyCaret required dependencies:
2022-11-08 11:26:35,576:INFO:                 pip: 22.2.2
2022-11-08 11:26:35,576:INFO:          setuptools: 58.1.0
2022-11-08 11:26:35,576:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:26:35,576:INFO:             IPython: 8.4.0
2022-11-08 11:26:35,576:INFO:          ipywidgets: 8.0.2
2022-11-08 11:26:35,576:INFO:                tqdm: 4.64.0
2022-11-08 11:26:35,576:INFO:               numpy: 1.22.3
2022-11-08 11:26:35,576:INFO:              pandas: 1.4.2
2022-11-08 11:26:35,576:INFO:              jinja2: 3.1.2
2022-11-08 11:26:35,576:INFO:               scipy: 1.8.1
2022-11-08 11:26:35,576:INFO:              joblib: 1.2.0
2022-11-08 11:26:35,581:INFO:             sklearn: 1.1.2
2022-11-08 11:26:35,581:INFO:                pyod: 1.0.6
2022-11-08 11:26:35,581:INFO:            imblearn: 0.9.1
2022-11-08 11:26:35,581:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:26:35,581:INFO:            lightgbm: 3.3.3
2022-11-08 11:26:35,581:INFO:               numba: 0.55.2
2022-11-08 11:26:35,581:INFO:            requests: 2.28.1
2022-11-08 11:26:35,581:INFO:          matplotlib: 3.5.1
2022-11-08 11:26:35,581:INFO:          scikitplot: 0.3.7
2022-11-08 11:26:35,581:INFO:         yellowbrick: 1.5
2022-11-08 11:26:35,581:INFO:              plotly: 5.11.0
2022-11-08 11:26:35,581:INFO:             kaleido: 0.2.1
2022-11-08 11:26:35,581:INFO:         statsmodels: 0.13.5
2022-11-08 11:26:35,581:INFO:              sktime: 0.13.4
2022-11-08 11:26:35,581:INFO:               tbats: 1.1.1
2022-11-08 11:26:35,581:INFO:            pmdarima: 1.8.5
2022-11-08 11:26:35,581:INFO:              psutil: 5.9.1
2022-11-08 11:26:35,581:INFO:PyCaret optional dependencies:
2022-11-08 11:26:35,581:INFO:                shap: Not installed
2022-11-08 11:26:35,581:INFO:           interpret: Not installed
2022-11-08 11:26:35,581:INFO:                umap: Not installed
2022-11-08 11:26:35,581:INFO:    pandas_profiling: Not installed
2022-11-08 11:26:35,581:INFO:  explainerdashboard: Not installed
2022-11-08 11:26:35,581:INFO:             autoviz: Not installed
2022-11-08 11:26:35,581:INFO:           fairlearn: Not installed
2022-11-08 11:26:35,581:INFO:             xgboost: Not installed
2022-11-08 11:26:35,581:INFO:            catboost: Not installed
2022-11-08 11:26:35,581:INFO:              kmodes: Not installed
2022-11-08 11:26:35,581:INFO:             mlxtend: Not installed
2022-11-08 11:26:35,581:INFO:       statsforecast: Not installed
2022-11-08 11:26:35,581:INFO:        tune_sklearn: Not installed
2022-11-08 11:26:35,581:INFO:                 ray: Not installed
2022-11-08 11:26:35,581:INFO:            hyperopt: Not installed
2022-11-08 11:26:35,581:INFO:              optuna: Not installed
2022-11-08 11:26:35,586:INFO:               skopt: Not installed
2022-11-08 11:26:35,586:INFO:              mlflow: Not installed
2022-11-08 11:26:35,586:INFO:              gradio: Not installed
2022-11-08 11:26:35,586:INFO:             fastapi: Not installed
2022-11-08 11:26:35,586:INFO:             uvicorn: Not installed
2022-11-08 11:26:35,586:INFO:              m2cgen: Not installed
2022-11-08 11:26:35,586:INFO:           evidently: Not installed
2022-11-08 11:26:35,586:INFO:                nltk: 3.7
2022-11-08 11:26:35,586:INFO:            pyLDAvis: Not installed
2022-11-08 11:26:35,586:INFO:              gensim: Not installed
2022-11-08 11:26:35,586:INFO:               spacy: Not installed
2022-11-08 11:26:35,586:INFO:           wordcloud: Not installed
2022-11-08 11:26:35,586:INFO:            textblob: Not installed
2022-11-08 11:26:35,586:INFO:               fugue: Not installed
2022-11-08 11:26:35,586:INFO:           streamlit: Not installed
2022-11-08 11:26:35,586:INFO:             prophet: Not installed
2022-11-08 11:26:35,586:INFO:None
2022-11-08 11:26:35,586:INFO:Set up data.
2022-11-08 11:26:35,601:INFO:Set up train/test split.
2022-11-08 11:26:35,610:INFO:Set up index.
2022-11-08 11:26:35,610:INFO:Set up folding strategy.
2022-11-08 11:26:35,612:INFO:Assigning column types.
2022-11-08 11:26:35,619:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:26:35,619:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,636:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,645:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:35,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:35,833:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,843:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,856:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,144:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-08 11:26:36,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,498:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-08 11:26:36,518:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,806:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-08 11:26:36,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,097:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:26:37,179:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,388:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-08 11:26:37,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,683:INFO:Preparing preprocessing pipeline...
2022-11-08 11:26:37,684:INFO:Set up simple imputation.
2022-11-08 11:26:37,684:INFO:Set up variance threshold.
2022-11-08 11:26:37,737:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:26:37,746:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-08 11:26:37,746:INFO:Creating final display dataframe.
2022-11-08 11:26:38,013:INFO:Setup display_container:                Description             Value
0               Session id              7997
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              a163
2022-11-08 11:26:38,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,368:INFO:setup() successfully completed in 2.8s...............
2022-11-08 11:26:56,151:INFO:Initializing compare_models()
2022-11-08 11:26:56,151:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-08 11:26:56,151:INFO:Checking exceptions
2022-11-08 11:26:56,151:INFO:Preparing display monitor
2022-11-08 11:26:56,243:INFO:Initializing Linear Regression
2022-11-08 11:26:56,243:INFO:Total runtime is 0.0 minutes
2022-11-08 11:26:56,249:INFO:SubProcess create_model() called ==================================
2022-11-08 11:26:56,249:INFO:Initializing create_model()
2022-11-08 11:26:56,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:26:56,250:INFO:Checking exceptions
2022-11-08 11:26:56,253:INFO:Importing libraries
2022-11-08 11:26:56,253:INFO:Copying training dataset
2022-11-08 11:26:56,259:INFO:Defining folds
2022-11-08 11:26:56,259:INFO:Declaring metric variables
2022-11-08 11:26:56,270:INFO:Importing untrained model
2022-11-08 11:26:56,280:INFO:Linear Regression Imported successfully
2022-11-08 11:26:56,293:INFO:Starting cross validation
2022-11-08 11:26:56,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:04,746:INFO:Calculating mean and std
2022-11-08 11:27:04,748:INFO:Creating metrics dataframe
2022-11-08 11:27:04,753:INFO:Uploading results into container
2022-11-08 11:27:04,753:INFO:Uploading model into container now
2022-11-08 11:27:04,754:INFO:master_model_container: 1
2022-11-08 11:27:04,754:INFO:display_container: 2
2022-11-08 11:27:04,754:INFO:LinearRegression(n_jobs=-1)
2022-11-08 11:27:04,754:INFO:create_model() successfully completed......................................
2022-11-08 11:27:04,870:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:04,870:INFO:Creating metrics dataframe
2022-11-08 11:27:04,890:INFO:Initializing Lasso Regression
2022-11-08 11:27:04,891:INFO:Total runtime is 0.14414142370223998 minutes
2022-11-08 11:27:04,896:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:04,898:INFO:Initializing create_model()
2022-11-08 11:27:04,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:04,898:INFO:Checking exceptions
2022-11-08 11:27:04,902:INFO:Importing libraries
2022-11-08 11:27:04,902:INFO:Copying training dataset
2022-11-08 11:27:04,912:INFO:Defining folds
2022-11-08 11:27:04,912:INFO:Declaring metric variables
2022-11-08 11:27:04,920:INFO:Importing untrained model
2022-11-08 11:27:04,928:INFO:Lasso Regression Imported successfully
2022-11-08 11:27:04,946:INFO:Starting cross validation
2022-11-08 11:27:04,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:05,257:INFO:Calculating mean and std
2022-11-08 11:27:05,259:INFO:Creating metrics dataframe
2022-11-08 11:27:05,262:INFO:Uploading results into container
2022-11-08 11:27:05,263:INFO:Uploading model into container now
2022-11-08 11:27:05,263:INFO:master_model_container: 2
2022-11-08 11:27:05,263:INFO:display_container: 2
2022-11-08 11:27:05,264:INFO:Lasso(random_state=7997)
2022-11-08 11:27:05,264:INFO:create_model() successfully completed......................................
2022-11-08 11:27:05,378:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:05,378:INFO:Creating metrics dataframe
2022-11-08 11:27:05,391:INFO:Initializing Ridge Regression
2022-11-08 11:27:05,391:INFO:Total runtime is 0.1524614373842875 minutes
2022-11-08 11:27:05,396:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:05,396:INFO:Initializing create_model()
2022-11-08 11:27:05,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:05,397:INFO:Checking exceptions
2022-11-08 11:27:05,401:INFO:Importing libraries
2022-11-08 11:27:05,402:INFO:Copying training dataset
2022-11-08 11:27:05,406:INFO:Defining folds
2022-11-08 11:27:05,406:INFO:Declaring metric variables
2022-11-08 11:27:05,410:INFO:Importing untrained model
2022-11-08 11:27:05,419:INFO:Ridge Regression Imported successfully
2022-11-08 11:27:05,438:INFO:Starting cross validation
2022-11-08 11:27:05,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:05,639:INFO:Calculating mean and std
2022-11-08 11:27:05,641:INFO:Creating metrics dataframe
2022-11-08 11:27:05,645:INFO:Uploading results into container
2022-11-08 11:27:05,646:INFO:Uploading model into container now
2022-11-08 11:27:05,647:INFO:master_model_container: 3
2022-11-08 11:27:05,647:INFO:display_container: 2
2022-11-08 11:27:05,648:INFO:Ridge(random_state=7997)
2022-11-08 11:27:05,649:INFO:create_model() successfully completed......................................
2022-11-08 11:27:05,756:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:05,756:INFO:Creating metrics dataframe
2022-11-08 11:27:05,769:INFO:Initializing Elastic Net
2022-11-08 11:27:05,769:INFO:Total runtime is 0.15877500375111897 minutes
2022-11-08 11:27:05,774:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:05,775:INFO:Initializing create_model()
2022-11-08 11:27:05,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:05,775:INFO:Checking exceptions
2022-11-08 11:27:05,777:INFO:Importing libraries
2022-11-08 11:27:05,778:INFO:Copying training dataset
2022-11-08 11:27:05,783:INFO:Defining folds
2022-11-08 11:27:05,783:INFO:Declaring metric variables
2022-11-08 11:27:05,789:INFO:Importing untrained model
2022-11-08 11:27:05,797:INFO:Elastic Net Imported successfully
2022-11-08 11:27:05,812:INFO:Starting cross validation
2022-11-08 11:27:05,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:06,019:INFO:Calculating mean and std
2022-11-08 11:27:06,021:INFO:Creating metrics dataframe
2022-11-08 11:27:06,025:INFO:Uploading results into container
2022-11-08 11:27:06,026:INFO:Uploading model into container now
2022-11-08 11:27:06,026:INFO:master_model_container: 4
2022-11-08 11:27:06,026:INFO:display_container: 2
2022-11-08 11:27:06,027:INFO:ElasticNet(random_state=7997)
2022-11-08 11:27:06,027:INFO:create_model() successfully completed......................................
2022-11-08 11:27:06,133:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:06,134:INFO:Creating metrics dataframe
2022-11-08 11:27:06,147:INFO:Initializing Least Angle Regression
2022-11-08 11:27:06,147:INFO:Total runtime is 0.16507114966710407 minutes
2022-11-08 11:27:06,153:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:06,154:INFO:Initializing create_model()
2022-11-08 11:27:06,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:06,154:INFO:Checking exceptions
2022-11-08 11:27:06,157:INFO:Importing libraries
2022-11-08 11:27:06,157:INFO:Copying training dataset
2022-11-08 11:27:06,161:INFO:Defining folds
2022-11-08 11:27:06,162:INFO:Declaring metric variables
2022-11-08 11:27:06,173:INFO:Importing untrained model
2022-11-08 11:27:06,180:INFO:Least Angle Regression Imported successfully
2022-11-08 11:27:06,197:INFO:Starting cross validation
2022-11-08 11:27:06,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:06,266:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,271:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,285:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,296:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,328:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,336:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,351:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,358:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,389:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,389:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,411:INFO:Calculating mean and std
2022-11-08 11:27:06,412:INFO:Creating metrics dataframe
2022-11-08 11:27:06,417:INFO:Uploading results into container
2022-11-08 11:27:06,418:INFO:Uploading model into container now
2022-11-08 11:27:06,418:INFO:master_model_container: 5
2022-11-08 11:27:06,418:INFO:display_container: 2
2022-11-08 11:27:06,419:INFO:Lars(random_state=7997)
2022-11-08 11:27:06,419:INFO:create_model() successfully completed......................................
2022-11-08 11:27:06,524:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:06,525:INFO:Creating metrics dataframe
2022-11-08 11:27:06,540:INFO:Initializing Lasso Least Angle Regression
2022-11-08 11:27:06,541:INFO:Total runtime is 0.1716353933016459 minutes
2022-11-08 11:27:06,546:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:06,547:INFO:Initializing create_model()
2022-11-08 11:27:06,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:06,547:INFO:Checking exceptions
2022-11-08 11:27:06,551:INFO:Importing libraries
2022-11-08 11:27:06,551:INFO:Copying training dataset
2022-11-08 11:27:06,556:INFO:Defining folds
2022-11-08 11:27:06,556:INFO:Declaring metric variables
2022-11-08 11:27:06,561:INFO:Importing untrained model
2022-11-08 11:27:06,568:INFO:Lasso Least Angle Regression Imported successfully
2022-11-08 11:27:06,586:INFO:Starting cross validation
2022-11-08 11:27:06,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:06,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,661:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,672:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,686:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,716:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,726:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,738:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,746:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,755:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,769:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,787:INFO:Calculating mean and std
2022-11-08 11:27:06,788:INFO:Creating metrics dataframe
2022-11-08 11:27:06,792:INFO:Uploading results into container
2022-11-08 11:27:06,792:INFO:Uploading model into container now
2022-11-08 11:27:06,793:INFO:master_model_container: 6
2022-11-08 11:27:06,793:INFO:display_container: 2
2022-11-08 11:27:06,794:INFO:LassoLars(random_state=7997)
2022-11-08 11:27:06,794:INFO:create_model() successfully completed......................................
2022-11-08 11:27:06,901:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:06,901:INFO:Creating metrics dataframe
2022-11-08 11:27:06,917:INFO:Initializing Orthogonal Matching Pursuit
2022-11-08 11:27:06,917:INFO:Total runtime is 0.17789403200149534 minutes
2022-11-08 11:27:06,923:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:06,923:INFO:Initializing create_model()
2022-11-08 11:27:06,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:06,923:INFO:Checking exceptions
2022-11-08 11:27:06,925:INFO:Importing libraries
2022-11-08 11:27:06,925:INFO:Copying training dataset
2022-11-08 11:27:06,933:INFO:Defining folds
2022-11-08 11:27:06,933:INFO:Declaring metric variables
2022-11-08 11:27:06,939:INFO:Importing untrained model
2022-11-08 11:27:06,950:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-08 11:27:06,967:INFO:Starting cross validation
2022-11-08 11:27:06,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:07,026:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,042:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,056:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,086:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,101:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,116:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,126:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,151:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,158:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,168:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,184:INFO:Calculating mean and std
2022-11-08 11:27:07,186:INFO:Creating metrics dataframe
2022-11-08 11:27:07,190:INFO:Uploading results into container
2022-11-08 11:27:07,191:INFO:Uploading model into container now
2022-11-08 11:27:07,191:INFO:master_model_container: 7
2022-11-08 11:27:07,191:INFO:display_container: 2
2022-11-08 11:27:07,192:INFO:OrthogonalMatchingPursuit()
2022-11-08 11:27:07,192:INFO:create_model() successfully completed......................................
2022-11-08 11:27:07,297:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:07,297:INFO:Creating metrics dataframe
2022-11-08 11:27:07,311:INFO:Initializing Bayesian Ridge
2022-11-08 11:27:07,312:INFO:Total runtime is 0.18449139992396035 minutes
2022-11-08 11:27:07,318:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:07,319:INFO:Initializing create_model()
2022-11-08 11:27:07,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:07,320:INFO:Checking exceptions
2022-11-08 11:27:07,323:INFO:Importing libraries
2022-11-08 11:27:07,323:INFO:Copying training dataset
2022-11-08 11:27:07,328:INFO:Defining folds
2022-11-08 11:27:07,328:INFO:Declaring metric variables
2022-11-08 11:27:07,334:INFO:Importing untrained model
2022-11-08 11:27:07,344:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:27:07,361:INFO:Starting cross validation
2022-11-08 11:27:07,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:07,581:INFO:Calculating mean and std
2022-11-08 11:27:07,583:INFO:Creating metrics dataframe
2022-11-08 11:27:07,586:INFO:Uploading results into container
2022-11-08 11:27:07,587:INFO:Uploading model into container now
2022-11-08 11:27:07,588:INFO:master_model_container: 8
2022-11-08 11:27:07,588:INFO:display_container: 2
2022-11-08 11:27:07,589:INFO:BayesianRidge()
2022-11-08 11:27:07,589:INFO:create_model() successfully completed......................................
2022-11-08 11:27:07,687:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:07,695:INFO:Creating metrics dataframe
2022-11-08 11:27:07,710:INFO:Initializing Passive Aggressive Regressor
2022-11-08 11:27:07,710:INFO:Total runtime is 0.1911191940307617 minutes
2022-11-08 11:27:07,717:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:07,717:INFO:Initializing create_model()
2022-11-08 11:27:07,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:07,718:INFO:Checking exceptions
2022-11-08 11:27:07,721:INFO:Importing libraries
2022-11-08 11:27:07,721:INFO:Copying training dataset
2022-11-08 11:27:07,727:INFO:Defining folds
2022-11-08 11:27:07,727:INFO:Declaring metric variables
2022-11-08 11:27:07,733:INFO:Importing untrained model
2022-11-08 11:27:07,742:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:27:07,759:INFO:Starting cross validation
2022-11-08 11:27:07,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:07,959:INFO:Calculating mean and std
2022-11-08 11:27:07,961:INFO:Creating metrics dataframe
2022-11-08 11:27:07,965:INFO:Uploading results into container
2022-11-08 11:27:07,966:INFO:Uploading model into container now
2022-11-08 11:27:07,967:INFO:master_model_container: 9
2022-11-08 11:27:07,967:INFO:display_container: 2
2022-11-08 11:27:07,968:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:27:07,968:INFO:create_model() successfully completed......................................
2022-11-08 11:27:08,075:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:08,075:INFO:Creating metrics dataframe
2022-11-08 11:27:08,090:INFO:Initializing Huber Regressor
2022-11-08 11:27:08,090:INFO:Total runtime is 0.19745233853658037 minutes
2022-11-08 11:27:08,095:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:08,096:INFO:Initializing create_model()
2022-11-08 11:27:08,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:08,096:INFO:Checking exceptions
2022-11-08 11:27:08,100:INFO:Importing libraries
2022-11-08 11:27:08,100:INFO:Copying training dataset
2022-11-08 11:27:08,105:INFO:Defining folds
2022-11-08 11:27:08,106:INFO:Declaring metric variables
2022-11-08 11:27:08,111:INFO:Importing untrained model
2022-11-08 11:27:08,119:INFO:Huber Regressor Imported successfully
2022-11-08 11:27:08,135:INFO:Starting cross validation
2022-11-08 11:27:08,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:08,275:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,286:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,291:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,386:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,386:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,397:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,411:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,470:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,470:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,491:INFO:Calculating mean and std
2022-11-08 11:27:08,492:INFO:Creating metrics dataframe
2022-11-08 11:27:08,498:INFO:Uploading results into container
2022-11-08 11:27:08,499:INFO:Uploading model into container now
2022-11-08 11:27:08,499:INFO:master_model_container: 10
2022-11-08 11:27:08,499:INFO:display_container: 2
2022-11-08 11:27:08,500:INFO:HuberRegressor()
2022-11-08 11:27:08,500:INFO:create_model() successfully completed......................................
2022-11-08 11:27:08,602:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:08,602:INFO:Creating metrics dataframe
2022-11-08 11:27:08,620:INFO:Initializing K Neighbors Regressor
2022-11-08 11:27:08,621:INFO:Total runtime is 0.20630602041880286 minutes
2022-11-08 11:27:08,625:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:08,625:INFO:Initializing create_model()
2022-11-08 11:27:08,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:08,626:INFO:Checking exceptions
2022-11-08 11:27:08,631:INFO:Importing libraries
2022-11-08 11:27:08,632:INFO:Copying training dataset
2022-11-08 11:27:08,636:INFO:Defining folds
2022-11-08 11:27:08,636:INFO:Declaring metric variables
2022-11-08 11:27:08,643:INFO:Importing untrained model
2022-11-08 11:27:08,649:INFO:K Neighbors Regressor Imported successfully
2022-11-08 11:27:08,671:INFO:Starting cross validation
2022-11-08 11:27:08,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:08,924:INFO:Calculating mean and std
2022-11-08 11:27:08,926:INFO:Creating metrics dataframe
2022-11-08 11:27:08,933:INFO:Uploading results into container
2022-11-08 11:27:08,934:INFO:Uploading model into container now
2022-11-08 11:27:08,934:INFO:master_model_container: 11
2022-11-08 11:27:08,934:INFO:display_container: 2
2022-11-08 11:27:08,935:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-08 11:27:08,935:INFO:create_model() successfully completed......................................
2022-11-08 11:27:09,053:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:09,053:INFO:Creating metrics dataframe
2022-11-08 11:27:09,073:INFO:Initializing Decision Tree Regressor
2022-11-08 11:27:09,073:INFO:Total runtime is 0.213830022017161 minutes
2022-11-08 11:27:09,078:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:09,078:INFO:Initializing create_model()
2022-11-08 11:27:09,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:09,079:INFO:Checking exceptions
2022-11-08 11:27:09,083:INFO:Importing libraries
2022-11-08 11:27:09,083:INFO:Copying training dataset
2022-11-08 11:27:09,088:INFO:Defining folds
2022-11-08 11:27:09,088:INFO:Declaring metric variables
2022-11-08 11:27:09,092:INFO:Importing untrained model
2022-11-08 11:27:09,102:INFO:Decision Tree Regressor Imported successfully
2022-11-08 11:27:09,116:INFO:Starting cross validation
2022-11-08 11:27:09,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:09,334:INFO:Calculating mean and std
2022-11-08 11:27:09,337:INFO:Creating metrics dataframe
2022-11-08 11:27:09,341:INFO:Uploading results into container
2022-11-08 11:27:09,342:INFO:Uploading model into container now
2022-11-08 11:27:09,342:INFO:master_model_container: 12
2022-11-08 11:27:09,343:INFO:display_container: 2
2022-11-08 11:27:09,343:INFO:DecisionTreeRegressor(random_state=7997)
2022-11-08 11:27:09,343:INFO:create_model() successfully completed......................................
2022-11-08 11:27:09,451:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:09,451:INFO:Creating metrics dataframe
2022-11-08 11:27:09,468:INFO:Initializing Random Forest Regressor
2022-11-08 11:27:09,469:INFO:Total runtime is 0.22043606042861932 minutes
2022-11-08 11:27:09,474:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:09,474:INFO:Initializing create_model()
2022-11-08 11:27:09,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:09,474:INFO:Checking exceptions
2022-11-08 11:27:09,477:INFO:Importing libraries
2022-11-08 11:27:09,477:INFO:Copying training dataset
2022-11-08 11:27:09,485:INFO:Defining folds
2022-11-08 11:27:09,485:INFO:Declaring metric variables
2022-11-08 11:27:09,494:INFO:Importing untrained model
2022-11-08 11:27:09,502:INFO:Random Forest Regressor Imported successfully
2022-11-08 11:27:09,521:INFO:Starting cross validation
2022-11-08 11:27:09,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:10,958:INFO:Calculating mean and std
2022-11-08 11:27:10,960:INFO:Creating metrics dataframe
2022-11-08 11:27:10,966:INFO:Uploading results into container
2022-11-08 11:27:10,967:INFO:Uploading model into container now
2022-11-08 11:27:10,967:INFO:master_model_container: 13
2022-11-08 11:27:10,967:INFO:display_container: 2
2022-11-08 11:27:10,968:INFO:RandomForestRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:27:10,969:INFO:create_model() successfully completed......................................
2022-11-08 11:27:11,088:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:11,088:INFO:Creating metrics dataframe
2022-11-08 11:27:11,110:INFO:Initializing Extra Trees Regressor
2022-11-08 11:27:11,110:INFO:Total runtime is 0.24777800639470413 minutes
2022-11-08 11:27:11,120:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:11,121:INFO:Initializing create_model()
2022-11-08 11:27:11,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:11,122:INFO:Checking exceptions
2022-11-08 11:27:11,125:INFO:Importing libraries
2022-11-08 11:27:11,125:INFO:Copying training dataset
2022-11-08 11:27:11,133:INFO:Defining folds
2022-11-08 11:27:11,134:INFO:Declaring metric variables
2022-11-08 11:27:11,141:INFO:Importing untrained model
2022-11-08 11:27:11,155:INFO:Extra Trees Regressor Imported successfully
2022-11-08 11:27:11,171:INFO:Starting cross validation
2022-11-08 11:27:11,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:12,166:INFO:Calculating mean and std
2022-11-08 11:27:12,167:INFO:Creating metrics dataframe
2022-11-08 11:27:12,171:INFO:Uploading results into container
2022-11-08 11:27:12,171:INFO:Uploading model into container now
2022-11-08 11:27:12,172:INFO:master_model_container: 14
2022-11-08 11:27:12,172:INFO:display_container: 2
2022-11-08 11:27:12,172:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:27:12,172:INFO:create_model() successfully completed......................................
2022-11-08 11:27:12,291:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:12,291:INFO:Creating metrics dataframe
2022-11-08 11:27:12,312:INFO:Initializing AdaBoost Regressor
2022-11-08 11:27:12,312:INFO:Total runtime is 0.26781946023305253 minutes
2022-11-08 11:27:12,317:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:12,317:INFO:Initializing create_model()
2022-11-08 11:27:12,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:12,318:INFO:Checking exceptions
2022-11-08 11:27:12,321:INFO:Importing libraries
2022-11-08 11:27:12,322:INFO:Copying training dataset
2022-11-08 11:27:12,330:INFO:Defining folds
2022-11-08 11:27:12,330:INFO:Declaring metric variables
2022-11-08 11:27:12,337:INFO:Importing untrained model
2022-11-08 11:27:12,344:INFO:AdaBoost Regressor Imported successfully
2022-11-08 11:27:12,359:INFO:Starting cross validation
2022-11-08 11:27:12,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:12,895:INFO:Calculating mean and std
2022-11-08 11:27:12,896:INFO:Creating metrics dataframe
2022-11-08 11:27:12,900:INFO:Uploading results into container
2022-11-08 11:27:12,900:INFO:Uploading model into container now
2022-11-08 11:27:12,901:INFO:master_model_container: 15
2022-11-08 11:27:12,901:INFO:display_container: 2
2022-11-08 11:27:12,901:INFO:AdaBoostRegressor(random_state=7997)
2022-11-08 11:27:12,901:INFO:create_model() successfully completed......................................
2022-11-08 11:27:13,006:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:13,006:INFO:Creating metrics dataframe
2022-11-08 11:27:13,045:INFO:Initializing Gradient Boosting Regressor
2022-11-08 11:27:13,045:INFO:Total runtime is 0.2800426681836446 minutes
2022-11-08 11:27:13,051:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:13,056:INFO:Initializing create_model()
2022-11-08 11:27:13,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:13,056:INFO:Checking exceptions
2022-11-08 11:27:13,056:INFO:Importing libraries
2022-11-08 11:27:13,061:INFO:Copying training dataset
2022-11-08 11:27:13,069:INFO:Defining folds
2022-11-08 11:27:13,069:INFO:Declaring metric variables
2022-11-08 11:27:13,076:INFO:Importing untrained model
2022-11-08 11:27:13,101:INFO:Gradient Boosting Regressor Imported successfully
2022-11-08 11:27:13,111:INFO:Starting cross validation
2022-11-08 11:27:13,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:13,847:INFO:Calculating mean and std
2022-11-08 11:27:13,848:INFO:Creating metrics dataframe
2022-11-08 11:27:13,859:INFO:Uploading results into container
2022-11-08 11:27:13,862:INFO:Uploading model into container now
2022-11-08 11:27:13,862:INFO:master_model_container: 16
2022-11-08 11:27:13,863:INFO:display_container: 2
2022-11-08 11:27:13,864:INFO:GradientBoostingRegressor(random_state=7997)
2022-11-08 11:27:13,864:INFO:create_model() successfully completed......................................
2022-11-08 11:27:14,011:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:14,011:INFO:Creating metrics dataframe
2022-11-08 11:27:14,060:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:27:14,060:INFO:Total runtime is 0.2969590703646342 minutes
2022-11-08 11:27:14,077:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:14,077:INFO:Initializing create_model()
2022-11-08 11:27:14,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:14,077:INFO:Checking exceptions
2022-11-08 11:27:14,088:INFO:Importing libraries
2022-11-08 11:27:14,088:INFO:Copying training dataset
2022-11-08 11:27:14,111:INFO:Defining folds
2022-11-08 11:27:14,111:INFO:Declaring metric variables
2022-11-08 11:27:14,128:INFO:Importing untrained model
2022-11-08 11:27:14,146:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:27:14,177:INFO:Starting cross validation
2022-11-08 11:27:14,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:14,698:INFO:Calculating mean and std
2022-11-08 11:27:14,708:INFO:Creating metrics dataframe
2022-11-08 11:27:14,718:INFO:Uploading results into container
2022-11-08 11:27:14,718:INFO:Uploading model into container now
2022-11-08 11:27:14,718:INFO:master_model_container: 17
2022-11-08 11:27:14,718:INFO:display_container: 2
2022-11-08 11:27:14,718:INFO:LGBMRegressor(random_state=7997)
2022-11-08 11:27:14,718:INFO:create_model() successfully completed......................................
2022-11-08 11:27:14,875:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:14,875:INFO:Creating metrics dataframe
2022-11-08 11:27:14,899:INFO:Initializing Dummy Regressor
2022-11-08 11:27:14,899:INFO:Total runtime is 0.31092872222264606 minutes
2022-11-08 11:27:14,917:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:14,917:INFO:Initializing create_model()
2022-11-08 11:27:14,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:14,918:INFO:Checking exceptions
2022-11-08 11:27:14,927:INFO:Importing libraries
2022-11-08 11:27:14,927:INFO:Copying training dataset
2022-11-08 11:27:14,938:INFO:Defining folds
2022-11-08 11:27:14,938:INFO:Declaring metric variables
2022-11-08 11:27:14,948:INFO:Importing untrained model
2022-11-08 11:27:14,964:INFO:Dummy Regressor Imported successfully
2022-11-08 11:27:14,988:INFO:Starting cross validation
2022-11-08 11:27:14,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:15,328:INFO:Calculating mean and std
2022-11-08 11:27:15,330:INFO:Creating metrics dataframe
2022-11-08 11:27:15,344:INFO:Uploading results into container
2022-11-08 11:27:15,347:INFO:Uploading model into container now
2022-11-08 11:27:15,348:INFO:master_model_container: 18
2022-11-08 11:27:15,348:INFO:display_container: 2
2022-11-08 11:27:15,348:INFO:DummyRegressor()
2022-11-08 11:27:15,348:INFO:create_model() successfully completed......................................
2022-11-08 11:27:15,510:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:15,511:INFO:Creating metrics dataframe
2022-11-08 11:27:15,576:INFO:Initializing create_model()
2022-11-08 11:27:15,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:15,578:INFO:Checking exceptions
2022-11-08 11:27:15,578:INFO:Importing libraries
2022-11-08 11:27:15,578:INFO:Copying training dataset
2022-11-08 11:27:15,591:INFO:Defining folds
2022-11-08 11:27:15,591:INFO:Declaring metric variables
2022-11-08 11:27:15,591:INFO:Importing untrained model
2022-11-08 11:27:15,591:INFO:Declaring custom model
2022-11-08 11:27:15,591:INFO:Huber Regressor Imported successfully
2022-11-08 11:27:15,597:INFO:Cross validation set to False
2022-11-08 11:27:15,597:INFO:Fitting Model
2022-11-08 11:27:15,748:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:15,748:INFO:HuberRegressor()
2022-11-08 11:27:15,748:INFO:create_model() successfully completed......................................
2022-11-08 11:27:15,916:INFO:Initializing create_model()
2022-11-08 11:27:15,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=PassiveAggressiveRegressor(random_state=7997), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:15,916:INFO:Checking exceptions
2022-11-08 11:27:15,926:INFO:Importing libraries
2022-11-08 11:27:15,926:INFO:Copying training dataset
2022-11-08 11:27:15,928:INFO:Defining folds
2022-11-08 11:27:15,928:INFO:Declaring metric variables
2022-11-08 11:27:15,928:INFO:Importing untrained model
2022-11-08 11:27:15,928:INFO:Declaring custom model
2022-11-08 11:27:15,928:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:27:15,928:INFO:Cross validation set to False
2022-11-08 11:27:15,928:INFO:Fitting Model
2022-11-08 11:27:15,976:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:27:15,976:INFO:create_model() successfully completed......................................
2022-11-08 11:27:16,156:INFO:Initializing create_model()
2022-11-08 11:27:16,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:16,159:INFO:Checking exceptions
2022-11-08 11:27:16,168:INFO:Importing libraries
2022-11-08 11:27:16,168:INFO:Copying training dataset
2022-11-08 11:27:16,175:INFO:Defining folds
2022-11-08 11:27:16,176:INFO:Declaring metric variables
2022-11-08 11:27:16,177:INFO:Importing untrained model
2022-11-08 11:27:16,178:INFO:Declaring custom model
2022-11-08 11:27:16,180:INFO:Dummy Regressor Imported successfully
2022-11-08 11:27:16,182:INFO:Cross validation set to False
2022-11-08 11:27:16,182:INFO:Fitting Model
2022-11-08 11:27:16,209:INFO:DummyRegressor()
2022-11-08 11:27:16,210:INFO:create_model() successfully completed......................................
2022-11-08 11:27:16,448:INFO:master_model_container: 18
2022-11-08 11:27:16,456:INFO:display_container: 2
2022-11-08 11:27:16,458:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=7997), DummyRegressor()]
2022-11-08 11:27:16,458:INFO:compare_models() successfully completed......................................
2022-11-08 11:28:46,645:INFO:Initializing compare_models()
2022-11-08 11:28:46,645:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-08 11:28:46,645:INFO:Checking exceptions
2022-11-08 11:28:46,650:INFO:Preparing display monitor
2022-11-08 11:28:46,726:INFO:Initializing Linear Regression
2022-11-08 11:28:46,726:INFO:Total runtime is 0.0 minutes
2022-11-08 11:28:46,736:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:46,736:INFO:Initializing create_model()
2022-11-08 11:28:46,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:46,740:INFO:Checking exceptions
2022-11-08 11:28:46,742:INFO:Importing libraries
2022-11-08 11:28:46,742:INFO:Copying training dataset
2022-11-08 11:28:46,745:INFO:Defining folds
2022-11-08 11:28:46,745:INFO:Declaring metric variables
2022-11-08 11:28:46,756:INFO:Importing untrained model
2022-11-08 11:28:46,766:INFO:Linear Regression Imported successfully
2022-11-08 11:28:46,777:INFO:Starting cross validation
2022-11-08 11:28:46,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:47,027:INFO:Calculating mean and std
2022-11-08 11:28:47,027:INFO:Creating metrics dataframe
2022-11-08 11:28:47,028:INFO:Uploading results into container
2022-11-08 11:28:47,028:INFO:Uploading model into container now
2022-11-08 11:28:47,028:INFO:master_model_container: 19
2022-11-08 11:28:47,028:INFO:display_container: 3
2022-11-08 11:28:47,028:INFO:LinearRegression(n_jobs=-1)
2022-11-08 11:28:47,028:INFO:create_model() successfully completed......................................
2022-11-08 11:28:47,191:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:47,191:INFO:Creating metrics dataframe
2022-11-08 11:28:47,206:INFO:Initializing Lasso Regression
2022-11-08 11:28:47,206:INFO:Total runtime is 0.008009803295135499 minutes
2022-11-08 11:28:47,211:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:47,212:INFO:Initializing create_model()
2022-11-08 11:28:47,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:47,213:INFO:Checking exceptions
2022-11-08 11:28:47,215:INFO:Importing libraries
2022-11-08 11:28:47,215:INFO:Copying training dataset
2022-11-08 11:28:47,222:INFO:Defining folds
2022-11-08 11:28:47,222:INFO:Declaring metric variables
2022-11-08 11:28:47,229:INFO:Importing untrained model
2022-11-08 11:28:47,244:INFO:Lasso Regression Imported successfully
2022-11-08 11:28:47,261:INFO:Starting cross validation
2022-11-08 11:28:47,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:47,527:INFO:Calculating mean and std
2022-11-08 11:28:47,527:INFO:Creating metrics dataframe
2022-11-08 11:28:47,531:INFO:Uploading results into container
2022-11-08 11:28:47,535:INFO:Uploading model into container now
2022-11-08 11:28:47,535:INFO:master_model_container: 20
2022-11-08 11:28:47,535:INFO:display_container: 3
2022-11-08 11:28:47,537:INFO:Lasso(random_state=7997)
2022-11-08 11:28:47,537:INFO:create_model() successfully completed......................................
2022-11-08 11:28:47,688:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:47,688:INFO:Creating metrics dataframe
2022-11-08 11:28:47,709:INFO:Initializing Ridge Regression
2022-11-08 11:28:47,709:INFO:Total runtime is 0.01638394594192505 minutes
2022-11-08 11:28:47,713:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:47,713:INFO:Initializing create_model()
2022-11-08 11:28:47,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:47,713:INFO:Checking exceptions
2022-11-08 11:28:47,719:INFO:Importing libraries
2022-11-08 11:28:47,720:INFO:Copying training dataset
2022-11-08 11:28:47,729:INFO:Defining folds
2022-11-08 11:28:47,730:INFO:Declaring metric variables
2022-11-08 11:28:47,740:INFO:Importing untrained model
2022-11-08 11:28:47,749:INFO:Ridge Regression Imported successfully
2022-11-08 11:28:47,768:INFO:Starting cross validation
2022-11-08 11:28:47,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:47,976:INFO:Calculating mean and std
2022-11-08 11:28:47,978:INFO:Creating metrics dataframe
2022-11-08 11:28:47,983:INFO:Uploading results into container
2022-11-08 11:28:47,984:INFO:Uploading model into container now
2022-11-08 11:28:47,985:INFO:master_model_container: 21
2022-11-08 11:28:47,985:INFO:display_container: 3
2022-11-08 11:28:47,985:INFO:Ridge(random_state=7997)
2022-11-08 11:28:47,986:INFO:create_model() successfully completed......................................
2022-11-08 11:28:48,108:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:48,108:INFO:Creating metrics dataframe
2022-11-08 11:28:48,125:INFO:Initializing Elastic Net
2022-11-08 11:28:48,126:INFO:Total runtime is 0.023335512479146323 minutes
2022-11-08 11:28:48,131:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:48,132:INFO:Initializing create_model()
2022-11-08 11:28:48,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:48,132:INFO:Checking exceptions
2022-11-08 11:28:48,137:INFO:Importing libraries
2022-11-08 11:28:48,137:INFO:Copying training dataset
2022-11-08 11:28:48,142:INFO:Defining folds
2022-11-08 11:28:48,142:INFO:Declaring metric variables
2022-11-08 11:28:48,150:INFO:Importing untrained model
2022-11-08 11:28:48,170:INFO:Elastic Net Imported successfully
2022-11-08 11:28:48,192:INFO:Starting cross validation
2022-11-08 11:28:48,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:48,430:INFO:Calculating mean and std
2022-11-08 11:28:48,434:INFO:Creating metrics dataframe
2022-11-08 11:28:48,438:INFO:Uploading results into container
2022-11-08 11:28:48,439:INFO:Uploading model into container now
2022-11-08 11:28:48,439:INFO:master_model_container: 22
2022-11-08 11:28:48,440:INFO:display_container: 3
2022-11-08 11:28:48,440:INFO:ElasticNet(random_state=7997)
2022-11-08 11:28:48,441:INFO:create_model() successfully completed......................................
2022-11-08 11:28:48,568:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:48,568:INFO:Creating metrics dataframe
2022-11-08 11:28:48,583:INFO:Initializing Least Angle Regression
2022-11-08 11:28:48,584:INFO:Total runtime is 0.03096684217453003 minutes
2022-11-08 11:28:48,588:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:48,589:INFO:Initializing create_model()
2022-11-08 11:28:48,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:48,590:INFO:Checking exceptions
2022-11-08 11:28:48,591:INFO:Importing libraries
2022-11-08 11:28:48,591:INFO:Copying training dataset
2022-11-08 11:28:48,596:INFO:Defining folds
2022-11-08 11:28:48,597:INFO:Declaring metric variables
2022-11-08 11:28:48,604:INFO:Importing untrained model
2022-11-08 11:28:48,613:INFO:Least Angle Regression Imported successfully
2022-11-08 11:28:48,630:INFO:Starting cross validation
2022-11-08 11:28:48,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:48,691:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,706:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,710:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,725:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,755:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,765:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,781:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,785:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,817:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,818:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,836:INFO:Calculating mean and std
2022-11-08 11:28:48,838:INFO:Creating metrics dataframe
2022-11-08 11:28:48,841:INFO:Uploading results into container
2022-11-08 11:28:48,842:INFO:Uploading model into container now
2022-11-08 11:28:48,842:INFO:master_model_container: 23
2022-11-08 11:28:48,843:INFO:display_container: 3
2022-11-08 11:28:48,843:INFO:Lars(random_state=7997)
2022-11-08 11:28:48,843:INFO:create_model() successfully completed......................................
2022-11-08 11:28:48,967:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:48,967:INFO:Creating metrics dataframe
2022-11-08 11:28:48,983:INFO:Initializing Lasso Least Angle Regression
2022-11-08 11:28:48,983:INFO:Total runtime is 0.037631022930145266 minutes
2022-11-08 11:28:48,989:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:48,990:INFO:Initializing create_model()
2022-11-08 11:28:48,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:48,990:INFO:Checking exceptions
2022-11-08 11:28:48,993:INFO:Importing libraries
2022-11-08 11:28:48,994:INFO:Copying training dataset
2022-11-08 11:28:49,001:INFO:Defining folds
2022-11-08 11:28:49,002:INFO:Declaring metric variables
2022-11-08 11:28:49,011:INFO:Importing untrained model
2022-11-08 11:28:49,020:INFO:Lasso Least Angle Regression Imported successfully
2022-11-08 11:28:49,036:INFO:Starting cross validation
2022-11-08 11:28:49,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:49,110:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,120:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,130:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,141:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,166:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,175:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,196:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,212:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,220:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,220:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,240:INFO:Calculating mean and std
2022-11-08 11:28:49,242:INFO:Creating metrics dataframe
2022-11-08 11:28:49,245:INFO:Uploading results into container
2022-11-08 11:28:49,246:INFO:Uploading model into container now
2022-11-08 11:28:49,246:INFO:master_model_container: 24
2022-11-08 11:28:49,246:INFO:display_container: 3
2022-11-08 11:28:49,247:INFO:LassoLars(random_state=7997)
2022-11-08 11:28:49,247:INFO:create_model() successfully completed......................................
2022-11-08 11:28:49,367:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:49,367:INFO:Creating metrics dataframe
2022-11-08 11:28:49,384:INFO:Initializing Orthogonal Matching Pursuit
2022-11-08 11:28:49,384:INFO:Total runtime is 0.044314014911651614 minutes
2022-11-08 11:28:49,389:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:49,390:INFO:Initializing create_model()
2022-11-08 11:28:49,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:49,390:INFO:Checking exceptions
2022-11-08 11:28:49,394:INFO:Importing libraries
2022-11-08 11:28:49,394:INFO:Copying training dataset
2022-11-08 11:28:49,400:INFO:Defining folds
2022-11-08 11:28:49,401:INFO:Declaring metric variables
2022-11-08 11:28:49,406:INFO:Importing untrained model
2022-11-08 11:28:49,413:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-08 11:28:49,428:INFO:Starting cross validation
2022-11-08 11:28:49,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:49,486:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,496:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,545:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,550:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,645:INFO:Calculating mean and std
2022-11-08 11:28:49,649:INFO:Creating metrics dataframe
2022-11-08 11:28:49,653:INFO:Uploading results into container
2022-11-08 11:28:49,653:INFO:Uploading model into container now
2022-11-08 11:28:49,654:INFO:master_model_container: 25
2022-11-08 11:28:49,654:INFO:display_container: 3
2022-11-08 11:28:49,654:INFO:OrthogonalMatchingPursuit()
2022-11-08 11:28:49,654:INFO:create_model() successfully completed......................................
2022-11-08 11:28:49,778:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:49,778:INFO:Creating metrics dataframe
2022-11-08 11:28:49,795:INFO:Initializing Bayesian Ridge
2022-11-08 11:28:49,796:INFO:Total runtime is 0.051180652777353924 minutes
2022-11-08 11:28:49,804:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:49,805:INFO:Initializing create_model()
2022-11-08 11:28:49,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:49,805:INFO:Checking exceptions
2022-11-08 11:28:49,806:INFO:Importing libraries
2022-11-08 11:28:49,807:INFO:Copying training dataset
2022-11-08 11:28:49,812:INFO:Defining folds
2022-11-08 11:28:49,812:INFO:Declaring metric variables
2022-11-08 11:28:49,822:INFO:Importing untrained model
2022-11-08 11:28:49,829:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:28:49,846:INFO:Starting cross validation
2022-11-08 11:28:49,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:50,056:INFO:Calculating mean and std
2022-11-08 11:28:50,058:INFO:Creating metrics dataframe
2022-11-08 11:28:50,061:INFO:Uploading results into container
2022-11-08 11:28:50,061:INFO:Uploading model into container now
2022-11-08 11:28:50,063:INFO:master_model_container: 26
2022-11-08 11:28:50,063:INFO:display_container: 3
2022-11-08 11:28:50,063:INFO:BayesianRidge()
2022-11-08 11:28:50,063:INFO:create_model() successfully completed......................................
2022-11-08 11:28:50,186:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:50,186:INFO:Creating metrics dataframe
2022-11-08 11:28:50,202:INFO:Initializing Passive Aggressive Regressor
2022-11-08 11:28:50,202:INFO:Total runtime is 0.057942891120910646 minutes
2022-11-08 11:28:50,207:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:50,208:INFO:Initializing create_model()
2022-11-08 11:28:50,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:50,208:INFO:Checking exceptions
2022-11-08 11:28:50,211:INFO:Importing libraries
2022-11-08 11:28:50,212:INFO:Copying training dataset
2022-11-08 11:28:50,219:INFO:Defining folds
2022-11-08 11:28:50,219:INFO:Declaring metric variables
2022-11-08 11:28:50,225:INFO:Importing untrained model
2022-11-08 11:28:50,234:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:28:50,251:INFO:Starting cross validation
2022-11-08 11:28:50,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:50,451:INFO:Calculating mean and std
2022-11-08 11:28:50,453:INFO:Creating metrics dataframe
2022-11-08 11:28:50,457:INFO:Uploading results into container
2022-11-08 11:28:50,458:INFO:Uploading model into container now
2022-11-08 11:28:50,458:INFO:master_model_container: 27
2022-11-08 11:28:50,458:INFO:display_container: 3
2022-11-08 11:28:50,459:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:28:50,459:INFO:create_model() successfully completed......................................
2022-11-08 11:28:50,578:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:50,580:INFO:Creating metrics dataframe
2022-11-08 11:28:50,595:INFO:Initializing Huber Regressor
2022-11-08 11:28:50,596:INFO:Total runtime is 0.06450155178705852 minutes
2022-11-08 11:28:50,600:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:50,602:INFO:Initializing create_model()
2022-11-08 11:28:50,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:50,602:INFO:Checking exceptions
2022-11-08 11:28:50,605:INFO:Importing libraries
2022-11-08 11:28:50,606:INFO:Copying training dataset
2022-11-08 11:28:50,610:INFO:Defining folds
2022-11-08 11:28:50,610:INFO:Declaring metric variables
2022-11-08 11:28:50,618:INFO:Importing untrained model
2022-11-08 11:28:50,627:INFO:Huber Regressor Imported successfully
2022-11-08 11:28:50,642:INFO:Starting cross validation
2022-11-08 11:28:50,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:50,768:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,777:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,800:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,880:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,889:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,889:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,909:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,959:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,966:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,978:INFO:Calculating mean and std
2022-11-08 11:28:50,980:INFO:Creating metrics dataframe
2022-11-08 11:28:50,984:INFO:Uploading results into container
2022-11-08 11:28:50,984:INFO:Uploading model into container now
2022-11-08 11:28:50,985:INFO:master_model_container: 28
2022-11-08 11:28:50,985:INFO:display_container: 3
2022-11-08 11:28:50,986:INFO:HuberRegressor()
2022-11-08 11:28:50,986:INFO:create_model() successfully completed......................................
2022-11-08 11:28:51,106:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:51,106:INFO:Creating metrics dataframe
2022-11-08 11:28:51,124:INFO:Initializing K Neighbors Regressor
2022-11-08 11:28:51,124:INFO:Total runtime is 0.07330013513565065 minutes
2022-11-08 11:28:51,130:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:51,131:INFO:Initializing create_model()
2022-11-08 11:28:51,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:51,131:INFO:Checking exceptions
2022-11-08 11:28:51,133:INFO:Importing libraries
2022-11-08 11:28:51,133:INFO:Copying training dataset
2022-11-08 11:28:51,138:INFO:Defining folds
2022-11-08 11:28:51,139:INFO:Declaring metric variables
2022-11-08 11:28:51,148:INFO:Importing untrained model
2022-11-08 11:28:51,156:INFO:K Neighbors Regressor Imported successfully
2022-11-08 11:28:51,172:INFO:Starting cross validation
2022-11-08 11:28:51,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:51,395:INFO:Calculating mean and std
2022-11-08 11:28:51,397:INFO:Creating metrics dataframe
2022-11-08 11:28:51,401:INFO:Uploading results into container
2022-11-08 11:28:51,401:INFO:Uploading model into container now
2022-11-08 11:28:51,402:INFO:master_model_container: 29
2022-11-08 11:28:51,402:INFO:display_container: 3
2022-11-08 11:28:51,402:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-08 11:28:51,403:INFO:create_model() successfully completed......................................
2022-11-08 11:28:51,518:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:51,518:INFO:Creating metrics dataframe
2022-11-08 11:28:51,539:INFO:Initializing Decision Tree Regressor
2022-11-08 11:28:51,540:INFO:Total runtime is 0.08024451732635499 minutes
2022-11-08 11:28:51,544:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:51,546:INFO:Initializing create_model()
2022-11-08 11:28:51,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:51,547:INFO:Checking exceptions
2022-11-08 11:28:51,549:INFO:Importing libraries
2022-11-08 11:28:51,549:INFO:Copying training dataset
2022-11-08 11:28:51,554:INFO:Defining folds
2022-11-08 11:28:51,555:INFO:Declaring metric variables
2022-11-08 11:28:51,561:INFO:Importing untrained model
2022-11-08 11:28:51,574:INFO:Decision Tree Regressor Imported successfully
2022-11-08 11:28:51,592:INFO:Starting cross validation
2022-11-08 11:28:51,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:51,799:INFO:Calculating mean and std
2022-11-08 11:28:51,801:INFO:Creating metrics dataframe
2022-11-08 11:28:51,805:INFO:Uploading results into container
2022-11-08 11:28:51,805:INFO:Uploading model into container now
2022-11-08 11:28:51,806:INFO:master_model_container: 30
2022-11-08 11:28:51,806:INFO:display_container: 3
2022-11-08 11:28:51,806:INFO:DecisionTreeRegressor(random_state=7997)
2022-11-08 11:28:51,807:INFO:create_model() successfully completed......................................
2022-11-08 11:28:51,926:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:51,926:INFO:Creating metrics dataframe
2022-11-08 11:28:51,943:INFO:Initializing Random Forest Regressor
2022-11-08 11:28:51,943:INFO:Total runtime is 0.08695812622706096 minutes
2022-11-08 11:28:51,950:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:51,950:INFO:Initializing create_model()
2022-11-08 11:28:51,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:51,951:INFO:Checking exceptions
2022-11-08 11:28:51,953:INFO:Importing libraries
2022-11-08 11:28:51,953:INFO:Copying training dataset
2022-11-08 11:28:51,958:INFO:Defining folds
2022-11-08 11:28:51,958:INFO:Declaring metric variables
2022-11-08 11:28:51,964:INFO:Importing untrained model
2022-11-08 11:28:51,971:INFO:Random Forest Regressor Imported successfully
2022-11-08 11:28:51,983:INFO:Starting cross validation
2022-11-08 11:28:51,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:53,222:INFO:Calculating mean and std
2022-11-08 11:28:53,223:INFO:Creating metrics dataframe
2022-11-08 11:28:53,228:INFO:Uploading results into container
2022-11-08 11:28:53,229:INFO:Uploading model into container now
2022-11-08 11:28:53,229:INFO:master_model_container: 31
2022-11-08 11:28:53,230:INFO:display_container: 3
2022-11-08 11:28:53,230:INFO:RandomForestRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:28:53,231:INFO:create_model() successfully completed......................................
2022-11-08 11:28:53,348:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:53,348:INFO:Creating metrics dataframe
2022-11-08 11:28:53,367:INFO:Initializing Extra Trees Regressor
2022-11-08 11:28:53,367:INFO:Total runtime is 0.110696812470754 minutes
2022-11-08 11:28:53,372:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:53,373:INFO:Initializing create_model()
2022-11-08 11:28:53,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:53,373:INFO:Checking exceptions
2022-11-08 11:28:53,378:INFO:Importing libraries
2022-11-08 11:28:53,378:INFO:Copying training dataset
2022-11-08 11:28:53,383:INFO:Defining folds
2022-11-08 11:28:53,383:INFO:Declaring metric variables
2022-11-08 11:28:53,388:INFO:Importing untrained model
2022-11-08 11:28:53,397:INFO:Extra Trees Regressor Imported successfully
2022-11-08 11:28:53,410:INFO:Starting cross validation
2022-11-08 11:28:53,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:54,396:INFO:Calculating mean and std
2022-11-08 11:28:54,398:INFO:Creating metrics dataframe
2022-11-08 11:28:54,402:INFO:Uploading results into container
2022-11-08 11:28:54,402:INFO:Uploading model into container now
2022-11-08 11:28:54,403:INFO:master_model_container: 32
2022-11-08 11:28:54,403:INFO:display_container: 3
2022-11-08 11:28:54,403:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:28:54,403:INFO:create_model() successfully completed......................................
2022-11-08 11:28:54,616:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:54,616:INFO:Creating metrics dataframe
2022-11-08 11:28:54,637:INFO:Initializing AdaBoost Regressor
2022-11-08 11:28:54,637:INFO:Total runtime is 0.13185006380081177 minutes
2022-11-08 11:28:54,645:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:54,645:INFO:Initializing create_model()
2022-11-08 11:28:54,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:54,645:INFO:Checking exceptions
2022-11-08 11:28:54,647:INFO:Importing libraries
2022-11-08 11:28:54,647:INFO:Copying training dataset
2022-11-08 11:28:54,651:INFO:Defining folds
2022-11-08 11:28:54,652:INFO:Declaring metric variables
2022-11-08 11:28:54,658:INFO:Importing untrained model
2022-11-08 11:28:54,668:INFO:AdaBoost Regressor Imported successfully
2022-11-08 11:28:54,685:INFO:Starting cross validation
2022-11-08 11:28:54,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:55,217:INFO:Calculating mean and std
2022-11-08 11:28:55,219:INFO:Creating metrics dataframe
2022-11-08 11:28:55,222:INFO:Uploading results into container
2022-11-08 11:28:55,222:INFO:Uploading model into container now
2022-11-08 11:28:55,223:INFO:master_model_container: 33
2022-11-08 11:28:55,223:INFO:display_container: 3
2022-11-08 11:28:55,223:INFO:AdaBoostRegressor(random_state=7997)
2022-11-08 11:28:55,223:INFO:create_model() successfully completed......................................
2022-11-08 11:28:55,344:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:55,344:INFO:Creating metrics dataframe
2022-11-08 11:28:55,363:INFO:Initializing Gradient Boosting Regressor
2022-11-08 11:28:55,364:INFO:Total runtime is 0.1439779837926229 minutes
2022-11-08 11:28:55,370:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:55,371:INFO:Initializing create_model()
2022-11-08 11:28:55,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:55,371:INFO:Checking exceptions
2022-11-08 11:28:55,373:INFO:Importing libraries
2022-11-08 11:28:55,374:INFO:Copying training dataset
2022-11-08 11:28:55,382:INFO:Defining folds
2022-11-08 11:28:55,382:INFO:Declaring metric variables
2022-11-08 11:28:55,388:INFO:Importing untrained model
2022-11-08 11:28:55,396:INFO:Gradient Boosting Regressor Imported successfully
2022-11-08 11:28:55,411:INFO:Starting cross validation
2022-11-08 11:28:55,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:55,886:INFO:Calculating mean and std
2022-11-08 11:28:55,888:INFO:Creating metrics dataframe
2022-11-08 11:28:55,892:INFO:Uploading results into container
2022-11-08 11:28:55,893:INFO:Uploading model into container now
2022-11-08 11:28:55,893:INFO:master_model_container: 34
2022-11-08 11:28:55,893:INFO:display_container: 3
2022-11-08 11:28:55,893:INFO:GradientBoostingRegressor(random_state=7997)
2022-11-08 11:28:55,893:INFO:create_model() successfully completed......................................
2022-11-08 11:28:56,011:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:56,011:INFO:Creating metrics dataframe
2022-11-08 11:28:56,033:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:28:56,034:INFO:Total runtime is 0.15513759454091391 minutes
2022-11-08 11:28:56,039:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:56,040:INFO:Initializing create_model()
2022-11-08 11:28:56,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:56,040:INFO:Checking exceptions
2022-11-08 11:28:56,044:INFO:Importing libraries
2022-11-08 11:28:56,044:INFO:Copying training dataset
2022-11-08 11:28:56,050:INFO:Defining folds
2022-11-08 11:28:56,050:INFO:Declaring metric variables
2022-11-08 11:28:56,056:INFO:Importing untrained model
2022-11-08 11:28:56,067:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:28:56,083:INFO:Starting cross validation
2022-11-08 11:28:56,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:56,389:INFO:Calculating mean and std
2022-11-08 11:28:56,391:INFO:Creating metrics dataframe
2022-11-08 11:28:56,395:INFO:Uploading results into container
2022-11-08 11:28:56,396:INFO:Uploading model into container now
2022-11-08 11:28:56,396:INFO:master_model_container: 35
2022-11-08 11:28:56,396:INFO:display_container: 3
2022-11-08 11:28:56,396:INFO:LGBMRegressor(random_state=7997)
2022-11-08 11:28:56,396:INFO:create_model() successfully completed......................................
2022-11-08 11:28:56,517:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:56,517:INFO:Creating metrics dataframe
2022-11-08 11:28:56,539:INFO:Initializing Dummy Regressor
2022-11-08 11:28:56,547:INFO:Total runtime is 0.16368584235509237 minutes
2022-11-08 11:28:56,553:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:56,554:INFO:Initializing create_model()
2022-11-08 11:28:56,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:56,554:INFO:Checking exceptions
2022-11-08 11:28:56,557:INFO:Importing libraries
2022-11-08 11:28:56,558:INFO:Copying training dataset
2022-11-08 11:28:56,563:INFO:Defining folds
2022-11-08 11:28:56,563:INFO:Declaring metric variables
2022-11-08 11:28:56,573:INFO:Importing untrained model
2022-11-08 11:28:56,581:INFO:Dummy Regressor Imported successfully
2022-11-08 11:28:56,597:INFO:Starting cross validation
2022-11-08 11:28:56,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:56,783:INFO:Calculating mean and std
2022-11-08 11:28:56,785:INFO:Creating metrics dataframe
2022-11-08 11:28:56,789:INFO:Uploading results into container
2022-11-08 11:28:56,789:INFO:Uploading model into container now
2022-11-08 11:28:56,790:INFO:master_model_container: 36
2022-11-08 11:28:56,790:INFO:display_container: 3
2022-11-08 11:28:56,790:INFO:DummyRegressor()
2022-11-08 11:28:56,790:INFO:create_model() successfully completed......................................
2022-11-08 11:28:56,909:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:56,909:INFO:Creating metrics dataframe
2022-11-08 11:28:56,946:INFO:Initializing create_model()
2022-11-08 11:28:56,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:56,946:INFO:Checking exceptions
2022-11-08 11:28:56,948:INFO:Importing libraries
2022-11-08 11:28:56,948:INFO:Copying training dataset
2022-11-08 11:28:56,948:INFO:Defining folds
2022-11-08 11:28:56,948:INFO:Declaring metric variables
2022-11-08 11:28:56,948:INFO:Importing untrained model
2022-11-08 11:28:56,955:INFO:Declaring custom model
2022-11-08 11:28:56,957:INFO:Huber Regressor Imported successfully
2022-11-08 11:28:56,958:INFO:Cross validation set to False
2022-11-08 11:28:56,959:INFO:Fitting Model
2022-11-08 11:28:57,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:57,017:INFO:HuberRegressor()
2022-11-08 11:28:57,017:INFO:create_model() successfully completed......................................
2022-11-08 11:28:57,149:INFO:Initializing create_model()
2022-11-08 11:28:57,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=PassiveAggressiveRegressor(random_state=7997), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:57,150:INFO:Checking exceptions
2022-11-08 11:28:57,155:INFO:Importing libraries
2022-11-08 11:28:57,157:INFO:Copying training dataset
2022-11-08 11:28:57,159:INFO:Defining folds
2022-11-08 11:28:57,159:INFO:Declaring metric variables
2022-11-08 11:28:57,159:INFO:Importing untrained model
2022-11-08 11:28:57,159:INFO:Declaring custom model
2022-11-08 11:28:57,159:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:28:57,159:INFO:Cross validation set to False
2022-11-08 11:28:57,159:INFO:Fitting Model
2022-11-08 11:28:57,177:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:28:57,177:INFO:create_model() successfully completed......................................
2022-11-08 11:28:57,307:INFO:Initializing create_model()
2022-11-08 11:28:57,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:57,308:INFO:Checking exceptions
2022-11-08 11:28:57,312:INFO:Importing libraries
2022-11-08 11:28:57,312:INFO:Copying training dataset
2022-11-08 11:28:57,317:INFO:Defining folds
2022-11-08 11:28:57,317:INFO:Declaring metric variables
2022-11-08 11:28:57,317:INFO:Importing untrained model
2022-11-08 11:28:57,317:INFO:Declaring custom model
2022-11-08 11:28:57,317:INFO:Dummy Regressor Imported successfully
2022-11-08 11:28:57,321:INFO:Cross validation set to False
2022-11-08 11:28:57,321:INFO:Fitting Model
2022-11-08 11:28:57,338:INFO:DummyRegressor()
2022-11-08 11:28:57,338:INFO:create_model() successfully completed......................................
2022-11-08 11:28:57,514:INFO:master_model_container: 36
2022-11-08 11:28:57,514:INFO:display_container: 3
2022-11-08 11:28:57,515:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=7997), DummyRegressor()]
2022-11-08 11:28:57,515:INFO:compare_models() successfully completed......................................
2022-11-08 11:29:38,346:INFO:Initializing create_model()
2022-11-08 11:29:38,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:29:38,347:INFO:Checking exceptions
2022-11-08 11:29:38,411:INFO:Importing libraries
2022-11-08 11:29:38,411:INFO:Copying training dataset
2022-11-08 11:29:38,417:INFO:Defining folds
2022-11-08 11:29:38,417:INFO:Declaring metric variables
2022-11-08 11:29:38,447:INFO:Importing untrained model
2022-11-08 11:29:38,455:INFO:Huber Regressor Imported successfully
2022-11-08 11:29:38,466:INFO:Starting cross validation
2022-11-08 11:29:38,466:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:29:38,825:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:38,827:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:38,840:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:38,877:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,292:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,292:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,346:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,425:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,810:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,839:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,850:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,891:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,388:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,439:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,439:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,487:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,856:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,932:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:41,006:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:41,126:INFO:Calculating mean and std
2022-11-08 11:29:41,128:INFO:Creating metrics dataframe
2022-11-08 11:29:41,135:INFO:Finalizing model
2022-11-08 11:29:41,186:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:41,192:INFO:Uploading results into container
2022-11-08 11:29:41,193:INFO:Uploading model into container now
2022-11-08 11:29:41,210:INFO:master_model_container: 37
2022-11-08 11:29:41,211:INFO:display_container: 4
2022-11-08 11:29:41,211:INFO:HuberRegressor()
2022-11-08 11:29:41,211:INFO:create_model() successfully completed......................................
2022-11-08 11:29:58,884:INFO:Initializing plot_model()
2022-11-08 11:29:58,884:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, system=True)
2022-11-08 11:29:58,886:INFO:Checking exceptions
2022-11-08 11:29:58,890:INFO:Preloading libraries
2022-11-08 11:29:58,891:INFO:Copying training dataset
2022-11-08 11:29:58,891:INFO:Plot type: residuals
2022-11-08 11:29:59,087:INFO:Fitting Model
2022-11-08 11:29:59,087:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:29:59,166:INFO:Scoring test/hold-out set
2022-11-08 11:30:00,137:INFO:Visual Rendered Successfully
2022-11-08 11:30:00,290:INFO:plot_model() successfully completed......................................
2022-11-08 11:30:39,625:INFO:PyCaret RegressionExperiment
2022-11-08 11:30:39,625:INFO:Logging name: reg-default-name
2022-11-08 11:30:39,625:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-08 11:30:39,626:INFO:version 3.0.0.rc4
2022-11-08 11:30:39,626:INFO:Initializing setup()
2022-11-08 11:30:39,626:INFO:self.USI: f870
2022-11-08 11:30:39,626:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'transform_target_method_param', 'master_model_container', 'y_test', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:30:39,626:INFO:Checking environment
2022-11-08 11:30:39,626:INFO:python_version: 3.10.4
2022-11-08 11:30:39,626:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:30:39,627:INFO:machine: AMD64
2022-11-08 11:30:39,627:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:30:39,627:INFO:Memory: svmem(total=8503136256, available=1445359616, percent=83.0, used=7057776640, free=1445359616)
2022-11-08 11:30:39,627:INFO:Physical Core: 2
2022-11-08 11:30:39,627:INFO:Logical Core: 4
2022-11-08 11:30:39,627:INFO:Checking libraries
2022-11-08 11:30:39,627:INFO:System:
2022-11-08 11:30:39,627:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:30:39,627:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:30:39,627:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:30:39,627:INFO:PyCaret required dependencies:
2022-11-08 11:30:39,627:INFO:                 pip: 22.2.2
2022-11-08 11:30:39,627:INFO:          setuptools: 58.1.0
2022-11-08 11:30:39,627:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:30:39,627:INFO:             IPython: 8.4.0
2022-11-08 11:30:39,627:INFO:          ipywidgets: 8.0.2
2022-11-08 11:30:39,627:INFO:                tqdm: 4.64.0
2022-11-08 11:30:39,627:INFO:               numpy: 1.22.3
2022-11-08 11:30:39,627:INFO:              pandas: 1.4.2
2022-11-08 11:30:39,627:INFO:              jinja2: 3.1.2
2022-11-08 11:30:39,627:INFO:               scipy: 1.8.1
2022-11-08 11:30:39,627:INFO:              joblib: 1.2.0
2022-11-08 11:30:39,627:INFO:             sklearn: 1.1.2
2022-11-08 11:30:39,627:INFO:                pyod: 1.0.6
2022-11-08 11:30:39,627:INFO:            imblearn: 0.9.1
2022-11-08 11:30:39,627:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:30:39,627:INFO:            lightgbm: 3.3.3
2022-11-08 11:30:39,627:INFO:               numba: 0.55.2
2022-11-08 11:30:39,627:INFO:            requests: 2.28.1
2022-11-08 11:30:39,631:INFO:          matplotlib: 3.5.1
2022-11-08 11:30:39,631:INFO:          scikitplot: 0.3.7
2022-11-08 11:30:39,631:INFO:         yellowbrick: 1.5
2022-11-08 11:30:39,631:INFO:              plotly: 5.11.0
2022-11-08 11:30:39,631:INFO:             kaleido: 0.2.1
2022-11-08 11:30:39,631:INFO:         statsmodels: 0.13.5
2022-11-08 11:30:39,631:INFO:              sktime: 0.13.4
2022-11-08 11:30:39,631:INFO:               tbats: 1.1.1
2022-11-08 11:30:39,631:INFO:            pmdarima: 1.8.5
2022-11-08 11:30:39,632:INFO:              psutil: 5.9.1
2022-11-08 11:30:39,632:INFO:PyCaret optional dependencies:
2022-11-08 11:30:39,632:INFO:                shap: Not installed
2022-11-08 11:30:39,632:INFO:           interpret: Not installed
2022-11-08 11:30:39,632:INFO:                umap: Not installed
2022-11-08 11:30:39,632:INFO:    pandas_profiling: Not installed
2022-11-08 11:30:39,632:INFO:  explainerdashboard: Not installed
2022-11-08 11:30:39,632:INFO:             autoviz: Not installed
2022-11-08 11:30:39,632:INFO:           fairlearn: Not installed
2022-11-08 11:30:39,632:INFO:             xgboost: Not installed
2022-11-08 11:30:39,632:INFO:            catboost: Not installed
2022-11-08 11:30:39,632:INFO:              kmodes: Not installed
2022-11-08 11:30:39,632:INFO:             mlxtend: Not installed
2022-11-08 11:30:39,632:INFO:       statsforecast: Not installed
2022-11-08 11:30:39,632:INFO:        tune_sklearn: Not installed
2022-11-08 11:30:39,632:INFO:                 ray: Not installed
2022-11-08 11:30:39,632:INFO:            hyperopt: Not installed
2022-11-08 11:30:39,632:INFO:              optuna: Not installed
2022-11-08 11:30:39,632:INFO:               skopt: Not installed
2022-11-08 11:30:39,632:INFO:              mlflow: Not installed
2022-11-08 11:30:39,632:INFO:              gradio: Not installed
2022-11-08 11:30:39,632:INFO:             fastapi: Not installed
2022-11-08 11:30:39,632:INFO:             uvicorn: Not installed
2022-11-08 11:30:39,632:INFO:              m2cgen: Not installed
2022-11-08 11:30:39,632:INFO:           evidently: Not installed
2022-11-08 11:30:39,632:INFO:                nltk: 3.7
2022-11-08 11:30:39,635:INFO:            pyLDAvis: Not installed
2022-11-08 11:30:39,635:INFO:              gensim: Not installed
2022-11-08 11:30:39,635:INFO:               spacy: Not installed
2022-11-08 11:30:39,635:INFO:           wordcloud: Not installed
2022-11-08 11:30:39,635:INFO:            textblob: Not installed
2022-11-08 11:30:39,635:INFO:               fugue: Not installed
2022-11-08 11:30:39,635:INFO:           streamlit: Not installed
2022-11-08 11:30:39,635:INFO:             prophet: Not installed
2022-11-08 11:30:39,635:INFO:None
2022-11-08 11:30:39,635:INFO:Set up data.
2022-11-08 11:30:39,645:INFO:Set up train/test split.
2022-11-08 11:30:39,653:INFO:Set up index.
2022-11-08 11:30:39,653:INFO:Set up folding strategy.
2022-11-08 11:30:39,653:INFO:Assigning column types.
2022-11-08 11:30:39,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:30:39,661:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,671:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:39,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:39,847:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,856:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,058:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-08 11:30:40,058:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,247:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,396:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-08 11:30:40,407:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,909:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-08 11:30:40,998:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,242:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:30:41,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,522:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-08 11:30:41,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,877:INFO:Preparing preprocessing pipeline...
2022-11-08 11:30:41,885:INFO:Set up simple imputation.
2022-11-08 11:30:41,885:INFO:Set up variance threshold.
2022-11-08 11:30:41,948:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:30:41,956:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-08 11:30:41,957:INFO:Creating final display dataframe.
2022-11-08 11:30:42,238:INFO:Setup display_container:                Description             Value
0               Session id               204
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              f870
2022-11-08 11:30:42,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,549:INFO:setup() successfully completed in 2.93s...............
2022-11-08 11:30:42,609:INFO:Initializing compare_models()
2022-11-08 11:30:42,609:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-08 11:30:42,609:INFO:Checking exceptions
2022-11-08 11:30:42,613:INFO:Preparing display monitor
2022-11-08 11:30:42,668:INFO:Initializing Linear Regression
2022-11-08 11:30:42,669:INFO:Total runtime is 1.911322275797526e-05 minutes
2022-11-08 11:30:42,675:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:42,675:INFO:Initializing create_model()
2022-11-08 11:30:42,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:42,675:INFO:Checking exceptions
2022-11-08 11:30:42,680:INFO:Importing libraries
2022-11-08 11:30:42,680:INFO:Copying training dataset
2022-11-08 11:30:42,680:INFO:Defining folds
2022-11-08 11:30:42,680:INFO:Declaring metric variables
2022-11-08 11:30:42,694:INFO:Importing untrained model
2022-11-08 11:30:42,701:INFO:Linear Regression Imported successfully
2022-11-08 11:30:42,713:INFO:Starting cross validation
2022-11-08 11:30:42,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:43,815:INFO:Calculating mean and std
2022-11-08 11:30:43,818:INFO:Creating metrics dataframe
2022-11-08 11:30:43,825:INFO:Uploading results into container
2022-11-08 11:30:43,826:INFO:Uploading model into container now
2022-11-08 11:30:43,827:INFO:master_model_container: 1
2022-11-08 11:30:43,827:INFO:display_container: 2
2022-11-08 11:30:43,827:INFO:LinearRegression(n_jobs=-1)
2022-11-08 11:30:43,827:INFO:create_model() successfully completed......................................
2022-11-08 11:30:43,977:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:43,977:INFO:Creating metrics dataframe
2022-11-08 11:30:43,992:INFO:Initializing Lasso Regression
2022-11-08 11:30:43,992:INFO:Total runtime is 0.02206399440765381 minutes
2022-11-08 11:30:43,997:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:43,997:INFO:Initializing create_model()
2022-11-08 11:30:43,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:43,997:INFO:Checking exceptions
2022-11-08 11:30:44,000:INFO:Importing libraries
2022-11-08 11:30:44,000:INFO:Copying training dataset
2022-11-08 11:30:44,007:INFO:Defining folds
2022-11-08 11:30:44,007:INFO:Declaring metric variables
2022-11-08 11:30:44,013:INFO:Importing untrained model
2022-11-08 11:30:44,021:INFO:Lasso Regression Imported successfully
2022-11-08 11:30:44,032:INFO:Starting cross validation
2022-11-08 11:30:44,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:44,333:INFO:Calculating mean and std
2022-11-08 11:30:44,336:INFO:Creating metrics dataframe
2022-11-08 11:30:44,340:INFO:Uploading results into container
2022-11-08 11:30:44,340:INFO:Uploading model into container now
2022-11-08 11:30:44,341:INFO:master_model_container: 2
2022-11-08 11:30:44,341:INFO:display_container: 2
2022-11-08 11:30:44,341:INFO:Lasso(random_state=204)
2022-11-08 11:30:44,341:INFO:create_model() successfully completed......................................
2022-11-08 11:30:44,463:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:44,464:INFO:Creating metrics dataframe
2022-11-08 11:30:44,480:INFO:Initializing Ridge Regression
2022-11-08 11:30:44,480:INFO:Total runtime is 0.03020600477854411 minutes
2022-11-08 11:30:44,487:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:44,488:INFO:Initializing create_model()
2022-11-08 11:30:44,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:44,488:INFO:Checking exceptions
2022-11-08 11:30:44,491:INFO:Importing libraries
2022-11-08 11:30:44,491:INFO:Copying training dataset
2022-11-08 11:30:44,497:INFO:Defining folds
2022-11-08 11:30:44,498:INFO:Declaring metric variables
2022-11-08 11:30:44,506:INFO:Importing untrained model
2022-11-08 11:30:44,511:INFO:Ridge Regression Imported successfully
2022-11-08 11:30:44,524:INFO:Starting cross validation
2022-11-08 11:30:44,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:44,739:INFO:Calculating mean and std
2022-11-08 11:30:44,742:INFO:Creating metrics dataframe
2022-11-08 11:30:44,745:INFO:Uploading results into container
2022-11-08 11:30:44,746:INFO:Uploading model into container now
2022-11-08 11:30:44,746:INFO:master_model_container: 3
2022-11-08 11:30:44,746:INFO:display_container: 2
2022-11-08 11:30:44,746:INFO:Ridge(random_state=204)
2022-11-08 11:30:44,746:INFO:create_model() successfully completed......................................
2022-11-08 11:30:44,885:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:44,885:INFO:Creating metrics dataframe
2022-11-08 11:30:44,912:INFO:Initializing Elastic Net
2022-11-08 11:30:44,912:INFO:Total runtime is 0.03739255666732788 minutes
2022-11-08 11:30:44,920:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:44,921:INFO:Initializing create_model()
2022-11-08 11:30:44,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:44,922:INFO:Checking exceptions
2022-11-08 11:30:44,923:INFO:Importing libraries
2022-11-08 11:30:44,923:INFO:Copying training dataset
2022-11-08 11:30:44,928:INFO:Defining folds
2022-11-08 11:30:44,929:INFO:Declaring metric variables
2022-11-08 11:30:44,936:INFO:Importing untrained model
2022-11-08 11:30:44,942:INFO:Elastic Net Imported successfully
2022-11-08 11:30:44,954:INFO:Starting cross validation
2022-11-08 11:30:44,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:45,195:INFO:Calculating mean and std
2022-11-08 11:30:45,197:INFO:Creating metrics dataframe
2022-11-08 11:30:45,202:INFO:Uploading results into container
2022-11-08 11:30:45,204:INFO:Uploading model into container now
2022-11-08 11:30:45,205:INFO:master_model_container: 4
2022-11-08 11:30:45,205:INFO:display_container: 2
2022-11-08 11:30:45,206:INFO:ElasticNet(random_state=204)
2022-11-08 11:30:45,206:INFO:create_model() successfully completed......................................
2022-11-08 11:30:45,347:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:45,347:INFO:Creating metrics dataframe
2022-11-08 11:30:45,371:INFO:Initializing Least Angle Regression
2022-11-08 11:30:45,372:INFO:Total runtime is 0.04505216677983602 minutes
2022-11-08 11:30:45,378:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:45,379:INFO:Initializing create_model()
2022-11-08 11:30:45,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:45,379:INFO:Checking exceptions
2022-11-08 11:30:45,381:INFO:Importing libraries
2022-11-08 11:30:45,382:INFO:Copying training dataset
2022-11-08 11:30:45,390:INFO:Defining folds
2022-11-08 11:30:45,391:INFO:Declaring metric variables
2022-11-08 11:30:45,400:INFO:Importing untrained model
2022-11-08 11:30:45,409:INFO:Least Angle Regression Imported successfully
2022-11-08 11:30:45,428:INFO:Starting cross validation
2022-11-08 11:30:45,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:45,489:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,500:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,510:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,555:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,560:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,580:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,590:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,614:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,620:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,636:INFO:Calculating mean and std
2022-11-08 11:30:45,637:INFO:Creating metrics dataframe
2022-11-08 11:30:45,641:INFO:Uploading results into container
2022-11-08 11:30:45,641:INFO:Uploading model into container now
2022-11-08 11:30:45,642:INFO:master_model_container: 5
2022-11-08 11:30:45,642:INFO:display_container: 2
2022-11-08 11:30:45,642:INFO:Lars(random_state=204)
2022-11-08 11:30:45,643:INFO:create_model() successfully completed......................................
2022-11-08 11:30:45,769:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:45,769:INFO:Creating metrics dataframe
2022-11-08 11:30:45,781:INFO:Initializing Lasso Least Angle Regression
2022-11-08 11:30:45,781:INFO:Total runtime is 0.05188793341318766 minutes
2022-11-08 11:30:45,788:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:45,789:INFO:Initializing create_model()
2022-11-08 11:30:45,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:45,789:INFO:Checking exceptions
2022-11-08 11:30:45,792:INFO:Importing libraries
2022-11-08 11:30:45,792:INFO:Copying training dataset
2022-11-08 11:30:45,798:INFO:Defining folds
2022-11-08 11:30:45,798:INFO:Declaring metric variables
2022-11-08 11:30:45,804:INFO:Importing untrained model
2022-11-08 11:30:45,813:INFO:Lasso Least Angle Regression Imported successfully
2022-11-08 11:30:45,829:INFO:Starting cross validation
2022-11-08 11:30:45,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:45,905:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,910:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,917:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,935:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,958:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,976:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,985:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,005:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,037:INFO:Calculating mean and std
2022-11-08 11:30:46,038:INFO:Creating metrics dataframe
2022-11-08 11:30:46,042:INFO:Uploading results into container
2022-11-08 11:30:46,042:INFO:Uploading model into container now
2022-11-08 11:30:46,044:INFO:master_model_container: 6
2022-11-08 11:30:46,044:INFO:display_container: 2
2022-11-08 11:30:46,044:INFO:LassoLars(random_state=204)
2022-11-08 11:30:46,045:INFO:create_model() successfully completed......................................
2022-11-08 11:30:46,169:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:46,169:INFO:Creating metrics dataframe
2022-11-08 11:30:46,184:INFO:Initializing Orthogonal Matching Pursuit
2022-11-08 11:30:46,184:INFO:Total runtime is 0.05859781503677368 minutes
2022-11-08 11:30:46,189:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:46,190:INFO:Initializing create_model()
2022-11-08 11:30:46,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:46,191:INFO:Checking exceptions
2022-11-08 11:30:46,193:INFO:Importing libraries
2022-11-08 11:30:46,194:INFO:Copying training dataset
2022-11-08 11:30:46,198:INFO:Defining folds
2022-11-08 11:30:46,198:INFO:Declaring metric variables
2022-11-08 11:30:46,208:INFO:Importing untrained model
2022-11-08 11:30:46,217:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-08 11:30:46,232:INFO:Starting cross validation
2022-11-08 11:30:46,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:46,287:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,305:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,310:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,317:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,341:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,360:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,375:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,385:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,395:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,412:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,428:INFO:Calculating mean and std
2022-11-08 11:30:46,429:INFO:Creating metrics dataframe
2022-11-08 11:30:46,435:INFO:Uploading results into container
2022-11-08 11:30:46,435:INFO:Uploading model into container now
2022-11-08 11:30:46,436:INFO:master_model_container: 7
2022-11-08 11:30:46,436:INFO:display_container: 2
2022-11-08 11:30:46,436:INFO:OrthogonalMatchingPursuit()
2022-11-08 11:30:46,437:INFO:create_model() successfully completed......................................
2022-11-08 11:30:46,586:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:46,586:INFO:Creating metrics dataframe
2022-11-08 11:30:46,601:INFO:Initializing Bayesian Ridge
2022-11-08 11:30:46,602:INFO:Total runtime is 0.06556618611017863 minutes
2022-11-08 11:30:46,607:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:46,607:INFO:Initializing create_model()
2022-11-08 11:30:46,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:46,608:INFO:Checking exceptions
2022-11-08 11:30:46,610:INFO:Importing libraries
2022-11-08 11:30:46,610:INFO:Copying training dataset
2022-11-08 11:30:46,614:INFO:Defining folds
2022-11-08 11:30:46,614:INFO:Declaring metric variables
2022-11-08 11:30:46,619:INFO:Importing untrained model
2022-11-08 11:30:46,626:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:30:46,639:INFO:Starting cross validation
2022-11-08 11:30:46,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:46,846:INFO:Calculating mean and std
2022-11-08 11:30:46,850:INFO:Creating metrics dataframe
2022-11-08 11:30:46,855:INFO:Uploading results into container
2022-11-08 11:30:46,855:INFO:Uploading model into container now
2022-11-08 11:30:46,856:INFO:master_model_container: 8
2022-11-08 11:30:46,856:INFO:display_container: 2
2022-11-08 11:30:46,856:INFO:BayesianRidge()
2022-11-08 11:30:46,856:INFO:create_model() successfully completed......................................
2022-11-08 11:30:46,977:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:46,977:INFO:Creating metrics dataframe
2022-11-08 11:30:46,994:INFO:Initializing Passive Aggressive Regressor
2022-11-08 11:30:46,994:INFO:Total runtime is 0.07209986050923665 minutes
2022-11-08 11:30:47,000:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:47,001:INFO:Initializing create_model()
2022-11-08 11:30:47,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:47,001:INFO:Checking exceptions
2022-11-08 11:30:47,003:INFO:Importing libraries
2022-11-08 11:30:47,004:INFO:Copying training dataset
2022-11-08 11:30:47,007:INFO:Defining folds
2022-11-08 11:30:47,007:INFO:Declaring metric variables
2022-11-08 11:30:47,012:INFO:Importing untrained model
2022-11-08 11:30:47,020:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:30:47,036:INFO:Starting cross validation
2022-11-08 11:30:47,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:47,227:INFO:Calculating mean and std
2022-11-08 11:30:47,229:INFO:Creating metrics dataframe
2022-11-08 11:30:47,234:INFO:Uploading results into container
2022-11-08 11:30:47,234:INFO:Uploading model into container now
2022-11-08 11:30:47,235:INFO:master_model_container: 9
2022-11-08 11:30:47,235:INFO:display_container: 2
2022-11-08 11:30:47,235:INFO:PassiveAggressiveRegressor(random_state=204)
2022-11-08 11:30:47,235:INFO:create_model() successfully completed......................................
2022-11-08 11:30:47,357:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:47,357:INFO:Creating metrics dataframe
2022-11-08 11:30:47,377:INFO:Initializing Huber Regressor
2022-11-08 11:30:47,377:INFO:Total runtime is 0.07848465045293172 minutes
2022-11-08 11:30:47,384:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:47,385:INFO:Initializing create_model()
2022-11-08 11:30:47,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:47,385:INFO:Checking exceptions
2022-11-08 11:30:47,388:INFO:Importing libraries
2022-11-08 11:30:47,388:INFO:Copying training dataset
2022-11-08 11:30:47,393:INFO:Defining folds
2022-11-08 11:30:47,393:INFO:Declaring metric variables
2022-11-08 11:30:47,400:INFO:Importing untrained model
2022-11-08 11:30:47,408:INFO:Huber Regressor Imported successfully
2022-11-08 11:30:47,424:INFO:Starting cross validation
2022-11-08 11:30:47,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:47,550:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,558:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,575:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,585:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,655:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,667:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,694:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,704:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,755:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,767:INFO:Calculating mean and std
2022-11-08 11:30:47,769:INFO:Creating metrics dataframe
2022-11-08 11:30:47,773:INFO:Uploading results into container
2022-11-08 11:30:47,773:INFO:Uploading model into container now
2022-11-08 11:30:47,774:INFO:master_model_container: 10
2022-11-08 11:30:47,774:INFO:display_container: 2
2022-11-08 11:30:47,774:INFO:HuberRegressor()
2022-11-08 11:30:47,774:INFO:create_model() successfully completed......................................
2022-11-08 11:30:47,897:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:47,899:INFO:Creating metrics dataframe
2022-11-08 11:30:47,918:INFO:Initializing K Neighbors Regressor
2022-11-08 11:30:47,919:INFO:Total runtime is 0.08751900196075439 minutes
2022-11-08 11:30:47,924:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:47,924:INFO:Initializing create_model()
2022-11-08 11:30:47,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:47,925:INFO:Checking exceptions
2022-11-08 11:30:47,928:INFO:Importing libraries
2022-11-08 11:30:47,928:INFO:Copying training dataset
2022-11-08 11:30:47,934:INFO:Defining folds
2022-11-08 11:30:47,934:INFO:Declaring metric variables
2022-11-08 11:30:47,942:INFO:Importing untrained model
2022-11-08 11:30:47,949:INFO:K Neighbors Regressor Imported successfully
2022-11-08 11:30:47,965:INFO:Starting cross validation
2022-11-08 11:30:47,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:48,197:INFO:Calculating mean and std
2022-11-08 11:30:48,199:INFO:Creating metrics dataframe
2022-11-08 11:30:48,203:INFO:Uploading results into container
2022-11-08 11:30:48,203:INFO:Uploading model into container now
2022-11-08 11:30:48,204:INFO:master_model_container: 11
2022-11-08 11:30:48,204:INFO:display_container: 2
2022-11-08 11:30:48,204:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-08 11:30:48,204:INFO:create_model() successfully completed......................................
2022-11-08 11:30:48,325:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:48,325:INFO:Creating metrics dataframe
2022-11-08 11:30:48,344:INFO:Initializing Decision Tree Regressor
2022-11-08 11:30:48,344:INFO:Total runtime is 0.0946046233177185 minutes
2022-11-08 11:30:48,350:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:48,351:INFO:Initializing create_model()
2022-11-08 11:30:48,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:48,352:INFO:Checking exceptions
2022-11-08 11:30:48,355:INFO:Importing libraries
2022-11-08 11:30:48,355:INFO:Copying training dataset
2022-11-08 11:30:48,360:INFO:Defining folds
2022-11-08 11:30:48,360:INFO:Declaring metric variables
2022-11-08 11:30:48,367:INFO:Importing untrained model
2022-11-08 11:30:48,374:INFO:Decision Tree Regressor Imported successfully
2022-11-08 11:30:48,387:INFO:Starting cross validation
2022-11-08 11:30:48,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:48,592:INFO:Calculating mean and std
2022-11-08 11:30:48,593:INFO:Creating metrics dataframe
2022-11-08 11:30:48,599:INFO:Uploading results into container
2022-11-08 11:30:48,599:INFO:Uploading model into container now
2022-11-08 11:30:48,600:INFO:master_model_container: 12
2022-11-08 11:30:48,600:INFO:display_container: 2
2022-11-08 11:30:48,600:INFO:DecisionTreeRegressor(random_state=204)
2022-11-08 11:30:48,601:INFO:create_model() successfully completed......................................
2022-11-08 11:30:48,726:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:48,726:INFO:Creating metrics dataframe
2022-11-08 11:30:48,744:INFO:Initializing Random Forest Regressor
2022-11-08 11:30:48,745:INFO:Total runtime is 0.10127543210983277 minutes
2022-11-08 11:30:48,750:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:48,751:INFO:Initializing create_model()
2022-11-08 11:30:48,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:48,751:INFO:Checking exceptions
2022-11-08 11:30:48,754:INFO:Importing libraries
2022-11-08 11:30:48,754:INFO:Copying training dataset
2022-11-08 11:30:48,759:INFO:Defining folds
2022-11-08 11:30:48,759:INFO:Declaring metric variables
2022-11-08 11:30:48,769:INFO:Importing untrained model
2022-11-08 11:30:48,773:INFO:Random Forest Regressor Imported successfully
2022-11-08 11:30:48,791:INFO:Starting cross validation
2022-11-08 11:30:48,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:50,156:INFO:Calculating mean and std
2022-11-08 11:30:50,158:INFO:Creating metrics dataframe
2022-11-08 11:30:50,162:INFO:Uploading results into container
2022-11-08 11:30:50,163:INFO:Uploading model into container now
2022-11-08 11:30:50,164:INFO:master_model_container: 13
2022-11-08 11:30:50,164:INFO:display_container: 2
2022-11-08 11:30:50,164:INFO:RandomForestRegressor(n_jobs=-1, random_state=204)
2022-11-08 11:30:50,165:INFO:create_model() successfully completed......................................
2022-11-08 11:30:50,291:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:50,291:INFO:Creating metrics dataframe
2022-11-08 11:30:50,308:INFO:Initializing Extra Trees Regressor
2022-11-08 11:30:50,308:INFO:Total runtime is 0.1273256580034892 minutes
2022-11-08 11:30:50,314:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:50,314:INFO:Initializing create_model()
2022-11-08 11:30:50,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:50,315:INFO:Checking exceptions
2022-11-08 11:30:50,319:INFO:Importing libraries
2022-11-08 11:30:50,319:INFO:Copying training dataset
2022-11-08 11:30:50,323:INFO:Defining folds
2022-11-08 11:30:50,323:INFO:Declaring metric variables
2022-11-08 11:30:50,330:INFO:Importing untrained model
2022-11-08 11:30:50,337:INFO:Extra Trees Regressor Imported successfully
2022-11-08 11:30:50,353:INFO:Starting cross validation
2022-11-08 11:30:50,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:51,309:INFO:Calculating mean and std
2022-11-08 11:30:51,312:INFO:Creating metrics dataframe
2022-11-08 11:30:51,317:INFO:Uploading results into container
2022-11-08 11:30:51,318:INFO:Uploading model into container now
2022-11-08 11:30:51,319:INFO:master_model_container: 14
2022-11-08 11:30:51,319:INFO:display_container: 2
2022-11-08 11:30:51,319:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=204)
2022-11-08 11:30:51,319:INFO:create_model() successfully completed......................................
2022-11-08 11:30:51,441:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:51,442:INFO:Creating metrics dataframe
2022-11-08 11:30:51,461:INFO:Initializing AdaBoost Regressor
2022-11-08 11:30:51,461:INFO:Total runtime is 0.14655420382817588 minutes
2022-11-08 11:30:51,467:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:51,468:INFO:Initializing create_model()
2022-11-08 11:30:51,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:51,469:INFO:Checking exceptions
2022-11-08 11:30:51,471:INFO:Importing libraries
2022-11-08 11:30:51,471:INFO:Copying training dataset
2022-11-08 11:30:51,477:INFO:Defining folds
2022-11-08 11:30:51,477:INFO:Declaring metric variables
2022-11-08 11:30:51,482:INFO:Importing untrained model
2022-11-08 11:30:51,489:INFO:AdaBoost Regressor Imported successfully
2022-11-08 11:30:51,501:INFO:Starting cross validation
2022-11-08 11:30:51,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:52,026:INFO:Calculating mean and std
2022-11-08 11:30:52,029:INFO:Creating metrics dataframe
2022-11-08 11:30:52,032:INFO:Uploading results into container
2022-11-08 11:30:52,032:INFO:Uploading model into container now
2022-11-08 11:30:52,033:INFO:master_model_container: 15
2022-11-08 11:30:52,033:INFO:display_container: 2
2022-11-08 11:30:52,033:INFO:AdaBoostRegressor(random_state=204)
2022-11-08 11:30:52,033:INFO:create_model() successfully completed......................................
2022-11-08 11:30:52,153:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:52,153:INFO:Creating metrics dataframe
2022-11-08 11:30:52,175:INFO:Initializing Gradient Boosting Regressor
2022-11-08 11:30:52,175:INFO:Total runtime is 0.15844988425572715 minutes
2022-11-08 11:30:52,181:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:52,182:INFO:Initializing create_model()
2022-11-08 11:30:52,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:52,183:INFO:Checking exceptions
2022-11-08 11:30:52,186:INFO:Importing libraries
2022-11-08 11:30:52,186:INFO:Copying training dataset
2022-11-08 11:30:52,190:INFO:Defining folds
2022-11-08 11:30:52,190:INFO:Declaring metric variables
2022-11-08 11:30:52,197:INFO:Importing untrained model
2022-11-08 11:30:52,206:INFO:Gradient Boosting Regressor Imported successfully
2022-11-08 11:30:52,220:INFO:Starting cross validation
2022-11-08 11:30:52,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:52,795:INFO:Calculating mean and std
2022-11-08 11:30:52,797:INFO:Creating metrics dataframe
2022-11-08 11:30:52,801:INFO:Uploading results into container
2022-11-08 11:30:52,801:INFO:Uploading model into container now
2022-11-08 11:30:52,802:INFO:master_model_container: 16
2022-11-08 11:30:52,802:INFO:display_container: 2
2022-11-08 11:30:52,802:INFO:GradientBoostingRegressor(random_state=204)
2022-11-08 11:30:52,802:INFO:create_model() successfully completed......................................
2022-11-08 11:30:52,923:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:52,923:INFO:Creating metrics dataframe
2022-11-08 11:30:52,943:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:30:52,944:INFO:Total runtime is 0.17126728693644208 minutes
2022-11-08 11:30:52,948:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:52,949:INFO:Initializing create_model()
2022-11-08 11:30:52,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:52,950:INFO:Checking exceptions
2022-11-08 11:30:52,952:INFO:Importing libraries
2022-11-08 11:30:52,953:INFO:Copying training dataset
2022-11-08 11:30:52,958:INFO:Defining folds
2022-11-08 11:30:52,959:INFO:Declaring metric variables
2022-11-08 11:30:52,968:INFO:Importing untrained model
2022-11-08 11:30:52,977:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:30:52,992:INFO:Starting cross validation
2022-11-08 11:30:52,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:53,366:INFO:Calculating mean and std
2022-11-08 11:30:53,368:INFO:Creating metrics dataframe
2022-11-08 11:30:53,372:INFO:Uploading results into container
2022-11-08 11:30:53,373:INFO:Uploading model into container now
2022-11-08 11:30:53,373:INFO:master_model_container: 17
2022-11-08 11:30:53,374:INFO:display_container: 2
2022-11-08 11:30:53,374:INFO:LGBMRegressor(random_state=204)
2022-11-08 11:30:53,374:INFO:create_model() successfully completed......................................
2022-11-08 11:30:53,497:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:53,497:INFO:Creating metrics dataframe
2022-11-08 11:30:53,515:INFO:Initializing Dummy Regressor
2022-11-08 11:30:53,515:INFO:Total runtime is 0.1807864824930827 minutes
2022-11-08 11:30:53,520:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:53,521:INFO:Initializing create_model()
2022-11-08 11:30:53,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:53,521:INFO:Checking exceptions
2022-11-08 11:30:53,524:INFO:Importing libraries
2022-11-08 11:30:53,524:INFO:Copying training dataset
2022-11-08 11:30:53,530:INFO:Defining folds
2022-11-08 11:30:53,530:INFO:Declaring metric variables
2022-11-08 11:30:53,535:INFO:Importing untrained model
2022-11-08 11:30:53,542:INFO:Dummy Regressor Imported successfully
2022-11-08 11:30:53,553:INFO:Starting cross validation
2022-11-08 11:30:53,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:53,738:INFO:Calculating mean and std
2022-11-08 11:30:53,739:INFO:Creating metrics dataframe
2022-11-08 11:30:53,744:INFO:Uploading results into container
2022-11-08 11:30:53,744:INFO:Uploading model into container now
2022-11-08 11:30:53,744:INFO:master_model_container: 18
2022-11-08 11:30:53,744:INFO:display_container: 2
2022-11-08 11:30:53,745:INFO:DummyRegressor()
2022-11-08 11:30:53,745:INFO:create_model() successfully completed......................................
2022-11-08 11:30:53,867:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:53,867:INFO:Creating metrics dataframe
2022-11-08 11:30:53,905:INFO:Initializing create_model()
2022-11-08 11:30:53,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=LassoLars(random_state=204), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:53,907:INFO:Checking exceptions
2022-11-08 11:30:53,950:INFO:Importing libraries
2022-11-08 11:30:53,950:INFO:Copying training dataset
2022-11-08 11:30:53,950:INFO:Defining folds
2022-11-08 11:30:53,950:INFO:Declaring metric variables
2022-11-08 11:30:53,950:INFO:Importing untrained model
2022-11-08 11:30:53,950:INFO:Declaring custom model
2022-11-08 11:30:53,955:INFO:Least Angle Regression Imported successfully
2022-11-08 11:30:53,955:INFO:Cross validation set to False
2022-11-08 11:30:53,955:INFO:Fitting Model
2022-11-08 11:30:54,056:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:54,057:INFO:LassoLars(random_state=204)
2022-11-08 11:30:54,057:INFO:create_model() successfully completed......................................
2022-11-08 11:30:54,190:INFO:Initializing create_model()
2022-11-08 11:30:54,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:54,190:INFO:Checking exceptions
2022-11-08 11:30:54,197:INFO:Importing libraries
2022-11-08 11:30:54,198:INFO:Copying training dataset
2022-11-08 11:30:54,198:INFO:Defining folds
2022-11-08 11:30:54,198:INFO:Declaring metric variables
2022-11-08 11:30:54,198:INFO:Importing untrained model
2022-11-08 11:30:54,198:INFO:Declaring custom model
2022-11-08 11:30:54,198:INFO:Dummy Regressor Imported successfully
2022-11-08 11:30:54,198:INFO:Cross validation set to False
2022-11-08 11:30:54,198:INFO:Fitting Model
2022-11-08 11:30:54,220:INFO:DummyRegressor()
2022-11-08 11:30:54,220:INFO:create_model() successfully completed......................................
2022-11-08 11:30:54,353:INFO:Initializing create_model()
2022-11-08 11:30:54,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:54,353:INFO:Checking exceptions
2022-11-08 11:30:54,359:INFO:Importing libraries
2022-11-08 11:30:54,360:INFO:Copying training dataset
2022-11-08 11:30:54,362:INFO:Defining folds
2022-11-08 11:30:54,362:INFO:Declaring metric variables
2022-11-08 11:30:54,362:INFO:Importing untrained model
2022-11-08 11:30:54,362:INFO:Declaring custom model
2022-11-08 11:30:54,365:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:30:54,365:INFO:Cross validation set to False
2022-11-08 11:30:54,365:INFO:Fitting Model
2022-11-08 11:30:54,377:INFO:BayesianRidge()
2022-11-08 11:30:54,377:INFO:create_model() successfully completed......................................
2022-11-08 11:30:54,604:INFO:master_model_container: 18
2022-11-08 11:30:54,604:INFO:display_container: 2
2022-11-08 11:30:54,605:INFO:[LassoLars(random_state=204), DummyRegressor(), BayesianRidge()]
2022-11-08 11:30:54,606:INFO:compare_models() successfully completed......................................
2022-11-08 11:30:54,800:INFO:Initializing create_model()
2022-11-08 11:30:54,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:54,801:INFO:Checking exceptions
2022-11-08 11:30:54,864:INFO:Importing libraries
2022-11-08 11:30:54,865:INFO:Copying training dataset
2022-11-08 11:30:54,870:INFO:Defining folds
2022-11-08 11:30:54,871:INFO:Declaring metric variables
2022-11-08 11:30:54,875:INFO:Importing untrained model
2022-11-08 11:30:54,884:INFO:Huber Regressor Imported successfully
2022-11-08 11:30:54,897:INFO:Starting cross validation
2022-11-08 11:30:54,898:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:55,185:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,190:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,195:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,219:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,587:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,600:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,608:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,614:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,086:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,095:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,137:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,433:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,455:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,483:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,523:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,840:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,854:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,908:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:57,063:INFO:Calculating mean and std
2022-11-08 11:30:57,066:INFO:Creating metrics dataframe
2022-11-08 11:30:57,071:INFO:Finalizing model
2022-11-08 11:30:57,129:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:57,135:INFO:Uploading results into container
2022-11-08 11:30:57,136:INFO:Uploading model into container now
2022-11-08 11:30:57,157:INFO:master_model_container: 19
2022-11-08 11:30:57,157:INFO:display_container: 3
2022-11-08 11:30:57,158:INFO:HuberRegressor()
2022-11-08 11:30:57,158:INFO:create_model() successfully completed......................................
2022-11-08 11:30:57,413:INFO:Initializing plot_model()
2022-11-08 11:30:57,414:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:30:57,414:INFO:Checking exceptions
2022-11-08 11:30:57,418:INFO:Preloading libraries
2022-11-08 11:30:57,420:INFO:Copying training dataset
2022-11-08 11:30:57,420:INFO:Plot type: residuals
2022-11-08 11:30:57,519:INFO:Fitting Model
2022-11-08 11:30:57,519:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:30:57,579:INFO:Scoring test/hold-out set
2022-11-08 11:30:58,095:INFO:Visual Rendered Successfully
2022-11-08 11:30:58,249:INFO:plot_model() successfully completed......................................
2022-11-08 11:31:26,927:INFO:Initializing create_model()
2022-11-08 11:31:26,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:31:26,927:INFO:Checking exceptions
2022-11-08 11:31:26,987:INFO:Importing libraries
2022-11-08 11:31:26,987:INFO:Copying training dataset
2022-11-08 11:31:26,997:INFO:Defining folds
2022-11-08 11:31:26,997:INFO:Declaring metric variables
2022-11-08 11:31:27,002:INFO:Importing untrained model
2022-11-08 11:31:27,008:INFO:Huber Regressor Imported successfully
2022-11-08 11:31:27,024:INFO:Starting cross validation
2022-11-08 11:31:27,026:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:31:27,221:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,223:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,247:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,275:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,463:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,474:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,493:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,619:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,771:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,797:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,873:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,905:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,986:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,016:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,098:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,137:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,193:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,261:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,277:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,300:INFO:Calculating mean and std
2022-11-08 11:31:28,301:INFO:Creating metrics dataframe
2022-11-08 11:31:28,309:INFO:Finalizing model
2022-11-08 11:31:28,369:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,376:INFO:Uploading results into container
2022-11-08 11:31:28,378:INFO:Uploading model into container now
2022-11-08 11:31:28,396:INFO:master_model_container: 20
2022-11-08 11:31:28,396:INFO:display_container: 4
2022-11-08 11:31:28,397:INFO:HuberRegressor()
2022-11-08 11:31:28,397:INFO:create_model() successfully completed......................................
2022-11-08 11:31:47,230:INFO:Initializing plot_model()
2022-11-08 11:31:47,230:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:31:47,230:INFO:Checking exceptions
2022-11-08 11:31:47,237:INFO:Preloading libraries
2022-11-08 11:31:47,237:INFO:Copying training dataset
2022-11-08 11:31:47,238:INFO:Plot type: residuals
2022-11-08 11:31:47,335:INFO:Fitting Model
2022-11-08 11:31:47,335:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:31:47,377:INFO:Scoring test/hold-out set
2022-11-08 11:31:48,341:INFO:Visual Rendered Successfully
2022-11-08 11:31:48,497:INFO:plot_model() successfully completed......................................
2022-11-08 11:31:54,928:INFO:Initializing plot_model()
2022-11-08 11:31:54,929:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:31:54,929:INFO:Checking exceptions
2022-11-08 11:31:54,936:INFO:Preloading libraries
2022-11-08 11:31:54,937:INFO:Copying training dataset
2022-11-08 11:31:54,937:INFO:Plot type: residuals
2022-11-08 11:31:55,046:INFO:Fitting Model
2022-11-08 11:31:55,046:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:31:55,087:INFO:Scoring test/hold-out set
2022-11-08 11:31:55,539:INFO:Visual Rendered Successfully
2022-11-08 11:31:55,688:INFO:plot_model() successfully completed......................................
2022-11-08 11:32:01,518:INFO:Initializing plot_model()
2022-11-08 11:32:01,518:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:32:01,518:INFO:Checking exceptions
2022-11-08 11:32:01,525:INFO:Preloading libraries
2022-11-08 11:32:01,525:INFO:Copying training dataset
2022-11-08 11:32:01,525:INFO:Plot type: residuals
2022-11-08 11:32:01,637:INFO:Fitting Model
2022-11-08 11:32:01,643:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:32:01,687:INFO:Scoring test/hold-out set
2022-11-08 11:32:02,137:INFO:Visual Rendered Successfully
2022-11-08 11:32:02,281:INFO:plot_model() successfully completed......................................
2022-11-08 11:33:40,757:INFO:Initializing plot_model()
2022-11-08 11:33:40,757:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:33:40,757:INFO:Checking exceptions
2022-11-08 11:33:40,760:INFO:Preloading libraries
2022-11-08 11:33:40,765:INFO:Copying training dataset
2022-11-08 11:33:40,765:INFO:Plot type: vc
2022-11-08 11:33:40,765:INFO:Determining param_name
2022-11-08 11:33:40,765:INFO:param_name: alpha
2022-11-08 11:33:40,872:INFO:Fitting Model
2022-11-08 11:33:41,090:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,099:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,117:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,153:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,236:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,257:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,270:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,270:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,379:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,399:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,399:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,399:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,520:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,545:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,552:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,565:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,651:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,666:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,671:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,681:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,785:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,826:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,826:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,831:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,925:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,950:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,006:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,007:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,040:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,097:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,115:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,133:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,155:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,170:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,185:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,200:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,216:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,241:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,256:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,266:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,276:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,306:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,318:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,328:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,349:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,370:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,378:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,397:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,415:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,436:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,448:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,458:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,478:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,498:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,511:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,518:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,538:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,569:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,569:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,580:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,599:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,630:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,638:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,650:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,665:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,698:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,705:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,729:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,761:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,771:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,785:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,795:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,827:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,840:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,852:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,852:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,886:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,901:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,913:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,921:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,964:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,972:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,985:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,012:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,045:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,073:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,090:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,095:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,107:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,136:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,150:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,154:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,167:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,205:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,215:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,218:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,397:INFO:Visual Rendered Successfully
2022-11-08 11:33:43,529:INFO:plot_model() successfully completed......................................
2022-11-08 11:34:24,000:INFO:Initializing plot_model()
2022-11-08 11:34:24,001:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:34:24,001:INFO:Checking exceptions
2022-11-08 11:34:24,009:INFO:Preloading libraries
2022-11-08 11:34:24,010:INFO:Copying training dataset
2022-11-08 11:34:24,010:INFO:Plot type: error
2022-11-08 11:34:24,080:INFO:Fitting Model
2022-11-08 11:34:24,080:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:34:24,080:INFO:Scoring test/hold-out set
2022-11-08 11:34:24,491:INFO:Visual Rendered Successfully
2022-11-08 11:34:24,638:INFO:plot_model() successfully completed......................................
2022-11-08 11:35:55,849:INFO:PyCaret ClassificationExperiment
2022-11-08 11:35:55,849:INFO:Logging name: clf-default-name
2022-11-08 11:35:55,851:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-08 11:35:55,851:INFO:version 3.0.0.rc4
2022-11-08 11:35:55,851:INFO:Initializing setup()
2022-11-08 11:35:55,851:INFO:self.USI: e41e
2022-11-08 11:35:55,851:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'master_model_container', 'y_test', '_is_multiclass', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', 'fix_imbalance', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:35:55,851:INFO:Checking environment
2022-11-08 11:35:55,851:INFO:python_version: 3.10.4
2022-11-08 11:35:55,851:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:35:55,851:INFO:machine: AMD64
2022-11-08 11:35:55,852:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:35:55,852:INFO:Memory: svmem(total=8503136256, available=1455661056, percent=82.9, used=7047475200, free=1455661056)
2022-11-08 11:35:55,852:INFO:Physical Core: 2
2022-11-08 11:35:55,852:INFO:Logical Core: 4
2022-11-08 11:35:55,852:INFO:Checking libraries
2022-11-08 11:35:55,852:INFO:System:
2022-11-08 11:35:55,852:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:35:55,852:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:35:55,852:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:35:55,852:INFO:PyCaret required dependencies:
2022-11-08 11:35:55,852:INFO:                 pip: 22.2.2
2022-11-08 11:35:55,853:INFO:          setuptools: 58.1.0
2022-11-08 11:35:55,853:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:35:55,853:INFO:             IPython: 8.4.0
2022-11-08 11:35:55,853:INFO:          ipywidgets: 8.0.2
2022-11-08 11:35:55,853:INFO:                tqdm: 4.64.0
2022-11-08 11:35:55,853:INFO:               numpy: 1.22.3
2022-11-08 11:35:55,853:INFO:              pandas: 1.4.2
2022-11-08 11:35:55,853:INFO:              jinja2: 3.1.2
2022-11-08 11:35:55,853:INFO:               scipy: 1.8.1
2022-11-08 11:35:55,853:INFO:              joblib: 1.2.0
2022-11-08 11:35:55,853:INFO:             sklearn: 1.1.2
2022-11-08 11:35:55,853:INFO:                pyod: 1.0.6
2022-11-08 11:35:55,853:INFO:            imblearn: 0.9.1
2022-11-08 11:35:55,853:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:35:55,853:INFO:            lightgbm: 3.3.3
2022-11-08 11:35:55,853:INFO:               numba: 0.55.2
2022-11-08 11:35:55,853:INFO:            requests: 2.28.1
2022-11-08 11:35:55,853:INFO:          matplotlib: 3.5.1
2022-11-08 11:35:55,854:INFO:          scikitplot: 0.3.7
2022-11-08 11:35:55,854:INFO:         yellowbrick: 1.5
2022-11-08 11:35:55,854:INFO:              plotly: 5.11.0
2022-11-08 11:35:55,854:INFO:             kaleido: 0.2.1
2022-11-08 11:35:55,854:INFO:         statsmodels: 0.13.5
2022-11-08 11:35:55,854:INFO:              sktime: 0.13.4
2022-11-08 11:35:55,854:INFO:               tbats: 1.1.1
2022-11-08 11:35:55,854:INFO:            pmdarima: 1.8.5
2022-11-08 11:35:55,854:INFO:              psutil: 5.9.1
2022-11-08 11:35:55,854:INFO:PyCaret optional dependencies:
2022-11-08 11:35:55,854:INFO:                shap: Not installed
2022-11-08 11:35:55,854:INFO:           interpret: Not installed
2022-11-08 11:35:55,854:INFO:                umap: Not installed
2022-11-08 11:35:55,854:INFO:    pandas_profiling: Not installed
2022-11-08 11:35:55,855:INFO:  explainerdashboard: Not installed
2022-11-08 11:35:55,855:INFO:             autoviz: Not installed
2022-11-08 11:35:55,855:INFO:           fairlearn: Not installed
2022-11-08 11:35:55,855:INFO:             xgboost: Not installed
2022-11-08 11:35:55,855:INFO:            catboost: Not installed
2022-11-08 11:35:55,855:INFO:              kmodes: Not installed
2022-11-08 11:35:55,855:INFO:             mlxtend: Not installed
2022-11-08 11:35:55,855:INFO:       statsforecast: Not installed
2022-11-08 11:35:55,856:INFO:        tune_sklearn: Not installed
2022-11-08 11:35:55,856:INFO:                 ray: Not installed
2022-11-08 11:35:55,856:INFO:            hyperopt: Not installed
2022-11-08 11:35:55,856:INFO:              optuna: Not installed
2022-11-08 11:35:55,856:INFO:               skopt: Not installed
2022-11-08 11:35:55,856:INFO:              mlflow: Not installed
2022-11-08 11:35:55,856:INFO:              gradio: Not installed
2022-11-08 11:35:55,856:INFO:             fastapi: Not installed
2022-11-08 11:35:55,856:INFO:             uvicorn: Not installed
2022-11-08 11:35:55,856:INFO:              m2cgen: Not installed
2022-11-08 11:35:55,857:INFO:           evidently: Not installed
2022-11-08 11:35:55,857:INFO:                nltk: 3.7
2022-11-08 11:35:55,857:INFO:            pyLDAvis: Not installed
2022-11-08 11:35:55,857:INFO:              gensim: Not installed
2022-11-08 11:35:55,857:INFO:               spacy: Not installed
2022-11-08 11:35:55,857:INFO:           wordcloud: Not installed
2022-11-08 11:35:55,857:INFO:            textblob: Not installed
2022-11-08 11:35:55,857:INFO:               fugue: Not installed
2022-11-08 11:35:55,857:INFO:           streamlit: Not installed
2022-11-08 11:35:55,857:INFO:             prophet: Not installed
2022-11-08 11:35:55,857:INFO:None
2022-11-08 11:35:55,857:INFO:Set up data.
2022-11-08 11:35:55,867:INFO:Set up train/test split.
2022-11-08 11:35:55,877:INFO:Set up index.
2022-11-08 11:35:55,877:INFO:Assigning column types.
2022-11-08 11:35:55,882:INFO:Set up folding strategy.
2022-11-08 11:35:55,884:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:35:55,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:35:55,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,179:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:35:56,412:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:57,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,005:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-11-08 11:35:57,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,616:INFO:Preparing preprocessing pipeline...
2022-11-08 11:35:57,620:INFO:Set up simple imputation.
2022-11-08 11:35:57,621:INFO:Set up variance threshold.
2022-11-08 11:35:57,698:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:35:57,698:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-11-08 11:35:57,698:INFO:Creating final display dataframe.
2022-11-08 11:35:58,181:INFO:Setup display_container:                     Description             Value
0                    Session id              5092
1                        Target              area
2                   Target type            Binary
3           Original data shape          (517, 9)
4        Transformed data shape          (517, 9)
5   Transformed train set shape          (361, 9)
6    Transformed test set shape          (156, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation          constant
12       Low variance threshold                 0
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              e41e
2022-11-08 11:35:58,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,436:INFO:setup() successfully completed in 2.59s...............
2022-11-08 11:36:15,112:INFO:Initializing compare_models()
2022-11-08 11:36:15,113:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-11-08 11:36:15,113:INFO:Checking exceptions
2022-11-08 11:36:15,119:INFO:Preparing display monitor
2022-11-08 11:36:15,186:INFO:Initializing Logistic Regression
2022-11-08 11:36:15,186:INFO:Total runtime is 0.0 minutes
2022-11-08 11:36:15,191:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:15,192:INFO:Initializing create_model()
2022-11-08 11:36:15,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:15,193:INFO:Checking exceptions
2022-11-08 11:36:15,196:INFO:Importing libraries
2022-11-08 11:36:15,197:INFO:Copying training dataset
2022-11-08 11:36:15,203:INFO:Defining folds
2022-11-08 11:36:15,203:INFO:Declaring metric variables
2022-11-08 11:36:15,211:INFO:Importing untrained model
2022-11-08 11:36:15,218:INFO:Logistic Regression Imported successfully
2022-11-08 11:36:15,235:INFO:Starting cross validation
2022-11-08 11:36:15,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:17,190:INFO:Calculating mean and std
2022-11-08 11:36:17,197:INFO:Creating metrics dataframe
2022-11-08 11:36:17,199:INFO:Uploading results into container
2022-11-08 11:36:17,199:INFO:Uploading model into container now
2022-11-08 11:36:17,199:INFO:master_model_container: 1
2022-11-08 11:36:17,199:INFO:display_container: 2
2022-11-08 11:36:17,199:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5092, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-11-08 11:36:17,199:INFO:create_model() successfully completed......................................
2022-11-08 11:36:17,346:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:17,347:INFO:Creating metrics dataframe
2022-11-08 11:36:17,361:INFO:Initializing K Neighbors Classifier
2022-11-08 11:36:17,362:INFO:Total runtime is 0.03626526991526286 minutes
2022-11-08 11:36:17,367:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:17,367:INFO:Initializing create_model()
2022-11-08 11:36:17,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:17,368:INFO:Checking exceptions
2022-11-08 11:36:17,369:INFO:Importing libraries
2022-11-08 11:36:17,369:INFO:Copying training dataset
2022-11-08 11:36:17,380:INFO:Defining folds
2022-11-08 11:36:17,381:INFO:Declaring metric variables
2022-11-08 11:36:17,392:INFO:Importing untrained model
2022-11-08 11:36:17,401:INFO:K Neighbors Classifier Imported successfully
2022-11-08 11:36:17,429:INFO:Starting cross validation
2022-11-08 11:36:17,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:17,842:INFO:Calculating mean and std
2022-11-08 11:36:17,845:INFO:Creating metrics dataframe
2022-11-08 11:36:17,850:INFO:Uploading results into container
2022-11-08 11:36:17,850:INFO:Uploading model into container now
2022-11-08 11:36:17,851:INFO:master_model_container: 2
2022-11-08 11:36:17,851:INFO:display_container: 2
2022-11-08 11:36:17,851:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-11-08 11:36:17,851:INFO:create_model() successfully completed......................................
2022-11-08 11:36:17,985:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:17,985:INFO:Creating metrics dataframe
2022-11-08 11:36:18,001:INFO:Initializing Naive Bayes
2022-11-08 11:36:18,001:INFO:Total runtime is 0.046926466623942065 minutes
2022-11-08 11:36:18,006:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:18,008:INFO:Initializing create_model()
2022-11-08 11:36:18,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:18,010:INFO:Checking exceptions
2022-11-08 11:36:18,012:INFO:Importing libraries
2022-11-08 11:36:18,013:INFO:Copying training dataset
2022-11-08 11:36:18,018:INFO:Defining folds
2022-11-08 11:36:18,018:INFO:Declaring metric variables
2022-11-08 11:36:18,023:INFO:Importing untrained model
2022-11-08 11:36:18,032:INFO:Naive Bayes Imported successfully
2022-11-08 11:36:18,050:INFO:Starting cross validation
2022-11-08 11:36:18,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:18,302:INFO:Calculating mean and std
2022-11-08 11:36:18,304:INFO:Creating metrics dataframe
2022-11-08 11:36:18,313:INFO:Uploading results into container
2022-11-08 11:36:18,313:INFO:Uploading model into container now
2022-11-08 11:36:18,314:INFO:master_model_container: 3
2022-11-08 11:36:18,314:INFO:display_container: 2
2022-11-08 11:36:18,314:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-11-08 11:36:18,314:INFO:create_model() successfully completed......................................
2022-11-08 11:36:18,446:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:18,446:INFO:Creating metrics dataframe
2022-11-08 11:36:18,461:INFO:Initializing Decision Tree Classifier
2022-11-08 11:36:18,462:INFO:Total runtime is 0.05460441907246908 minutes
2022-11-08 11:36:18,468:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:18,469:INFO:Initializing create_model()
2022-11-08 11:36:18,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:18,469:INFO:Checking exceptions
2022-11-08 11:36:18,471:INFO:Importing libraries
2022-11-08 11:36:18,471:INFO:Copying training dataset
2022-11-08 11:36:18,480:INFO:Defining folds
2022-11-08 11:36:18,480:INFO:Declaring metric variables
2022-11-08 11:36:18,488:INFO:Importing untrained model
2022-11-08 11:36:18,499:INFO:Decision Tree Classifier Imported successfully
2022-11-08 11:36:18,517:INFO:Starting cross validation
2022-11-08 11:36:18,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:18,756:INFO:Calculating mean and std
2022-11-08 11:36:18,759:INFO:Creating metrics dataframe
2022-11-08 11:36:18,763:INFO:Uploading results into container
2022-11-08 11:36:18,764:INFO:Uploading model into container now
2022-11-08 11:36:18,765:INFO:master_model_container: 4
2022-11-08 11:36:18,765:INFO:display_container: 2
2022-11-08 11:36:18,766:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5092, splitter='best')
2022-11-08 11:36:18,767:INFO:create_model() successfully completed......................................
2022-11-08 11:36:18,887:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:18,887:INFO:Creating metrics dataframe
2022-11-08 11:36:18,903:INFO:Initializing SVM - Linear Kernel
2022-11-08 11:36:18,904:INFO:Total runtime is 0.06196676095326742 minutes
2022-11-08 11:36:18,909:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:18,910:INFO:Initializing create_model()
2022-11-08 11:36:18,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:18,910:INFO:Checking exceptions
2022-11-08 11:36:18,913:INFO:Importing libraries
2022-11-08 11:36:18,913:INFO:Copying training dataset
2022-11-08 11:36:18,917:INFO:Defining folds
2022-11-08 11:36:18,917:INFO:Declaring metric variables
2022-11-08 11:36:18,926:INFO:Importing untrained model
2022-11-08 11:36:18,934:INFO:SVM - Linear Kernel Imported successfully
2022-11-08 11:36:18,955:INFO:Starting cross validation
2022-11-08 11:36:18,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:19,096:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-11-08 11:36:19,153:INFO:Calculating mean and std
2022-11-08 11:36:19,154:INFO:Creating metrics dataframe
2022-11-08 11:36:19,156:INFO:Uploading results into container
2022-11-08 11:36:19,156:INFO:Uploading model into container now
2022-11-08 11:36:19,156:INFO:master_model_container: 5
2022-11-08 11:36:19,156:INFO:display_container: 2
2022-11-08 11:36:19,156:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5092, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-08 11:36:19,156:INFO:create_model() successfully completed......................................
2022-11-08 11:36:19,284:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:19,284:INFO:Creating metrics dataframe
2022-11-08 11:36:19,299:INFO:Initializing Ridge Classifier
2022-11-08 11:36:19,299:INFO:Total runtime is 0.06855111519495646 minutes
2022-11-08 11:36:19,305:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:19,306:INFO:Initializing create_model()
2022-11-08 11:36:19,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:19,306:INFO:Checking exceptions
2022-11-08 11:36:19,306:INFO:Importing libraries
2022-11-08 11:36:19,306:INFO:Copying training dataset
2022-11-08 11:36:19,314:INFO:Defining folds
2022-11-08 11:36:19,314:INFO:Declaring metric variables
2022-11-08 11:36:19,320:INFO:Importing untrained model
2022-11-08 11:36:19,329:INFO:Ridge Classifier Imported successfully
2022-11-08 11:36:19,343:INFO:Starting cross validation
2022-11-08 11:36:19,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:19,544:INFO:Calculating mean and std
2022-11-08 11:36:19,546:INFO:Creating metrics dataframe
2022-11-08 11:36:19,550:INFO:Uploading results into container
2022-11-08 11:36:19,550:INFO:Uploading model into container now
2022-11-08 11:36:19,551:INFO:master_model_container: 6
2022-11-08 11:36:19,551:INFO:display_container: 2
2022-11-08 11:36:19,551:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5092, solver='auto', tol=0.001)
2022-11-08 11:36:19,551:INFO:create_model() successfully completed......................................
2022-11-08 11:36:19,682:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:19,682:INFO:Creating metrics dataframe
2022-11-08 11:36:19,710:INFO:Initializing Random Forest Classifier
2022-11-08 11:36:19,710:INFO:Total runtime is 0.0754038135210673 minutes
2022-11-08 11:36:19,717:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:19,718:INFO:Initializing create_model()
2022-11-08 11:36:19,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:19,718:INFO:Checking exceptions
2022-11-08 11:36:19,719:INFO:Importing libraries
2022-11-08 11:36:19,719:INFO:Copying training dataset
2022-11-08 11:36:19,728:INFO:Defining folds
2022-11-08 11:36:19,729:INFO:Declaring metric variables
2022-11-08 11:36:19,737:INFO:Importing untrained model
2022-11-08 11:36:19,746:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:36:19,760:INFO:Starting cross validation
2022-11-08 11:36:19,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:21,147:INFO:Calculating mean and std
2022-11-08 11:36:21,148:INFO:Creating metrics dataframe
2022-11-08 11:36:21,152:INFO:Uploading results into container
2022-11-08 11:36:21,153:INFO:Uploading model into container now
2022-11-08 11:36:21,153:INFO:master_model_container: 7
2022-11-08 11:36:21,153:INFO:display_container: 2
2022-11-08 11:36:21,156:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:21,156:INFO:create_model() successfully completed......................................
2022-11-08 11:36:21,277:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:21,277:INFO:Creating metrics dataframe
2022-11-08 11:36:21,294:INFO:Initializing Quadratic Discriminant Analysis
2022-11-08 11:36:21,294:INFO:Total runtime is 0.10180829763412476 minutes
2022-11-08 11:36:21,300:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:21,301:INFO:Initializing create_model()
2022-11-08 11:36:21,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:21,301:INFO:Checking exceptions
2022-11-08 11:36:21,303:INFO:Importing libraries
2022-11-08 11:36:21,303:INFO:Copying training dataset
2022-11-08 11:36:21,309:INFO:Defining folds
2022-11-08 11:36:21,309:INFO:Declaring metric variables
2022-11-08 11:36:21,318:INFO:Importing untrained model
2022-11-08 11:36:21,325:INFO:Quadratic Discriminant Analysis Imported successfully
2022-11-08 11:36:21,341:INFO:Starting cross validation
2022-11-08 11:36:21,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:21,416:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-11-08 11:36:21,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:36:21,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:36:21,586:INFO:Calculating mean and std
2022-11-08 11:36:21,589:INFO:Creating metrics dataframe
2022-11-08 11:36:21,593:INFO:Uploading results into container
2022-11-08 11:36:21,593:INFO:Uploading model into container now
2022-11-08 11:36:21,594:INFO:master_model_container: 8
2022-11-08 11:36:21,594:INFO:display_container: 2
2022-11-08 11:36:21,594:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-11-08 11:36:21,595:INFO:create_model() successfully completed......................................
2022-11-08 11:36:21,716:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:21,716:INFO:Creating metrics dataframe
2022-11-08 11:36:21,735:INFO:Initializing Ada Boost Classifier
2022-11-08 11:36:21,735:INFO:Total runtime is 0.10916291475296021 minutes
2022-11-08 11:36:21,741:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:21,742:INFO:Initializing create_model()
2022-11-08 11:36:21,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:21,742:INFO:Checking exceptions
2022-11-08 11:36:21,745:INFO:Importing libraries
2022-11-08 11:36:21,746:INFO:Copying training dataset
2022-11-08 11:36:21,750:INFO:Defining folds
2022-11-08 11:36:21,750:INFO:Declaring metric variables
2022-11-08 11:36:21,756:INFO:Importing untrained model
2022-11-08 11:36:21,764:INFO:Ada Boost Classifier Imported successfully
2022-11-08 11:36:21,779:INFO:Starting cross validation
2022-11-08 11:36:21,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:22,458:INFO:Calculating mean and std
2022-11-08 11:36:22,460:INFO:Creating metrics dataframe
2022-11-08 11:36:22,464:INFO:Uploading results into container
2022-11-08 11:36:22,464:INFO:Uploading model into container now
2022-11-08 11:36:22,465:INFO:master_model_container: 9
2022-11-08 11:36:22,465:INFO:display_container: 2
2022-11-08 11:36:22,465:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092)
2022-11-08 11:36:22,465:INFO:create_model() successfully completed......................................
2022-11-08 11:36:22,588:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:22,588:INFO:Creating metrics dataframe
2022-11-08 11:36:22,608:INFO:Initializing Gradient Boosting Classifier
2022-11-08 11:36:22,608:INFO:Total runtime is 0.12370062271753947 minutes
2022-11-08 11:36:22,613:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:22,613:INFO:Initializing create_model()
2022-11-08 11:36:22,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:22,614:INFO:Checking exceptions
2022-11-08 11:36:22,617:INFO:Importing libraries
2022-11-08 11:36:22,617:INFO:Copying training dataset
2022-11-08 11:36:22,623:INFO:Defining folds
2022-11-08 11:36:22,623:INFO:Declaring metric variables
2022-11-08 11:36:22,626:INFO:Importing untrained model
2022-11-08 11:36:22,634:INFO:Gradient Boosting Classifier Imported successfully
2022-11-08 11:36:22,648:INFO:Starting cross validation
2022-11-08 11:36:22,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:23,413:INFO:Calculating mean and std
2022-11-08 11:36:23,415:INFO:Creating metrics dataframe
2022-11-08 11:36:23,421:INFO:Uploading results into container
2022-11-08 11:36:23,421:INFO:Uploading model into container now
2022-11-08 11:36:23,422:INFO:master_model_container: 10
2022-11-08 11:36:23,422:INFO:display_container: 2
2022-11-08 11:36:23,424:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5092, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-08 11:36:23,424:INFO:create_model() successfully completed......................................
2022-11-08 11:36:23,558:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:23,558:INFO:Creating metrics dataframe
2022-11-08 11:36:23,575:INFO:Initializing Linear Discriminant Analysis
2022-11-08 11:36:23,575:INFO:Total runtime is 0.1398259401321411 minutes
2022-11-08 11:36:23,579:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:23,580:INFO:Initializing create_model()
2022-11-08 11:36:23,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:23,582:INFO:Checking exceptions
2022-11-08 11:36:23,584:INFO:Importing libraries
2022-11-08 11:36:23,585:INFO:Copying training dataset
2022-11-08 11:36:23,590:INFO:Defining folds
2022-11-08 11:36:23,590:INFO:Declaring metric variables
2022-11-08 11:36:23,596:INFO:Importing untrained model
2022-11-08 11:36:23,604:INFO:Linear Discriminant Analysis Imported successfully
2022-11-08 11:36:23,620:INFO:Starting cross validation
2022-11-08 11:36:23,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:23,892:INFO:Calculating mean and std
2022-11-08 11:36:23,894:INFO:Creating metrics dataframe
2022-11-08 11:36:23,898:INFO:Uploading results into container
2022-11-08 11:36:23,898:INFO:Uploading model into container now
2022-11-08 11:36:23,899:INFO:master_model_container: 11
2022-11-08 11:36:23,899:INFO:display_container: 2
2022-11-08 11:36:23,899:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-11-08 11:36:23,899:INFO:create_model() successfully completed......................................
2022-11-08 11:36:24,025:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:24,025:INFO:Creating metrics dataframe
2022-11-08 11:36:24,044:INFO:Initializing Extra Trees Classifier
2022-11-08 11:36:24,045:INFO:Total runtime is 0.1476488471031189 minutes
2022-11-08 11:36:24,051:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:24,051:INFO:Initializing create_model()
2022-11-08 11:36:24,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:24,052:INFO:Checking exceptions
2022-11-08 11:36:24,054:INFO:Importing libraries
2022-11-08 11:36:24,054:INFO:Copying training dataset
2022-11-08 11:36:24,059:INFO:Defining folds
2022-11-08 11:36:24,059:INFO:Declaring metric variables
2022-11-08 11:36:24,064:INFO:Importing untrained model
2022-11-08 11:36:24,073:INFO:Extra Trees Classifier Imported successfully
2022-11-08 11:36:24,090:INFO:Starting cross validation
2022-11-08 11:36:24,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:25,414:INFO:Calculating mean and std
2022-11-08 11:36:25,417:INFO:Creating metrics dataframe
2022-11-08 11:36:25,422:INFO:Uploading results into container
2022-11-08 11:36:25,424:INFO:Uploading model into container now
2022-11-08 11:36:25,425:INFO:master_model_container: 12
2022-11-08 11:36:25,425:INFO:display_container: 2
2022-11-08 11:36:25,425:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:25,425:INFO:create_model() successfully completed......................................
2022-11-08 11:36:25,551:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:25,552:INFO:Creating metrics dataframe
2022-11-08 11:36:25,569:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:36:25,569:INFO:Total runtime is 0.17306079069773356 minutes
2022-11-08 11:36:25,575:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:25,576:INFO:Initializing create_model()
2022-11-08 11:36:25,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:25,577:INFO:Checking exceptions
2022-11-08 11:36:25,578:INFO:Importing libraries
2022-11-08 11:36:25,578:INFO:Copying training dataset
2022-11-08 11:36:25,585:INFO:Defining folds
2022-11-08 11:36:25,585:INFO:Declaring metric variables
2022-11-08 11:36:25,593:INFO:Importing untrained model
2022-11-08 11:36:25,601:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:36:25,615:INFO:Starting cross validation
2022-11-08 11:36:25,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:25,984:INFO:Calculating mean and std
2022-11-08 11:36:25,987:INFO:Creating metrics dataframe
2022-11-08 11:36:25,990:INFO:Uploading results into container
2022-11-08 11:36:25,990:INFO:Uploading model into container now
2022-11-08 11:36:25,991:INFO:master_model_container: 13
2022-11-08 11:36:25,991:INFO:display_container: 2
2022-11-08 11:36:25,991:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5092, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-08 11:36:25,991:INFO:create_model() successfully completed......................................
2022-11-08 11:36:26,114:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:26,114:INFO:Creating metrics dataframe
2022-11-08 11:36:26,134:INFO:Initializing Dummy Classifier
2022-11-08 11:36:26,135:INFO:Total runtime is 0.18249115943908692 minutes
2022-11-08 11:36:26,141:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:26,142:INFO:Initializing create_model()
2022-11-08 11:36:26,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:26,142:INFO:Checking exceptions
2022-11-08 11:36:26,144:INFO:Importing libraries
2022-11-08 11:36:26,145:INFO:Copying training dataset
2022-11-08 11:36:26,151:INFO:Defining folds
2022-11-08 11:36:26,152:INFO:Declaring metric variables
2022-11-08 11:36:26,159:INFO:Importing untrained model
2022-11-08 11:36:26,167:INFO:Dummy Classifier Imported successfully
2022-11-08 11:36:26,178:INFO:Starting cross validation
2022-11-08 11:36:26,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:26,421:INFO:Calculating mean and std
2022-11-08 11:36:26,423:INFO:Creating metrics dataframe
2022-11-08 11:36:26,427:INFO:Uploading results into container
2022-11-08 11:36:26,428:INFO:Uploading model into container now
2022-11-08 11:36:26,428:INFO:master_model_container: 14
2022-11-08 11:36:26,428:INFO:display_container: 2
2022-11-08 11:36:26,428:INFO:DummyClassifier(constant=None, random_state=5092, strategy='prior')
2022-11-08 11:36:26,428:INFO:create_model() successfully completed......................................
2022-11-08 11:36:26,551:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:26,552:INFO:Creating metrics dataframe
2022-11-08 11:36:26,590:INFO:Initializing create_model()
2022-11-08 11:36:26,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:26,590:INFO:Checking exceptions
2022-11-08 11:36:26,598:INFO:Importing libraries
2022-11-08 11:36:26,598:INFO:Copying training dataset
2022-11-08 11:36:26,601:INFO:Defining folds
2022-11-08 11:36:26,601:INFO:Declaring metric variables
2022-11-08 11:36:26,604:INFO:Importing untrained model
2022-11-08 11:36:26,604:INFO:Declaring custom model
2022-11-08 11:36:26,605:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:36:26,606:INFO:Cross validation set to False
2022-11-08 11:36:26,606:INFO:Fitting Model
2022-11-08 11:36:26,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:26,907:INFO:create_model() successfully completed......................................
2022-11-08 11:36:27,084:INFO:master_model_container: 14
2022-11-08 11:36:27,084:INFO:display_container: 2
2022-11-08 11:36:27,085:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:27,085:INFO:compare_models() successfully completed......................................
2022-11-08 11:37:01,164:INFO:Initializing create_model()
2022-11-08 11:37:01,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ada, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:37:01,166:INFO:Checking exceptions
2022-11-08 11:37:01,224:INFO:Importing libraries
2022-11-08 11:37:01,224:INFO:Copying training dataset
2022-11-08 11:37:01,230:INFO:Defining folds
2022-11-08 11:37:01,230:INFO:Declaring metric variables
2022-11-08 11:37:01,235:INFO:Importing untrained model
2022-11-08 11:37:01,248:INFO:Ada Boost Classifier Imported successfully
2022-11-08 11:37:01,264:INFO:Starting cross validation
2022-11-08 11:37:01,266:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:37:04,832:INFO:Calculating mean and std
2022-11-08 11:37:04,834:INFO:Creating metrics dataframe
2022-11-08 11:37:04,839:INFO:Finalizing model
2022-11-08 11:37:04,995:INFO:Uploading results into container
2022-11-08 11:37:04,997:INFO:Uploading model into container now
2022-11-08 11:37:05,020:INFO:master_model_container: 15
2022-11-08 11:37:05,020:INFO:display_container: 3
2022-11-08 11:37:05,022:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092)
2022-11-08 11:37:05,022:INFO:create_model() successfully completed......................................
2022-11-08 11:37:24,907:INFO:Initializing plot_model()
2022-11-08 11:37:24,907:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:37:24,907:INFO:Checking exceptions
2022-11-08 11:37:24,926:INFO:Preloading libraries
2022-11-08 11:37:24,936:INFO:Copying training dataset
2022-11-08 11:37:24,936:INFO:Plot type: auc
2022-11-08 11:37:24,997:INFO:Fitting Model
2022-11-08 11:37:24,997:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2022-11-08 11:37:24,997:INFO:Scoring test/hold-out set
2022-11-08 11:37:25,304:INFO:Visual Rendered Successfully
2022-11-08 11:37:25,516:INFO:plot_model() successfully completed......................................
2022-11-08 11:37:46,925:INFO:Initializing create_model()
2022-11-08 11:37:46,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:37:46,925:INFO:Checking exceptions
2022-11-08 11:37:46,979:INFO:Importing libraries
2022-11-08 11:37:46,979:INFO:Copying training dataset
2022-11-08 11:37:46,989:INFO:Defining folds
2022-11-08 11:37:46,989:INFO:Declaring metric variables
2022-11-08 11:37:46,994:INFO:Importing untrained model
2022-11-08 11:37:47,043:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:37:47,056:INFO:Starting cross validation
2022-11-08 11:37:47,056:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:37:50,276:INFO:Calculating mean and std
2022-11-08 11:37:50,280:INFO:Creating metrics dataframe
2022-11-08 11:37:50,289:INFO:Finalizing model
2022-11-08 11:37:50,502:INFO:Uploading results into container
2022-11-08 11:37:50,503:INFO:Uploading model into container now
2022-11-08 11:37:50,521:INFO:master_model_container: 16
2022-11-08 11:37:50,521:INFO:display_container: 4
2022-11-08 11:37:50,522:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:37:50,522:INFO:create_model() successfully completed......................................
2022-11-08 11:38:10,730:INFO:Initializing create_model()
2022-11-08 11:38:10,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:10,734:INFO:Checking exceptions
2022-11-08 11:38:10,794:INFO:Importing libraries
2022-11-08 11:38:10,794:INFO:Copying training dataset
2022-11-08 11:38:10,804:INFO:Defining folds
2022-11-08 11:38:10,804:INFO:Declaring metric variables
2022-11-08 11:38:10,811:INFO:Importing untrained model
2022-11-08 11:38:10,816:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:38:10,840:INFO:Starting cross validation
2022-11-08 11:38:10,840:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:14,135:INFO:Calculating mean and std
2022-11-08 11:38:14,137:INFO:Creating metrics dataframe
2022-11-08 11:38:14,143:INFO:Finalizing model
2022-11-08 11:38:14,386:INFO:Uploading results into container
2022-11-08 11:38:14,388:INFO:Uploading model into container now
2022-11-08 11:38:14,412:INFO:master_model_container: 17
2022-11-08 11:38:14,412:INFO:display_container: 5
2022-11-08 11:38:14,412:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:14,412:INFO:create_model() successfully completed......................................
2022-11-08 11:38:16,810:INFO:Initializing plot_model()
2022-11-08 11:38:16,810:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:38:16,814:INFO:Checking exceptions
2022-11-08 11:38:16,851:INFO:Preloading libraries
2022-11-08 11:38:16,870:INFO:Copying training dataset
2022-11-08 11:38:16,870:INFO:Plot type: auc
2022-11-08 11:38:16,956:INFO:Fitting Model
2022-11-08 11:38:16,956:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2022-11-08 11:38:16,956:INFO:Scoring test/hold-out set
2022-11-08 11:38:17,231:INFO:Visual Rendered Successfully
2022-11-08 11:38:17,400:INFO:plot_model() successfully completed......................................
2022-11-08 11:38:47,135:INFO:Initializing compare_models()
2022-11-08 11:38:47,135:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-11-08 11:38:47,136:INFO:Checking exceptions
2022-11-08 11:38:47,142:INFO:Preparing display monitor
2022-11-08 11:38:47,218:INFO:Initializing Logistic Regression
2022-11-08 11:38:47,218:INFO:Total runtime is 0.0 minutes
2022-11-08 11:38:47,228:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:47,228:INFO:Initializing create_model()
2022-11-08 11:38:47,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:47,229:INFO:Checking exceptions
2022-11-08 11:38:47,233:INFO:Importing libraries
2022-11-08 11:38:47,233:INFO:Copying training dataset
2022-11-08 11:38:47,237:INFO:Defining folds
2022-11-08 11:38:47,238:INFO:Declaring metric variables
2022-11-08 11:38:47,242:INFO:Importing untrained model
2022-11-08 11:38:47,251:INFO:Logistic Regression Imported successfully
2022-11-08 11:38:47,266:INFO:Starting cross validation
2022-11-08 11:38:47,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:47,637:INFO:Calculating mean and std
2022-11-08 11:38:47,637:INFO:Creating metrics dataframe
2022-11-08 11:38:47,638:INFO:Uploading results into container
2022-11-08 11:38:47,638:INFO:Uploading model into container now
2022-11-08 11:38:47,638:INFO:master_model_container: 18
2022-11-08 11:38:47,638:INFO:display_container: 6
2022-11-08 11:38:47,638:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5092, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-11-08 11:38:47,638:INFO:create_model() successfully completed......................................
2022-11-08 11:38:47,769:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:47,769:INFO:Creating metrics dataframe
2022-11-08 11:38:47,783:INFO:Initializing K Neighbors Classifier
2022-11-08 11:38:47,783:INFO:Total runtime is 0.009412264823913575 minutes
2022-11-08 11:38:47,788:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:47,789:INFO:Initializing create_model()
2022-11-08 11:38:47,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:47,789:INFO:Checking exceptions
2022-11-08 11:38:47,790:INFO:Importing libraries
2022-11-08 11:38:47,790:INFO:Copying training dataset
2022-11-08 11:38:47,795:INFO:Defining folds
2022-11-08 11:38:47,795:INFO:Declaring metric variables
2022-11-08 11:38:47,804:INFO:Importing untrained model
2022-11-08 11:38:47,812:INFO:K Neighbors Classifier Imported successfully
2022-11-08 11:38:47,825:INFO:Starting cross validation
2022-11-08 11:38:47,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:48,156:INFO:Calculating mean and std
2022-11-08 11:38:48,159:INFO:Creating metrics dataframe
2022-11-08 11:38:48,164:INFO:Uploading results into container
2022-11-08 11:38:48,165:INFO:Uploading model into container now
2022-11-08 11:38:48,165:INFO:master_model_container: 19
2022-11-08 11:38:48,165:INFO:display_container: 6
2022-11-08 11:38:48,165:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-11-08 11:38:48,165:INFO:create_model() successfully completed......................................
2022-11-08 11:38:48,307:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:48,308:INFO:Creating metrics dataframe
2022-11-08 11:38:48,328:INFO:Initializing Naive Bayes
2022-11-08 11:38:48,328:INFO:Total runtime is 0.018499350547790526 minutes
2022-11-08 11:38:48,337:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:48,337:INFO:Initializing create_model()
2022-11-08 11:38:48,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:48,339:INFO:Checking exceptions
2022-11-08 11:38:48,342:INFO:Importing libraries
2022-11-08 11:38:48,342:INFO:Copying training dataset
2022-11-08 11:38:48,350:INFO:Defining folds
2022-11-08 11:38:48,350:INFO:Declaring metric variables
2022-11-08 11:38:48,362:INFO:Importing untrained model
2022-11-08 11:38:48,372:INFO:Naive Bayes Imported successfully
2022-11-08 11:38:48,389:INFO:Starting cross validation
2022-11-08 11:38:48,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:48,620:INFO:Calculating mean and std
2022-11-08 11:38:48,622:INFO:Creating metrics dataframe
2022-11-08 11:38:48,627:INFO:Uploading results into container
2022-11-08 11:38:48,628:INFO:Uploading model into container now
2022-11-08 11:38:48,628:INFO:master_model_container: 20
2022-11-08 11:38:48,628:INFO:display_container: 6
2022-11-08 11:38:48,628:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-11-08 11:38:48,629:INFO:create_model() successfully completed......................................
2022-11-08 11:38:48,752:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:48,752:INFO:Creating metrics dataframe
2022-11-08 11:38:48,766:INFO:Initializing Decision Tree Classifier
2022-11-08 11:38:48,767:INFO:Total runtime is 0.02582291762034098 minutes
2022-11-08 11:38:48,773:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:48,774:INFO:Initializing create_model()
2022-11-08 11:38:48,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:48,774:INFO:Checking exceptions
2022-11-08 11:38:48,778:INFO:Importing libraries
2022-11-08 11:38:48,778:INFO:Copying training dataset
2022-11-08 11:38:48,782:INFO:Defining folds
2022-11-08 11:38:48,782:INFO:Declaring metric variables
2022-11-08 11:38:48,788:INFO:Importing untrained model
2022-11-08 11:38:48,796:INFO:Decision Tree Classifier Imported successfully
2022-11-08 11:38:48,815:INFO:Starting cross validation
2022-11-08 11:38:48,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:49,072:INFO:Calculating mean and std
2022-11-08 11:38:49,074:INFO:Creating metrics dataframe
2022-11-08 11:38:49,079:INFO:Uploading results into container
2022-11-08 11:38:49,079:INFO:Uploading model into container now
2022-11-08 11:38:49,080:INFO:master_model_container: 21
2022-11-08 11:38:49,080:INFO:display_container: 6
2022-11-08 11:38:49,080:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5092, splitter='best')
2022-11-08 11:38:49,080:INFO:create_model() successfully completed......................................
2022-11-08 11:38:49,203:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:49,204:INFO:Creating metrics dataframe
2022-11-08 11:38:49,221:INFO:Initializing SVM - Linear Kernel
2022-11-08 11:38:49,223:INFO:Total runtime is 0.033409122625986734 minutes
2022-11-08 11:38:49,230:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:49,230:INFO:Initializing create_model()
2022-11-08 11:38:49,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:49,230:INFO:Checking exceptions
2022-11-08 11:38:49,234:INFO:Importing libraries
2022-11-08 11:38:49,234:INFO:Copying training dataset
2022-11-08 11:38:49,239:INFO:Defining folds
2022-11-08 11:38:49,239:INFO:Declaring metric variables
2022-11-08 11:38:49,246:INFO:Importing untrained model
2022-11-08 11:38:49,255:INFO:SVM - Linear Kernel Imported successfully
2022-11-08 11:38:49,269:INFO:Starting cross validation
2022-11-08 11:38:49,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:49,414:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-11-08 11:38:49,467:INFO:Calculating mean and std
2022-11-08 11:38:49,468:INFO:Creating metrics dataframe
2022-11-08 11:38:49,472:INFO:Uploading results into container
2022-11-08 11:38:49,472:INFO:Uploading model into container now
2022-11-08 11:38:49,473:INFO:master_model_container: 22
2022-11-08 11:38:49,473:INFO:display_container: 6
2022-11-08 11:38:49,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5092, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-08 11:38:49,473:INFO:create_model() successfully completed......................................
2022-11-08 11:38:49,599:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:49,599:INFO:Creating metrics dataframe
2022-11-08 11:38:49,615:INFO:Initializing Ridge Classifier
2022-11-08 11:38:49,616:INFO:Total runtime is 0.0399705171585083 minutes
2022-11-08 11:38:49,622:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:49,623:INFO:Initializing create_model()
2022-11-08 11:38:49,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:49,623:INFO:Checking exceptions
2022-11-08 11:38:49,625:INFO:Importing libraries
2022-11-08 11:38:49,627:INFO:Copying training dataset
2022-11-08 11:38:49,634:INFO:Defining folds
2022-11-08 11:38:49,634:INFO:Declaring metric variables
2022-11-08 11:38:49,640:INFO:Importing untrained model
2022-11-08 11:38:49,650:INFO:Ridge Classifier Imported successfully
2022-11-08 11:38:49,664:INFO:Starting cross validation
2022-11-08 11:38:49,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:49,866:INFO:Calculating mean and std
2022-11-08 11:38:49,870:INFO:Creating metrics dataframe
2022-11-08 11:38:49,874:INFO:Uploading results into container
2022-11-08 11:38:49,875:INFO:Uploading model into container now
2022-11-08 11:38:49,876:INFO:master_model_container: 23
2022-11-08 11:38:49,876:INFO:display_container: 6
2022-11-08 11:38:49,876:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5092, solver='auto', tol=0.001)
2022-11-08 11:38:49,876:INFO:create_model() successfully completed......................................
2022-11-08 11:38:50,001:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:50,001:INFO:Creating metrics dataframe
2022-11-08 11:38:50,019:INFO:Initializing Random Forest Classifier
2022-11-08 11:38:50,019:INFO:Total runtime is 0.04668279488881429 minutes
2022-11-08 11:38:50,027:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:50,028:INFO:Initializing create_model()
2022-11-08 11:38:50,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:50,028:INFO:Checking exceptions
2022-11-08 11:38:50,031:INFO:Importing libraries
2022-11-08 11:38:50,031:INFO:Copying training dataset
2022-11-08 11:38:50,035:INFO:Defining folds
2022-11-08 11:38:50,035:INFO:Declaring metric variables
2022-11-08 11:38:50,042:INFO:Importing untrained model
2022-11-08 11:38:50,049:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:38:50,066:INFO:Starting cross validation
2022-11-08 11:38:50,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:51,365:INFO:Calculating mean and std
2022-11-08 11:38:51,367:INFO:Creating metrics dataframe
2022-11-08 11:38:51,372:INFO:Uploading results into container
2022-11-08 11:38:51,372:INFO:Uploading model into container now
2022-11-08 11:38:51,375:INFO:master_model_container: 24
2022-11-08 11:38:51,375:INFO:display_container: 6
2022-11-08 11:38:51,376:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:51,376:INFO:create_model() successfully completed......................................
2022-11-08 11:38:51,495:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:51,495:INFO:Creating metrics dataframe
2022-11-08 11:38:51,517:INFO:Initializing Quadratic Discriminant Analysis
2022-11-08 11:38:51,517:INFO:Total runtime is 0.07164777517318725 minutes
2022-11-08 11:38:51,522:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:51,523:INFO:Initializing create_model()
2022-11-08 11:38:51,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:51,524:INFO:Checking exceptions
2022-11-08 11:38:51,528:INFO:Importing libraries
2022-11-08 11:38:51,528:INFO:Copying training dataset
2022-11-08 11:38:51,532:INFO:Defining folds
2022-11-08 11:38:51,532:INFO:Declaring metric variables
2022-11-08 11:38:51,537:INFO:Importing untrained model
2022-11-08 11:38:51,548:INFO:Quadratic Discriminant Analysis Imported successfully
2022-11-08 11:38:51,564:INFO:Starting cross validation
2022-11-08 11:38:51,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:51,634:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-11-08 11:38:51,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:38:51,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:38:51,818:INFO:Calculating mean and std
2022-11-08 11:38:51,819:INFO:Creating metrics dataframe
2022-11-08 11:38:51,824:INFO:Uploading results into container
2022-11-08 11:38:51,825:INFO:Uploading model into container now
2022-11-08 11:38:51,826:INFO:master_model_container: 25
2022-11-08 11:38:51,826:INFO:display_container: 6
2022-11-08 11:38:51,826:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-11-08 11:38:51,827:INFO:create_model() successfully completed......................................
2022-11-08 11:38:51,951:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:51,951:INFO:Creating metrics dataframe
2022-11-08 11:38:51,968:INFO:Initializing Ada Boost Classifier
2022-11-08 11:38:51,969:INFO:Total runtime is 0.07918850580851236 minutes
2022-11-08 11:38:51,976:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:51,977:INFO:Initializing create_model()
2022-11-08 11:38:51,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:51,978:INFO:Checking exceptions
2022-11-08 11:38:51,980:INFO:Importing libraries
2022-11-08 11:38:51,980:INFO:Copying training dataset
2022-11-08 11:38:51,985:INFO:Defining folds
2022-11-08 11:38:51,985:INFO:Declaring metric variables
2022-11-08 11:38:51,992:INFO:Importing untrained model
2022-11-08 11:38:52,000:INFO:Ada Boost Classifier Imported successfully
2022-11-08 11:38:52,013:INFO:Starting cross validation
2022-11-08 11:38:52,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:52,680:INFO:Calculating mean and std
2022-11-08 11:38:52,681:INFO:Creating metrics dataframe
2022-11-08 11:38:52,685:INFO:Uploading results into container
2022-11-08 11:38:52,686:INFO:Uploading model into container now
2022-11-08 11:38:52,687:INFO:master_model_container: 26
2022-11-08 11:38:52,688:INFO:display_container: 6
2022-11-08 11:38:52,688:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092)
2022-11-08 11:38:52,689:INFO:create_model() successfully completed......................................
2022-11-08 11:38:52,808:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:52,808:INFO:Creating metrics dataframe
2022-11-08 11:38:52,827:INFO:Initializing Gradient Boosting Classifier
2022-11-08 11:38:52,827:INFO:Total runtime is 0.09347862799962361 minutes
2022-11-08 11:38:52,832:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:52,832:INFO:Initializing create_model()
2022-11-08 11:38:52,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:52,833:INFO:Checking exceptions
2022-11-08 11:38:52,836:INFO:Importing libraries
2022-11-08 11:38:52,836:INFO:Copying training dataset
2022-11-08 11:38:52,842:INFO:Defining folds
2022-11-08 11:38:52,842:INFO:Declaring metric variables
2022-11-08 11:38:52,850:INFO:Importing untrained model
2022-11-08 11:38:52,857:INFO:Gradient Boosting Classifier Imported successfully
2022-11-08 11:38:52,878:INFO:Starting cross validation
2022-11-08 11:38:52,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:53,578:INFO:Calculating mean and std
2022-11-08 11:38:53,580:INFO:Creating metrics dataframe
2022-11-08 11:38:53,584:INFO:Uploading results into container
2022-11-08 11:38:53,584:INFO:Uploading model into container now
2022-11-08 11:38:53,585:INFO:master_model_container: 27
2022-11-08 11:38:53,585:INFO:display_container: 6
2022-11-08 11:38:53,586:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5092, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-08 11:38:53,586:INFO:create_model() successfully completed......................................
2022-11-08 11:38:53,711:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:53,711:INFO:Creating metrics dataframe
2022-11-08 11:38:53,728:INFO:Initializing Linear Discriminant Analysis
2022-11-08 11:38:53,728:INFO:Total runtime is 0.10849990049997965 minutes
2022-11-08 11:38:53,733:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:53,734:INFO:Initializing create_model()
2022-11-08 11:38:53,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:53,734:INFO:Checking exceptions
2022-11-08 11:38:53,739:INFO:Importing libraries
2022-11-08 11:38:53,739:INFO:Copying training dataset
2022-11-08 11:38:53,744:INFO:Defining folds
2022-11-08 11:38:53,744:INFO:Declaring metric variables
2022-11-08 11:38:53,752:INFO:Importing untrained model
2022-11-08 11:38:53,760:INFO:Linear Discriminant Analysis Imported successfully
2022-11-08 11:38:53,775:INFO:Starting cross validation
2022-11-08 11:38:53,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:54,034:INFO:Calculating mean and std
2022-11-08 11:38:54,036:INFO:Creating metrics dataframe
2022-11-08 11:38:54,040:INFO:Uploading results into container
2022-11-08 11:38:54,041:INFO:Uploading model into container now
2022-11-08 11:38:54,041:INFO:master_model_container: 28
2022-11-08 11:38:54,041:INFO:display_container: 6
2022-11-08 11:38:54,041:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-11-08 11:38:54,041:INFO:create_model() successfully completed......................................
2022-11-08 11:38:54,165:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:54,165:INFO:Creating metrics dataframe
2022-11-08 11:38:54,184:INFO:Initializing Extra Trees Classifier
2022-11-08 11:38:54,184:INFO:Total runtime is 0.11609896818796793 minutes
2022-11-08 11:38:54,190:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:54,191:INFO:Initializing create_model()
2022-11-08 11:38:54,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:54,191:INFO:Checking exceptions
2022-11-08 11:38:54,194:INFO:Importing libraries
2022-11-08 11:38:54,194:INFO:Copying training dataset
2022-11-08 11:38:54,198:INFO:Defining folds
2022-11-08 11:38:54,198:INFO:Declaring metric variables
2022-11-08 11:38:54,206:INFO:Importing untrained model
2022-11-08 11:38:54,213:INFO:Extra Trees Classifier Imported successfully
2022-11-08 11:38:54,225:INFO:Starting cross validation
2022-11-08 11:38:54,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:55,378:INFO:Calculating mean and std
2022-11-08 11:38:55,380:INFO:Creating metrics dataframe
2022-11-08 11:38:55,384:INFO:Uploading results into container
2022-11-08 11:38:55,384:INFO:Uploading model into container now
2022-11-08 11:38:55,385:INFO:master_model_container: 29
2022-11-08 11:38:55,385:INFO:display_container: 6
2022-11-08 11:38:55,386:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:55,387:INFO:create_model() successfully completed......................................
2022-11-08 11:38:55,510:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:55,510:INFO:Creating metrics dataframe
2022-11-08 11:38:55,528:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:38:55,529:INFO:Total runtime is 0.13851706584294637 minutes
2022-11-08 11:38:55,533:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:55,534:INFO:Initializing create_model()
2022-11-08 11:38:55,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:55,534:INFO:Checking exceptions
2022-11-08 11:38:55,539:INFO:Importing libraries
2022-11-08 11:38:55,539:INFO:Copying training dataset
2022-11-08 11:38:55,543:INFO:Defining folds
2022-11-08 11:38:55,543:INFO:Declaring metric variables
2022-11-08 11:38:55,551:INFO:Importing untrained model
2022-11-08 11:38:55,557:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:38:55,574:INFO:Starting cross validation
2022-11-08 11:38:55,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:55,914:INFO:Calculating mean and std
2022-11-08 11:38:55,915:INFO:Creating metrics dataframe
2022-11-08 11:38:55,920:INFO:Uploading results into container
2022-11-08 11:38:55,921:INFO:Uploading model into container now
2022-11-08 11:38:55,921:INFO:master_model_container: 30
2022-11-08 11:38:55,921:INFO:display_container: 6
2022-11-08 11:38:55,922:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5092, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-08 11:38:55,922:INFO:create_model() successfully completed......................................
2022-11-08 11:38:56,044:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:56,045:INFO:Creating metrics dataframe
2022-11-08 11:38:56,063:INFO:Initializing Dummy Classifier
2022-11-08 11:38:56,063:INFO:Total runtime is 0.14742266337076823 minutes
2022-11-08 11:38:56,068:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:56,068:INFO:Initializing create_model()
2022-11-08 11:38:56,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:56,068:INFO:Checking exceptions
2022-11-08 11:38:56,074:INFO:Importing libraries
2022-11-08 11:38:56,074:INFO:Copying training dataset
2022-11-08 11:38:56,078:INFO:Defining folds
2022-11-08 11:38:56,078:INFO:Declaring metric variables
2022-11-08 11:38:56,084:INFO:Importing untrained model
2022-11-08 11:38:56,093:INFO:Dummy Classifier Imported successfully
2022-11-08 11:38:56,104:INFO:Starting cross validation
2022-11-08 11:38:56,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:56,338:INFO:Calculating mean and std
2022-11-08 11:38:56,340:INFO:Creating metrics dataframe
2022-11-08 11:38:56,343:INFO:Uploading results into container
2022-11-08 11:38:56,344:INFO:Uploading model into container now
2022-11-08 11:38:56,344:INFO:master_model_container: 31
2022-11-08 11:38:56,344:INFO:display_container: 6
2022-11-08 11:38:56,344:INFO:DummyClassifier(constant=None, random_state=5092, strategy='prior')
2022-11-08 11:38:56,344:INFO:create_model() successfully completed......................................
2022-11-08 11:38:56,470:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:56,471:INFO:Creating metrics dataframe
2022-11-08 11:38:56,506:INFO:Initializing create_model()
2022-11-08 11:38:56,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:56,507:INFO:Checking exceptions
2022-11-08 11:38:56,512:INFO:Importing libraries
2022-11-08 11:38:56,513:INFO:Copying training dataset
2022-11-08 11:38:56,517:INFO:Defining folds
2022-11-08 11:38:56,517:INFO:Declaring metric variables
2022-11-08 11:38:56,518:INFO:Importing untrained model
2022-11-08 11:38:56,519:INFO:Declaring custom model
2022-11-08 11:38:56,520:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:38:56,520:INFO:Cross validation set to False
2022-11-08 11:38:56,520:INFO:Fitting Model
2022-11-08 11:38:56,747:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:56,747:INFO:create_model() successfully completed......................................
2022-11-08 11:38:56,920:INFO:master_model_container: 31
2022-11-08 11:38:56,920:INFO:display_container: 6
2022-11-08 11:38:56,921:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:56,921:INFO:compare_models() successfully completed......................................
2022-11-08 11:39:26,961:INFO:Initializing plot_model()
2022-11-08 11:39:26,961:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:39:26,962:INFO:Checking exceptions
2022-11-08 11:39:27,002:INFO:Preloading libraries
2022-11-08 11:39:27,028:INFO:Copying training dataset
2022-11-08 11:39:27,029:INFO:Plot type: learning
2022-11-08 11:39:27,092:INFO:Fitting Model
2022-11-08 11:39:40,196:INFO:Visual Rendered Successfully
2022-11-08 11:39:40,356:INFO:plot_model() successfully completed......................................
2022-11-08 11:40:20,936:INFO:Initializing tune_model()
2022-11-08 11:40:20,936:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>)
2022-11-08 11:40:20,936:INFO:Checking exceptions
2022-11-08 11:40:21,013:INFO:Copying training dataset
2022-11-08 11:40:21,018:INFO:Checking base model
2022-11-08 11:40:21,019:INFO:Base model : Random Forest Classifier
2022-11-08 11:40:21,027:INFO:Declaring metric variables
2022-11-08 11:40:21,035:INFO:Defining Hyperparameters
2022-11-08 11:40:21,205:INFO:Tuning with n_jobs=-1
2022-11-08 11:40:21,205:INFO:Initializing RandomizedSearchCV
2022-11-08 11:40:36,922:INFO:best_params: {'actual_estimator__n_estimators': 90, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2022-11-08 11:40:36,926:INFO:Hyperparameter search completed
2022-11-08 11:40:36,926:INFO:SubProcess create_model() called ==================================
2022-11-08 11:40:36,927:INFO:Initializing create_model()
2022-11-08 11:40:36,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E3F7CB50>, model_only=True, return_train_score=False, kwargs={'n_estimators': 90, 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.02, 'max_features': 'log2', 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': True})
2022-11-08 11:40:36,928:INFO:Checking exceptions
2022-11-08 11:40:36,930:INFO:Importing libraries
2022-11-08 11:40:36,930:INFO:Copying training dataset
2022-11-08 11:40:36,937:INFO:Defining folds
2022-11-08 11:40:36,937:INFO:Declaring metric variables
2022-11-08 11:40:36,944:INFO:Importing untrained model
2022-11-08 11:40:36,945:INFO:Declaring custom model
2022-11-08 11:40:36,955:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:40:36,972:INFO:Starting cross validation
2022-11-08 11:40:36,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:40:38,181:INFO:Calculating mean and std
2022-11-08 11:40:38,185:INFO:Creating metrics dataframe
2022-11-08 11:40:38,198:INFO:Finalizing model
2022-11-08 11:40:38,469:INFO:Uploading results into container
2022-11-08 11:40:38,471:INFO:Uploading model into container now
2022-11-08 11:40:38,471:INFO:master_model_container: 32
2022-11-08 11:40:38,472:INFO:display_container: 7
2022-11-08 11:40:38,472:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=3,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=90, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:40:38,473:INFO:create_model() successfully completed......................................
2022-11-08 11:40:38,606:INFO:SubProcess create_model() end ==================================
2022-11-08 11:40:38,606:INFO:choose_better activated
2022-11-08 11:40:38,612:INFO:SubProcess create_model() called ==================================
2022-11-08 11:40:38,614:INFO:Initializing create_model()
2022-11-08 11:40:38,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:40:38,615:INFO:Checking exceptions
2022-11-08 11:40:38,620:INFO:Importing libraries
2022-11-08 11:40:38,620:INFO:Copying training dataset
2022-11-08 11:40:38,626:INFO:Defining folds
2022-11-08 11:40:38,626:INFO:Declaring metric variables
2022-11-08 11:40:38,626:INFO:Importing untrained model
2022-11-08 11:40:38,626:INFO:Declaring custom model
2022-11-08 11:40:38,626:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:40:38,626:INFO:Starting cross validation
2022-11-08 11:40:38,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:40:39,930:INFO:Calculating mean and std
2022-11-08 11:40:39,931:INFO:Creating metrics dataframe
2022-11-08 11:40:39,934:INFO:Finalizing model
2022-11-08 11:40:40,450:INFO:Uploading results into container
2022-11-08 11:40:40,452:INFO:Uploading model into container now
2022-11-08 11:40:40,452:INFO:master_model_container: 33
2022-11-08 11:40:40,453:INFO:display_container: 8
2022-11-08 11:40:40,453:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:40:40,454:INFO:create_model() successfully completed......................................
2022-11-08 11:40:40,637:INFO:SubProcess create_model() end ==================================
2022-11-08 11:40:40,644:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False) result for Accuracy is 0.5404
2022-11-08 11:40:40,646:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=3,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=90, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False) result for Accuracy is 0.5318
2022-11-08 11:40:40,646:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False) is best model
2022-11-08 11:40:40,646:INFO:choose_better completed
2022-11-08 11:40:40,646:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-11-08 11:40:40,700:INFO:master_model_container: 33
2022-11-08 11:40:40,700:INFO:display_container: 7
2022-11-08 11:40:40,701:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:40:40,701:INFO:tune_model() successfully completed......................................
2022-11-08 11:41:03,784:INFO:Initializing plot_model()
2022-11-08 11:41:03,784:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:41:03,785:INFO:Checking exceptions
2022-11-08 11:41:03,818:INFO:Preloading libraries
2022-11-08 11:41:03,829:INFO:Copying training dataset
2022-11-08 11:41:03,829:INFO:Plot type: learning
2022-11-08 11:41:03,895:INFO:Fitting Model
2022-11-08 11:41:14,928:INFO:Visual Rendered Successfully
2022-11-08 11:41:15,086:INFO:plot_model() successfully completed......................................
2022-11-08 11:41:36,786:INFO:Initializing save_model()
2022-11-08 11:41:36,786:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), model_name=forestfiremodel, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-11-08 11:41:36,786:INFO:Adding model into prep_pipe
2022-11-08 11:41:36,870:INFO:forestfiremodel.pkl saved in current working directory
2022-11-08 11:41:36,876:INFO:Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Trans...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=5092,
                                        verbose=0, warm_start=False))],
         verbose=False)
2022-11-08 11:41:36,876:INFO:save_model() successfully completed......................................
2022-12-18 15:31:32,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-18 15:31:32,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-18 15:31:32,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-18 15:31:32,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-18 15:31:36,590:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-12-18 15:31:37,142:INFO:PyCaret RegressionExperiment
2022-12-18 15:31:37,142:INFO:Logging name: reg-default-name
2022-12-18 15:31:37,142:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-18 15:31:37,142:INFO:version 3.0.0.rc4
2022-12-18 15:31:37,143:INFO:Initializing setup()
2022-12-18 15:31:37,143:INFO:self.USI: 1f9a
2022-12-18 15:31:37,143:INFO:self.variable_keys: {'exp_name_log', 'y', 'X', '_available_plots', 'seed', '_gpu_n_jobs_param', 'idx', 'n_jobs_param', 'variable_keys', 'html_param', 'fold_shuffle_param', 'fold_groups_param', '_all_metrics', 'memory', 'pipeline', 'data', 'transform_target_param', 'logging_param', 'transform_target_method_param', 'X_test', 'y_test', 'USI', 'log_plots_param', 'gpu_param', 'X_train', '_all_models_internal', 'exp_id', 'target_param', '_ml_usecase', 'y_train', 'master_model_container', '_all_models', 'display_container', 'fold_generator'}
2022-12-18 15:31:37,143:INFO:Checking environment
2022-12-18 15:31:37,143:INFO:python_version: 3.10.4
2022-12-18 15:31:37,143:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-12-18 15:31:37,143:INFO:machine: AMD64
2022-12-18 15:31:37,143:INFO:platform: Windows-10-10.0.19045-SP0
2022-12-18 15:31:37,143:INFO:Memory: svmem(total=8503136256, available=2077487104, percent=75.6, used=6425649152, free=2077487104)
2022-12-18 15:31:37,143:INFO:Physical Core: 2
2022-12-18 15:31:37,143:INFO:Logical Core: 4
2022-12-18 15:31:37,143:INFO:Checking libraries
2022-12-18 15:31:37,143:INFO:System:
2022-12-18 15:31:37,143:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-12-18 15:31:37,143:INFO:executable: c:\Python3.10\python.exe
2022-12-18 15:31:37,143:INFO:   machine: Windows-10-10.0.19045-SP0
2022-12-18 15:31:37,143:INFO:PyCaret required dependencies:
2022-12-18 15:31:37,144:INFO:                 pip: 22.2.2
2022-12-18 15:31:37,144:INFO:          setuptools: 58.1.0
2022-12-18 15:31:37,144:INFO:             pycaret: 3.0.0rc4
2022-12-18 15:31:37,144:INFO:             IPython: 8.4.0
2022-12-18 15:31:37,144:INFO:          ipywidgets: 8.0.2
2022-12-18 15:31:37,144:INFO:                tqdm: 4.64.0
2022-12-18 15:31:37,144:INFO:               numpy: 1.22.1
2022-12-18 15:31:37,144:INFO:              pandas: 1.4.2
2022-12-18 15:31:37,144:INFO:              jinja2: 3.1.2
2022-12-18 15:31:37,144:INFO:               scipy: 1.8.1
2022-12-18 15:31:37,144:INFO:              joblib: 1.2.0
2022-12-18 15:31:37,144:INFO:             sklearn: 1.1.2
2022-12-18 15:31:37,144:INFO:                pyod: 1.0.6
2022-12-18 15:31:37,144:INFO:            imblearn: 0.9.1
2022-12-18 15:31:37,144:INFO:   category_encoders: 2.5.1.post0
2022-12-18 15:31:37,144:INFO:            lightgbm: 3.3.3
2022-12-18 15:31:37,144:INFO:               numba: 0.55.2
2022-12-18 15:31:37,144:INFO:            requests: 2.28.1
2022-12-18 15:31:37,144:INFO:          matplotlib: 3.5.1
2022-12-18 15:31:37,144:INFO:          scikitplot: 0.3.7
2022-12-18 15:31:37,144:INFO:         yellowbrick: 1.5
2022-12-18 15:31:37,145:INFO:              plotly: 5.11.0
2022-12-18 15:31:37,145:INFO:             kaleido: 0.2.1
2022-12-18 15:31:37,145:INFO:         statsmodels: 0.13.5
2022-12-18 15:31:37,145:INFO:              sktime: 0.13.4
2022-12-18 15:31:37,145:INFO:               tbats: 1.1.1
2022-12-18 15:31:37,145:INFO:            pmdarima: 1.8.5
2022-12-18 15:31:37,145:INFO:              psutil: 5.9.1
2022-12-18 15:31:37,145:INFO:PyCaret optional dependencies:
2022-12-18 15:31:37,166:INFO:                shap: Not installed
2022-12-18 15:31:37,166:INFO:           interpret: Not installed
2022-12-18 15:31:37,166:INFO:                umap: Not installed
2022-12-18 15:31:37,167:INFO:    pandas_profiling: Not installed
2022-12-18 15:31:37,167:INFO:  explainerdashboard: Not installed
2022-12-18 15:31:37,167:INFO:             autoviz: Not installed
2022-12-18 15:31:37,167:INFO:           fairlearn: Not installed
2022-12-18 15:31:37,167:INFO:             xgboost: Not installed
2022-12-18 15:31:37,167:INFO:            catboost: Not installed
2022-12-18 15:31:37,167:INFO:              kmodes: Not installed
2022-12-18 15:31:37,167:INFO:             mlxtend: Not installed
2022-12-18 15:31:37,167:INFO:       statsforecast: Not installed
2022-12-18 15:31:37,167:INFO:        tune_sklearn: Not installed
2022-12-18 15:31:37,167:INFO:                 ray: Not installed
2022-12-18 15:31:37,167:INFO:            hyperopt: Not installed
2022-12-18 15:31:37,168:INFO:              optuna: Not installed
2022-12-18 15:31:37,168:INFO:               skopt: Not installed
2022-12-18 15:31:37,168:INFO:              mlflow: Not installed
2022-12-18 15:31:37,168:INFO:              gradio: Not installed
2022-12-18 15:31:37,168:INFO:             fastapi: Not installed
2022-12-18 15:31:37,168:INFO:             uvicorn: Not installed
2022-12-18 15:31:37,168:INFO:              m2cgen: Not installed
2022-12-18 15:31:37,168:INFO:           evidently: Not installed
2022-12-18 15:31:37,168:INFO:                nltk: 3.7
2022-12-18 15:31:37,168:INFO:            pyLDAvis: Not installed
2022-12-18 15:31:37,168:INFO:              gensim: Not installed
2022-12-18 15:31:37,168:INFO:               spacy: 3.4.3
2022-12-18 15:31:37,168:INFO:           wordcloud: Not installed
2022-12-18 15:31:37,168:INFO:            textblob: Not installed
2022-12-18 15:31:37,168:INFO:               fugue: Not installed
2022-12-18 15:31:37,168:INFO:           streamlit: Not installed
2022-12-18 15:31:37,169:INFO:             prophet: Not installed
2022-12-18 15:31:37,169:INFO:None
2022-12-18 15:31:37,169:INFO:Set up data.
2022-12-18 15:31:37,176:INFO:Set up train/test split.
2022-12-18 15:31:37,182:INFO:Set up index.
2022-12-18 15:31:37,182:INFO:Set up folding strategy.
2022-12-18 15:31:37,182:INFO:Assigning column types.
2022-12-18 15:31:37,186:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-18 15:31:37,188:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,193:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,198:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,319:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,460:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,467:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,473:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,615:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-18 15:31:37,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,625:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,750:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,756:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,762:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:37,901:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-18 15:31:37,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:31:37,981:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,238:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-18 15:31:38,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,516:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-18 15:31:38,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:31:38,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,798:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-18 15:31:38,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:38,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,096:INFO:Preparing preprocessing pipeline...
2022-12-18 15:31:39,097:INFO:Set up simple imputation.
2022-12-18 15:31:39,097:INFO:Set up variance threshold.
2022-12-18 15:31:39,152:INFO:Finished creating preprocessing pipeline.
2022-12-18 15:31:39,158:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-18 15:31:39,158:INFO:Creating final display dataframe.
2022-12-18 15:31:39,402:INFO:Setup display_container:                Description             Value
0               Session id              2258
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              1f9a
2022-12-18 15:31:39,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:31:39,736:INFO:setup() successfully completed in 2.59s...............
2022-12-18 15:32:28,774:INFO:Initializing compare_models()
2022-12-18 15:32:28,774:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-18 15:32:28,774:INFO:Checking exceptions
2022-12-18 15:32:28,777:INFO:Preparing display monitor
2022-12-18 15:32:28,855:INFO:Initializing Linear Regression
2022-12-18 15:32:28,855:INFO:Total runtime is 0.0 minutes
2022-12-18 15:32:28,862:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:28,863:INFO:Initializing create_model()
2022-12-18 15:32:28,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:28,864:INFO:Checking exceptions
2022-12-18 15:32:28,868:INFO:Importing libraries
2022-12-18 15:32:28,868:INFO:Copying training dataset
2022-12-18 15:32:28,873:INFO:Defining folds
2022-12-18 15:32:28,873:INFO:Declaring metric variables
2022-12-18 15:32:28,880:INFO:Importing untrained model
2022-12-18 15:32:28,891:INFO:Linear Regression Imported successfully
2022-12-18 15:32:28,905:INFO:Starting cross validation
2022-12-18 15:32:28,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:39,695:INFO:Calculating mean and std
2022-12-18 15:32:39,699:INFO:Creating metrics dataframe
2022-12-18 15:32:39,713:INFO:Uploading results into container
2022-12-18 15:32:39,714:INFO:Uploading model into container now
2022-12-18 15:32:39,719:INFO:master_model_container: 1
2022-12-18 15:32:39,719:INFO:display_container: 2
2022-12-18 15:32:39,720:INFO:LinearRegression(n_jobs=-1)
2022-12-18 15:32:39,720:INFO:create_model() successfully completed......................................
2022-12-18 15:32:39,892:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:39,892:INFO:Creating metrics dataframe
2022-12-18 15:32:39,935:INFO:Initializing Lasso Regression
2022-12-18 15:32:39,936:INFO:Total runtime is 0.1846660017967224 minutes
2022-12-18 15:32:39,952:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:39,954:INFO:Initializing create_model()
2022-12-18 15:32:39,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:39,954:INFO:Checking exceptions
2022-12-18 15:32:39,959:INFO:Importing libraries
2022-12-18 15:32:39,959:INFO:Copying training dataset
2022-12-18 15:32:39,969:INFO:Defining folds
2022-12-18 15:32:39,972:INFO:Declaring metric variables
2022-12-18 15:32:39,983:INFO:Importing untrained model
2022-12-18 15:32:39,995:INFO:Lasso Regression Imported successfully
2022-12-18 15:32:40,018:INFO:Starting cross validation
2022-12-18 15:32:40,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:40,532:INFO:Calculating mean and std
2022-12-18 15:32:40,538:INFO:Creating metrics dataframe
2022-12-18 15:32:40,544:INFO:Uploading results into container
2022-12-18 15:32:40,545:INFO:Uploading model into container now
2022-12-18 15:32:40,545:INFO:master_model_container: 2
2022-12-18 15:32:40,545:INFO:display_container: 2
2022-12-18 15:32:40,546:INFO:Lasso(random_state=2258)
2022-12-18 15:32:40,546:INFO:create_model() successfully completed......................................
2022-12-18 15:32:40,648:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:40,648:INFO:Creating metrics dataframe
2022-12-18 15:32:40,671:INFO:Initializing Ridge Regression
2022-12-18 15:32:40,671:INFO:Total runtime is 0.196921972433726 minutes
2022-12-18 15:32:40,677:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:40,677:INFO:Initializing create_model()
2022-12-18 15:32:40,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:40,678:INFO:Checking exceptions
2022-12-18 15:32:40,682:INFO:Importing libraries
2022-12-18 15:32:40,682:INFO:Copying training dataset
2022-12-18 15:32:40,696:INFO:Defining folds
2022-12-18 15:32:40,696:INFO:Declaring metric variables
2022-12-18 15:32:40,704:INFO:Importing untrained model
2022-12-18 15:32:40,712:INFO:Ridge Regression Imported successfully
2022-12-18 15:32:40,730:INFO:Starting cross validation
2022-12-18 15:32:40,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:41,055:INFO:Calculating mean and std
2022-12-18 15:32:41,057:INFO:Creating metrics dataframe
2022-12-18 15:32:41,061:INFO:Uploading results into container
2022-12-18 15:32:41,061:INFO:Uploading model into container now
2022-12-18 15:32:41,062:INFO:master_model_container: 3
2022-12-18 15:32:41,062:INFO:display_container: 2
2022-12-18 15:32:41,063:INFO:Ridge(random_state=2258)
2022-12-18 15:32:41,063:INFO:create_model() successfully completed......................................
2022-12-18 15:32:41,159:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:41,160:INFO:Creating metrics dataframe
2022-12-18 15:32:41,172:INFO:Initializing Elastic Net
2022-12-18 15:32:41,172:INFO:Total runtime is 0.2052762508392334 minutes
2022-12-18 15:32:41,177:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:41,177:INFO:Initializing create_model()
2022-12-18 15:32:41,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:41,178:INFO:Checking exceptions
2022-12-18 15:32:41,180:INFO:Importing libraries
2022-12-18 15:32:41,181:INFO:Copying training dataset
2022-12-18 15:32:41,188:INFO:Defining folds
2022-12-18 15:32:41,188:INFO:Declaring metric variables
2022-12-18 15:32:41,197:INFO:Importing untrained model
2022-12-18 15:32:41,207:INFO:Elastic Net Imported successfully
2022-12-18 15:32:41,229:INFO:Starting cross validation
2022-12-18 15:32:41,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:41,513:INFO:Calculating mean and std
2022-12-18 15:32:41,514:INFO:Creating metrics dataframe
2022-12-18 15:32:41,519:INFO:Uploading results into container
2022-12-18 15:32:41,520:INFO:Uploading model into container now
2022-12-18 15:32:41,520:INFO:master_model_container: 4
2022-12-18 15:32:41,520:INFO:display_container: 2
2022-12-18 15:32:41,521:INFO:ElasticNet(random_state=2258)
2022-12-18 15:32:41,521:INFO:create_model() successfully completed......................................
2022-12-18 15:32:41,612:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:41,612:INFO:Creating metrics dataframe
2022-12-18 15:32:41,632:INFO:Initializing Least Angle Regression
2022-12-18 15:32:41,633:INFO:Total runtime is 0.2129642407099406 minutes
2022-12-18 15:32:41,640:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:41,640:INFO:Initializing create_model()
2022-12-18 15:32:41,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:41,641:INFO:Checking exceptions
2022-12-18 15:32:41,644:INFO:Importing libraries
2022-12-18 15:32:41,644:INFO:Copying training dataset
2022-12-18 15:32:41,647:INFO:Defining folds
2022-12-18 15:32:41,648:INFO:Declaring metric variables
2022-12-18 15:32:41,657:INFO:Importing untrained model
2022-12-18 15:32:41,668:INFO:Least Angle Regression Imported successfully
2022-12-18 15:32:41,687:INFO:Starting cross validation
2022-12-18 15:32:41,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:41,759:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,771:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,788:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,806:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,872:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,886:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,888:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,892:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,943:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,965:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:41,991:INFO:Calculating mean and std
2022-12-18 15:32:41,994:INFO:Creating metrics dataframe
2022-12-18 15:32:42,000:INFO:Uploading results into container
2022-12-18 15:32:42,001:INFO:Uploading model into container now
2022-12-18 15:32:42,002:INFO:master_model_container: 5
2022-12-18 15:32:42,002:INFO:display_container: 2
2022-12-18 15:32:42,003:INFO:Lars(random_state=2258)
2022-12-18 15:32:42,003:INFO:create_model() successfully completed......................................
2022-12-18 15:32:42,115:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:42,115:INFO:Creating metrics dataframe
2022-12-18 15:32:42,137:INFO:Initializing Lasso Least Angle Regression
2022-12-18 15:32:42,137:INFO:Total runtime is 0.22136144638061525 minutes
2022-12-18 15:32:42,145:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:42,145:INFO:Initializing create_model()
2022-12-18 15:32:42,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:42,146:INFO:Checking exceptions
2022-12-18 15:32:42,152:INFO:Importing libraries
2022-12-18 15:32:42,152:INFO:Copying training dataset
2022-12-18 15:32:42,161:INFO:Defining folds
2022-12-18 15:32:42,161:INFO:Declaring metric variables
2022-12-18 15:32:42,173:INFO:Importing untrained model
2022-12-18 15:32:42,184:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:32:42,205:INFO:Starting cross validation
2022-12-18 15:32:42,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:42,277:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,286:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,300:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,322:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,380:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,412:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,423:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,441:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,469:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:32:42,491:INFO:Calculating mean and std
2022-12-18 15:32:42,494:INFO:Creating metrics dataframe
2022-12-18 15:32:42,501:INFO:Uploading results into container
2022-12-18 15:32:42,502:INFO:Uploading model into container now
2022-12-18 15:32:42,503:INFO:master_model_container: 6
2022-12-18 15:32:42,503:INFO:display_container: 2
2022-12-18 15:32:42,504:INFO:LassoLars(random_state=2258)
2022-12-18 15:32:42,504:INFO:create_model() successfully completed......................................
2022-12-18 15:32:42,612:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:42,613:INFO:Creating metrics dataframe
2022-12-18 15:32:42,636:INFO:Initializing Orthogonal Matching Pursuit
2022-12-18 15:32:42,636:INFO:Total runtime is 0.2296836018562317 minutes
2022-12-18 15:32:42,643:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:42,644:INFO:Initializing create_model()
2022-12-18 15:32:42,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:42,644:INFO:Checking exceptions
2022-12-18 15:32:42,650:INFO:Importing libraries
2022-12-18 15:32:42,650:INFO:Copying training dataset
2022-12-18 15:32:42,659:INFO:Defining folds
2022-12-18 15:32:42,659:INFO:Declaring metric variables
2022-12-18 15:32:42,668:INFO:Importing untrained model
2022-12-18 15:32:42,679:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-18 15:32:42,706:INFO:Starting cross validation
2022-12-18 15:32:42,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:42,778:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,806:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,816:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,826:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,909:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,926:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,939:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:42,952:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:43,040:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:43,042:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:32:43,077:INFO:Calculating mean and std
2022-12-18 15:32:43,080:INFO:Creating metrics dataframe
2022-12-18 15:32:43,087:INFO:Uploading results into container
2022-12-18 15:32:43,089:INFO:Uploading model into container now
2022-12-18 15:32:43,090:INFO:master_model_container: 7
2022-12-18 15:32:43,091:INFO:display_container: 2
2022-12-18 15:32:43,091:INFO:OrthogonalMatchingPursuit()
2022-12-18 15:32:43,091:INFO:create_model() successfully completed......................................
2022-12-18 15:32:43,200:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:43,200:INFO:Creating metrics dataframe
2022-12-18 15:32:43,214:INFO:Initializing Bayesian Ridge
2022-12-18 15:32:43,214:INFO:Total runtime is 0.23931201299031576 minutes
2022-12-18 15:32:43,222:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:43,223:INFO:Initializing create_model()
2022-12-18 15:32:43,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:43,224:INFO:Checking exceptions
2022-12-18 15:32:43,226:INFO:Importing libraries
2022-12-18 15:32:43,226:INFO:Copying training dataset
2022-12-18 15:32:43,230:INFO:Defining folds
2022-12-18 15:32:43,230:INFO:Declaring metric variables
2022-12-18 15:32:43,238:INFO:Importing untrained model
2022-12-18 15:32:43,246:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:32:43,262:INFO:Starting cross validation
2022-12-18 15:32:43,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:43,594:INFO:Calculating mean and std
2022-12-18 15:32:43,600:INFO:Creating metrics dataframe
2022-12-18 15:32:43,608:INFO:Uploading results into container
2022-12-18 15:32:43,609:INFO:Uploading model into container now
2022-12-18 15:32:43,610:INFO:master_model_container: 8
2022-12-18 15:32:43,610:INFO:display_container: 2
2022-12-18 15:32:43,610:INFO:BayesianRidge()
2022-12-18 15:32:43,610:INFO:create_model() successfully completed......................................
2022-12-18 15:32:43,722:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:43,723:INFO:Creating metrics dataframe
2022-12-18 15:32:43,741:INFO:Initializing Passive Aggressive Regressor
2022-12-18 15:32:43,741:INFO:Total runtime is 0.2480871081352234 minutes
2022-12-18 15:32:43,749:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:43,750:INFO:Initializing create_model()
2022-12-18 15:32:43,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:43,750:INFO:Checking exceptions
2022-12-18 15:32:43,753:INFO:Importing libraries
2022-12-18 15:32:43,753:INFO:Copying training dataset
2022-12-18 15:32:43,760:INFO:Defining folds
2022-12-18 15:32:43,760:INFO:Declaring metric variables
2022-12-18 15:32:43,767:INFO:Importing untrained model
2022-12-18 15:32:43,776:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:32:43,790:INFO:Starting cross validation
2022-12-18 15:32:43,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:44,034:INFO:Calculating mean and std
2022-12-18 15:32:44,037:INFO:Creating metrics dataframe
2022-12-18 15:32:44,044:INFO:Uploading results into container
2022-12-18 15:32:44,045:INFO:Uploading model into container now
2022-12-18 15:32:44,045:INFO:master_model_container: 9
2022-12-18 15:32:44,046:INFO:display_container: 2
2022-12-18 15:32:44,047:INFO:PassiveAggressiveRegressor(random_state=2258)
2022-12-18 15:32:44,048:INFO:create_model() successfully completed......................................
2022-12-18 15:32:44,132:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:44,132:INFO:Creating metrics dataframe
2022-12-18 15:32:44,144:INFO:Initializing Huber Regressor
2022-12-18 15:32:44,145:INFO:Total runtime is 0.25482166608174645 minutes
2022-12-18 15:32:44,150:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:44,150:INFO:Initializing create_model()
2022-12-18 15:32:44,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:44,151:INFO:Checking exceptions
2022-12-18 15:32:44,155:INFO:Importing libraries
2022-12-18 15:32:44,155:INFO:Copying training dataset
2022-12-18 15:32:44,159:INFO:Defining folds
2022-12-18 15:32:44,159:INFO:Declaring metric variables
2022-12-18 15:32:44,168:INFO:Importing untrained model
2022-12-18 15:32:44,174:INFO:Huber Regressor Imported successfully
2022-12-18 15:32:44,191:INFO:Starting cross validation
2022-12-18 15:32:44,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:44,326:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,332:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,334:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,341:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,440:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,459:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,459:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,475:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,529:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,536:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:44,550:INFO:Calculating mean and std
2022-12-18 15:32:44,552:INFO:Creating metrics dataframe
2022-12-18 15:32:44,557:INFO:Uploading results into container
2022-12-18 15:32:44,557:INFO:Uploading model into container now
2022-12-18 15:32:44,558:INFO:master_model_container: 10
2022-12-18 15:32:44,558:INFO:display_container: 2
2022-12-18 15:32:44,559:INFO:HuberRegressor()
2022-12-18 15:32:44,559:INFO:create_model() successfully completed......................................
2022-12-18 15:32:44,636:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:44,636:INFO:Creating metrics dataframe
2022-12-18 15:32:44,650:INFO:Initializing K Neighbors Regressor
2022-12-18 15:32:44,650:INFO:Total runtime is 0.26324120362599696 minutes
2022-12-18 15:32:44,653:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:44,654:INFO:Initializing create_model()
2022-12-18 15:32:44,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:44,655:INFO:Checking exceptions
2022-12-18 15:32:44,658:INFO:Importing libraries
2022-12-18 15:32:44,658:INFO:Copying training dataset
2022-12-18 15:32:44,662:INFO:Defining folds
2022-12-18 15:32:44,662:INFO:Declaring metric variables
2022-12-18 15:32:44,669:INFO:Importing untrained model
2022-12-18 15:32:44,675:INFO:K Neighbors Regressor Imported successfully
2022-12-18 15:32:44,690:INFO:Starting cross validation
2022-12-18 15:32:44,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:44,944:INFO:Calculating mean and std
2022-12-18 15:32:44,947:INFO:Creating metrics dataframe
2022-12-18 15:32:44,952:INFO:Uploading results into container
2022-12-18 15:32:44,952:INFO:Uploading model into container now
2022-12-18 15:32:44,953:INFO:master_model_container: 11
2022-12-18 15:32:44,953:INFO:display_container: 2
2022-12-18 15:32:44,954:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-18 15:32:44,955:INFO:create_model() successfully completed......................................
2022-12-18 15:32:45,032:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:45,032:INFO:Creating metrics dataframe
2022-12-18 15:32:45,044:INFO:Initializing Decision Tree Regressor
2022-12-18 15:32:45,044:INFO:Total runtime is 0.2698096553484599 minutes
2022-12-18 15:32:45,050:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:45,050:INFO:Initializing create_model()
2022-12-18 15:32:45,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:45,051:INFO:Checking exceptions
2022-12-18 15:32:45,054:INFO:Importing libraries
2022-12-18 15:32:45,054:INFO:Copying training dataset
2022-12-18 15:32:45,058:INFO:Defining folds
2022-12-18 15:32:45,058:INFO:Declaring metric variables
2022-12-18 15:32:45,062:INFO:Importing untrained model
2022-12-18 15:32:45,070:INFO:Decision Tree Regressor Imported successfully
2022-12-18 15:32:45,083:INFO:Starting cross validation
2022-12-18 15:32:45,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:45,304:INFO:Calculating mean and std
2022-12-18 15:32:45,306:INFO:Creating metrics dataframe
2022-12-18 15:32:45,310:INFO:Uploading results into container
2022-12-18 15:32:45,310:INFO:Uploading model into container now
2022-12-18 15:32:45,311:INFO:master_model_container: 12
2022-12-18 15:32:45,311:INFO:display_container: 2
2022-12-18 15:32:45,311:INFO:DecisionTreeRegressor(random_state=2258)
2022-12-18 15:32:45,311:INFO:create_model() successfully completed......................................
2022-12-18 15:32:45,390:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:45,390:INFO:Creating metrics dataframe
2022-12-18 15:32:45,404:INFO:Initializing Random Forest Regressor
2022-12-18 15:32:45,404:INFO:Total runtime is 0.2758166074752808 minutes
2022-12-18 15:32:45,409:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:45,409:INFO:Initializing create_model()
2022-12-18 15:32:45,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:45,410:INFO:Checking exceptions
2022-12-18 15:32:45,414:INFO:Importing libraries
2022-12-18 15:32:45,414:INFO:Copying training dataset
2022-12-18 15:32:45,418:INFO:Defining folds
2022-12-18 15:32:45,418:INFO:Declaring metric variables
2022-12-18 15:32:45,421:INFO:Importing untrained model
2022-12-18 15:32:45,430:INFO:Random Forest Regressor Imported successfully
2022-12-18 15:32:45,440:INFO:Starting cross validation
2022-12-18 15:32:45,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:46,903:INFO:Calculating mean and std
2022-12-18 15:32:46,905:INFO:Creating metrics dataframe
2022-12-18 15:32:46,908:INFO:Uploading results into container
2022-12-18 15:32:46,909:INFO:Uploading model into container now
2022-12-18 15:32:46,909:INFO:master_model_container: 13
2022-12-18 15:32:46,911:INFO:display_container: 2
2022-12-18 15:32:46,912:INFO:RandomForestRegressor(n_jobs=-1, random_state=2258)
2022-12-18 15:32:46,913:INFO:create_model() successfully completed......................................
2022-12-18 15:32:46,990:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:46,990:INFO:Creating metrics dataframe
2022-12-18 15:32:47,005:INFO:Initializing Extra Trees Regressor
2022-12-18 15:32:47,005:INFO:Total runtime is 0.3024883031845093 minutes
2022-12-18 15:32:47,009:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:47,011:INFO:Initializing create_model()
2022-12-18 15:32:47,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:47,012:INFO:Checking exceptions
2022-12-18 15:32:47,014:INFO:Importing libraries
2022-12-18 15:32:47,014:INFO:Copying training dataset
2022-12-18 15:32:47,018:INFO:Defining folds
2022-12-18 15:32:47,019:INFO:Declaring metric variables
2022-12-18 15:32:47,026:INFO:Importing untrained model
2022-12-18 15:32:47,034:INFO:Extra Trees Regressor Imported successfully
2022-12-18 15:32:47,050:INFO:Starting cross validation
2022-12-18 15:32:47,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:48,167:INFO:Calculating mean and std
2022-12-18 15:32:48,169:INFO:Creating metrics dataframe
2022-12-18 15:32:48,172:INFO:Uploading results into container
2022-12-18 15:32:48,173:INFO:Uploading model into container now
2022-12-18 15:32:48,174:INFO:master_model_container: 14
2022-12-18 15:32:48,174:INFO:display_container: 2
2022-12-18 15:32:48,175:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2258)
2022-12-18 15:32:48,177:INFO:create_model() successfully completed......................................
2022-12-18 15:32:48,256:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:48,256:INFO:Creating metrics dataframe
2022-12-18 15:32:48,271:INFO:Initializing AdaBoost Regressor
2022-12-18 15:32:48,271:INFO:Total runtime is 0.3235966523488363 minutes
2022-12-18 15:32:48,277:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:48,277:INFO:Initializing create_model()
2022-12-18 15:32:48,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:48,278:INFO:Checking exceptions
2022-12-18 15:32:48,281:INFO:Importing libraries
2022-12-18 15:32:48,281:INFO:Copying training dataset
2022-12-18 15:32:48,285:INFO:Defining folds
2022-12-18 15:32:48,285:INFO:Declaring metric variables
2022-12-18 15:32:48,289:INFO:Importing untrained model
2022-12-18 15:32:48,298:INFO:AdaBoost Regressor Imported successfully
2022-12-18 15:32:48,311:INFO:Starting cross validation
2022-12-18 15:32:48,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:48,813:INFO:Calculating mean and std
2022-12-18 15:32:48,815:INFO:Creating metrics dataframe
2022-12-18 15:32:48,819:INFO:Uploading results into container
2022-12-18 15:32:48,819:INFO:Uploading model into container now
2022-12-18 15:32:48,820:INFO:master_model_container: 15
2022-12-18 15:32:48,820:INFO:display_container: 2
2022-12-18 15:32:48,821:INFO:AdaBoostRegressor(random_state=2258)
2022-12-18 15:32:48,821:INFO:create_model() successfully completed......................................
2022-12-18 15:32:48,901:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:48,902:INFO:Creating metrics dataframe
2022-12-18 15:32:48,917:INFO:Initializing Gradient Boosting Regressor
2022-12-18 15:32:48,917:INFO:Total runtime is 0.3343620538711548 minutes
2022-12-18 15:32:48,922:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:48,922:INFO:Initializing create_model()
2022-12-18 15:32:48,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:48,923:INFO:Checking exceptions
2022-12-18 15:32:48,925:INFO:Importing libraries
2022-12-18 15:32:48,926:INFO:Copying training dataset
2022-12-18 15:32:48,931:INFO:Defining folds
2022-12-18 15:32:48,931:INFO:Declaring metric variables
2022-12-18 15:32:48,935:INFO:Importing untrained model
2022-12-18 15:32:48,942:INFO:Gradient Boosting Regressor Imported successfully
2022-12-18 15:32:48,952:INFO:Starting cross validation
2022-12-18 15:32:48,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:49,520:INFO:Calculating mean and std
2022-12-18 15:32:49,522:INFO:Creating metrics dataframe
2022-12-18 15:32:49,526:INFO:Uploading results into container
2022-12-18 15:32:49,527:INFO:Uploading model into container now
2022-12-18 15:32:49,528:INFO:master_model_container: 16
2022-12-18 15:32:49,528:INFO:display_container: 2
2022-12-18 15:32:49,529:INFO:GradientBoostingRegressor(random_state=2258)
2022-12-18 15:32:49,529:INFO:create_model() successfully completed......................................
2022-12-18 15:32:49,609:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:49,610:INFO:Creating metrics dataframe
2022-12-18 15:32:49,624:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:32:49,624:INFO:Total runtime is 0.34614344040552775 minutes
2022-12-18 15:32:49,631:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:49,632:INFO:Initializing create_model()
2022-12-18 15:32:49,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:49,632:INFO:Checking exceptions
2022-12-18 15:32:49,634:INFO:Importing libraries
2022-12-18 15:32:49,634:INFO:Copying training dataset
2022-12-18 15:32:49,637:INFO:Defining folds
2022-12-18 15:32:49,637:INFO:Declaring metric variables
2022-12-18 15:32:49,644:INFO:Importing untrained model
2022-12-18 15:32:49,650:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:32:49,661:INFO:Starting cross validation
2022-12-18 15:32:49,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:50,097:INFO:Calculating mean and std
2022-12-18 15:32:50,099:INFO:Creating metrics dataframe
2022-12-18 15:32:50,102:INFO:Uploading results into container
2022-12-18 15:32:50,102:INFO:Uploading model into container now
2022-12-18 15:32:50,103:INFO:master_model_container: 17
2022-12-18 15:32:50,103:INFO:display_container: 2
2022-12-18 15:32:50,103:INFO:LGBMRegressor(random_state=2258)
2022-12-18 15:32:50,104:INFO:create_model() successfully completed......................................
2022-12-18 15:32:50,180:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:50,181:INFO:Creating metrics dataframe
2022-12-18 15:32:50,197:INFO:Initializing Dummy Regressor
2022-12-18 15:32:50,197:INFO:Total runtime is 0.3556952397028605 minutes
2022-12-18 15:32:50,203:INFO:SubProcess create_model() called ==================================
2022-12-18 15:32:50,203:INFO:Initializing create_model()
2022-12-18 15:32:50,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32E30>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:50,204:INFO:Checking exceptions
2022-12-18 15:32:50,206:INFO:Importing libraries
2022-12-18 15:32:50,206:INFO:Copying training dataset
2022-12-18 15:32:50,212:INFO:Defining folds
2022-12-18 15:32:50,212:INFO:Declaring metric variables
2022-12-18 15:32:50,217:INFO:Importing untrained model
2022-12-18 15:32:50,226:INFO:Dummy Regressor Imported successfully
2022-12-18 15:32:50,251:INFO:Starting cross validation
2022-12-18 15:32:50,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:32:50,470:INFO:Calculating mean and std
2022-12-18 15:32:50,471:INFO:Creating metrics dataframe
2022-12-18 15:32:50,479:INFO:Uploading results into container
2022-12-18 15:32:50,480:INFO:Uploading model into container now
2022-12-18 15:32:50,480:INFO:master_model_container: 18
2022-12-18 15:32:50,480:INFO:display_container: 2
2022-12-18 15:32:50,481:INFO:DummyRegressor()
2022-12-18 15:32:50,481:INFO:create_model() successfully completed......................................
2022-12-18 15:32:50,559:INFO:SubProcess create_model() end ==================================
2022-12-18 15:32:50,559:INFO:Creating metrics dataframe
2022-12-18 15:32:50,590:INFO:Initializing create_model()
2022-12-18 15:32:50,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:50,591:INFO:Checking exceptions
2022-12-18 15:32:50,597:INFO:Importing libraries
2022-12-18 15:32:50,597:INFO:Copying training dataset
2022-12-18 15:32:50,600:INFO:Defining folds
2022-12-18 15:32:50,600:INFO:Declaring metric variables
2022-12-18 15:32:50,600:INFO:Importing untrained model
2022-12-18 15:32:50,600:INFO:Declaring custom model
2022-12-18 15:32:50,601:INFO:Huber Regressor Imported successfully
2022-12-18 15:32:50,601:INFO:Cross validation set to False
2022-12-18 15:32:50,601:INFO:Fitting Model
2022-12-18 15:32:50,698:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:32:50,698:INFO:HuberRegressor()
2022-12-18 15:32:50,698:INFO:create_model() successfully completed......................................
2022-12-18 15:32:50,784:INFO:Initializing create_model()
2022-12-18 15:32:50,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=PassiveAggressiveRegressor(random_state=2258), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:50,785:INFO:Checking exceptions
2022-12-18 15:32:50,792:INFO:Importing libraries
2022-12-18 15:32:50,792:INFO:Copying training dataset
2022-12-18 15:32:50,794:INFO:Defining folds
2022-12-18 15:32:50,794:INFO:Declaring metric variables
2022-12-18 15:32:50,795:INFO:Importing untrained model
2022-12-18 15:32:50,795:INFO:Declaring custom model
2022-12-18 15:32:50,795:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:32:50,796:INFO:Cross validation set to False
2022-12-18 15:32:50,796:INFO:Fitting Model
2022-12-18 15:32:50,823:INFO:PassiveAggressiveRegressor(random_state=2258)
2022-12-18 15:32:50,823:INFO:create_model() successfully completed......................................
2022-12-18 15:32:50,908:INFO:Initializing create_model()
2022-12-18 15:32:50,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:32:50,908:INFO:Checking exceptions
2022-12-18 15:32:50,914:INFO:Importing libraries
2022-12-18 15:32:50,914:INFO:Copying training dataset
2022-12-18 15:32:50,918:INFO:Defining folds
2022-12-18 15:32:50,918:INFO:Declaring metric variables
2022-12-18 15:32:50,918:INFO:Importing untrained model
2022-12-18 15:32:50,918:INFO:Declaring custom model
2022-12-18 15:32:50,919:INFO:Dummy Regressor Imported successfully
2022-12-18 15:32:50,919:INFO:Cross validation set to False
2022-12-18 15:32:50,920:INFO:Fitting Model
2022-12-18 15:32:50,935:INFO:DummyRegressor()
2022-12-18 15:32:50,936:INFO:create_model() successfully completed......................................
2022-12-18 15:32:51,161:INFO:master_model_container: 18
2022-12-18 15:32:51,161:INFO:display_container: 2
2022-12-18 15:32:51,164:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=2258), DummyRegressor()]
2022-12-18 15:32:51,164:INFO:compare_models() successfully completed......................................
2022-12-18 15:34:09,351:INFO:Initializing compare_models()
2022-12-18 15:34:09,351:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-18 15:34:09,351:INFO:Checking exceptions
2022-12-18 15:34:09,355:INFO:Preparing display monitor
2022-12-18 15:34:09,439:INFO:Initializing Linear Regression
2022-12-18 15:34:09,440:INFO:Total runtime is 1.660585403442383e-05 minutes
2022-12-18 15:34:09,449:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:09,450:INFO:Initializing create_model()
2022-12-18 15:34:09,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:09,451:INFO:Checking exceptions
2022-12-18 15:34:09,454:INFO:Importing libraries
2022-12-18 15:34:09,454:INFO:Copying training dataset
2022-12-18 15:34:09,460:INFO:Defining folds
2022-12-18 15:34:09,461:INFO:Declaring metric variables
2022-12-18 15:34:09,468:INFO:Importing untrained model
2022-12-18 15:34:09,478:INFO:Linear Regression Imported successfully
2022-12-18 15:34:09,493:INFO:Starting cross validation
2022-12-18 15:34:09,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:09,886:INFO:Calculating mean and std
2022-12-18 15:34:09,887:INFO:Creating metrics dataframe
2022-12-18 15:34:09,894:INFO:Uploading results into container
2022-12-18 15:34:09,895:INFO:Uploading model into container now
2022-12-18 15:34:09,896:INFO:master_model_container: 19
2022-12-18 15:34:09,897:INFO:display_container: 3
2022-12-18 15:34:09,897:INFO:LinearRegression(n_jobs=-1)
2022-12-18 15:34:09,897:INFO:create_model() successfully completed......................................
2022-12-18 15:34:10,037:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:10,037:INFO:Creating metrics dataframe
2022-12-18 15:34:10,054:INFO:Initializing Lasso Regression
2022-12-18 15:34:10,054:INFO:Total runtime is 0.010261718432108562 minutes
2022-12-18 15:34:10,064:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:10,065:INFO:Initializing create_model()
2022-12-18 15:34:10,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:10,065:INFO:Checking exceptions
2022-12-18 15:34:10,068:INFO:Importing libraries
2022-12-18 15:34:10,069:INFO:Copying training dataset
2022-12-18 15:34:10,074:INFO:Defining folds
2022-12-18 15:34:10,074:INFO:Declaring metric variables
2022-12-18 15:34:10,089:INFO:Importing untrained model
2022-12-18 15:34:10,098:INFO:Lasso Regression Imported successfully
2022-12-18 15:34:10,115:INFO:Starting cross validation
2022-12-18 15:34:10,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:10,364:INFO:Calculating mean and std
2022-12-18 15:34:10,365:INFO:Creating metrics dataframe
2022-12-18 15:34:10,369:INFO:Uploading results into container
2022-12-18 15:34:10,370:INFO:Uploading model into container now
2022-12-18 15:34:10,370:INFO:master_model_container: 20
2022-12-18 15:34:10,371:INFO:display_container: 3
2022-12-18 15:34:10,371:INFO:Lasso(random_state=2258)
2022-12-18 15:34:10,371:INFO:create_model() successfully completed......................................
2022-12-18 15:34:10,465:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:10,466:INFO:Creating metrics dataframe
2022-12-18 15:34:10,480:INFO:Initializing Ridge Regression
2022-12-18 15:34:10,480:INFO:Total runtime is 0.01736197868982951 minutes
2022-12-18 15:34:10,486:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:10,487:INFO:Initializing create_model()
2022-12-18 15:34:10,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:10,488:INFO:Checking exceptions
2022-12-18 15:34:10,491:INFO:Importing libraries
2022-12-18 15:34:10,492:INFO:Copying training dataset
2022-12-18 15:34:10,499:INFO:Defining folds
2022-12-18 15:34:10,499:INFO:Declaring metric variables
2022-12-18 15:34:10,507:INFO:Importing untrained model
2022-12-18 15:34:10,513:INFO:Ridge Regression Imported successfully
2022-12-18 15:34:10,531:INFO:Starting cross validation
2022-12-18 15:34:10,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:10,805:INFO:Calculating mean and std
2022-12-18 15:34:10,808:INFO:Creating metrics dataframe
2022-12-18 15:34:10,818:INFO:Uploading results into container
2022-12-18 15:34:10,819:INFO:Uploading model into container now
2022-12-18 15:34:10,820:INFO:master_model_container: 21
2022-12-18 15:34:10,820:INFO:display_container: 3
2022-12-18 15:34:10,821:INFO:Ridge(random_state=2258)
2022-12-18 15:34:10,821:INFO:create_model() successfully completed......................................
2022-12-18 15:34:10,926:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:10,926:INFO:Creating metrics dataframe
2022-12-18 15:34:10,939:INFO:Initializing Elastic Net
2022-12-18 15:34:10,939:INFO:Total runtime is 0.02500751813252767 minutes
2022-12-18 15:34:10,946:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:10,947:INFO:Initializing create_model()
2022-12-18 15:34:10,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:10,947:INFO:Checking exceptions
2022-12-18 15:34:10,950:INFO:Importing libraries
2022-12-18 15:34:10,950:INFO:Copying training dataset
2022-12-18 15:34:10,954:INFO:Defining folds
2022-12-18 15:34:10,954:INFO:Declaring metric variables
2022-12-18 15:34:10,963:INFO:Importing untrained model
2022-12-18 15:34:10,972:INFO:Elastic Net Imported successfully
2022-12-18 15:34:11,013:INFO:Starting cross validation
2022-12-18 15:34:11,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:11,233:INFO:Calculating mean and std
2022-12-18 15:34:11,235:INFO:Creating metrics dataframe
2022-12-18 15:34:11,238:INFO:Uploading results into container
2022-12-18 15:34:11,239:INFO:Uploading model into container now
2022-12-18 15:34:11,239:INFO:master_model_container: 22
2022-12-18 15:34:11,240:INFO:display_container: 3
2022-12-18 15:34:11,240:INFO:ElasticNet(random_state=2258)
2022-12-18 15:34:11,240:INFO:create_model() successfully completed......................................
2022-12-18 15:34:11,321:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:11,321:INFO:Creating metrics dataframe
2022-12-18 15:34:11,334:INFO:Initializing Least Angle Regression
2022-12-18 15:34:11,334:INFO:Total runtime is 0.03158211310704549 minutes
2022-12-18 15:34:11,339:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:11,339:INFO:Initializing create_model()
2022-12-18 15:34:11,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:11,340:INFO:Checking exceptions
2022-12-18 15:34:11,342:INFO:Importing libraries
2022-12-18 15:34:11,343:INFO:Copying training dataset
2022-12-18 15:34:11,347:INFO:Defining folds
2022-12-18 15:34:11,347:INFO:Declaring metric variables
2022-12-18 15:34:11,354:INFO:Importing untrained model
2022-12-18 15:34:11,359:INFO:Least Angle Regression Imported successfully
2022-12-18 15:34:11,373:INFO:Starting cross validation
2022-12-18 15:34:11,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:11,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,443:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,452:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,464:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,499:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,523:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,536:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,543:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,571:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,576:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:11,592:INFO:Calculating mean and std
2022-12-18 15:34:11,595:INFO:Creating metrics dataframe
2022-12-18 15:34:11,601:INFO:Uploading results into container
2022-12-18 15:34:11,602:INFO:Uploading model into container now
2022-12-18 15:34:11,602:INFO:master_model_container: 23
2022-12-18 15:34:11,602:INFO:display_container: 3
2022-12-18 15:34:11,603:INFO:Lars(random_state=2258)
2022-12-18 15:34:11,603:INFO:create_model() successfully completed......................................
2022-12-18 15:34:11,683:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:11,683:INFO:Creating metrics dataframe
2022-12-18 15:34:11,696:INFO:Initializing Lasso Least Angle Regression
2022-12-18 15:34:11,696:INFO:Total runtime is 0.037622380256652835 minutes
2022-12-18 15:34:11,701:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:11,701:INFO:Initializing create_model()
2022-12-18 15:34:11,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:11,702:INFO:Checking exceptions
2022-12-18 15:34:11,704:INFO:Importing libraries
2022-12-18 15:34:11,704:INFO:Copying training dataset
2022-12-18 15:34:11,709:INFO:Defining folds
2022-12-18 15:34:11,709:INFO:Declaring metric variables
2022-12-18 15:34:11,715:INFO:Importing untrained model
2022-12-18 15:34:11,724:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:34:11,738:INFO:Starting cross validation
2022-12-18 15:34:11,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:11,797:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,810:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,821:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,833:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,863:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,880:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,888:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,916:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,932:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,943:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:11,963:INFO:Calculating mean and std
2022-12-18 15:34:11,964:INFO:Creating metrics dataframe
2022-12-18 15:34:11,968:INFO:Uploading results into container
2022-12-18 15:34:11,969:INFO:Uploading model into container now
2022-12-18 15:34:11,971:INFO:master_model_container: 24
2022-12-18 15:34:11,971:INFO:display_container: 3
2022-12-18 15:34:11,972:INFO:LassoLars(random_state=2258)
2022-12-18 15:34:11,972:INFO:create_model() successfully completed......................................
2022-12-18 15:34:12,051:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:12,051:INFO:Creating metrics dataframe
2022-12-18 15:34:12,063:INFO:Initializing Orthogonal Matching Pursuit
2022-12-18 15:34:12,063:INFO:Total runtime is 0.043735476334889736 minutes
2022-12-18 15:34:12,067:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:12,068:INFO:Initializing create_model()
2022-12-18 15:34:12,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:12,069:INFO:Checking exceptions
2022-12-18 15:34:12,071:INFO:Importing libraries
2022-12-18 15:34:12,071:INFO:Copying training dataset
2022-12-18 15:34:12,075:INFO:Defining folds
2022-12-18 15:34:12,075:INFO:Declaring metric variables
2022-12-18 15:34:12,080:INFO:Importing untrained model
2022-12-18 15:34:12,087:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-18 15:34:12,103:INFO:Starting cross validation
2022-12-18 15:34:12,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:12,176:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,184:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,198:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,239:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,241:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,245:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,250:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,289:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,297:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,303:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:34:12,320:INFO:Calculating mean and std
2022-12-18 15:34:12,321:INFO:Creating metrics dataframe
2022-12-18 15:34:12,325:INFO:Uploading results into container
2022-12-18 15:34:12,328:INFO:Uploading model into container now
2022-12-18 15:34:12,329:INFO:master_model_container: 25
2022-12-18 15:34:12,329:INFO:display_container: 3
2022-12-18 15:34:12,329:INFO:OrthogonalMatchingPursuit()
2022-12-18 15:34:12,329:INFO:create_model() successfully completed......................................
2022-12-18 15:34:12,408:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:12,408:INFO:Creating metrics dataframe
2022-12-18 15:34:12,421:INFO:Initializing Bayesian Ridge
2022-12-18 15:34:12,421:INFO:Total runtime is 0.049702445665995285 minutes
2022-12-18 15:34:12,427:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:12,428:INFO:Initializing create_model()
2022-12-18 15:34:12,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:12,428:INFO:Checking exceptions
2022-12-18 15:34:12,431:INFO:Importing libraries
2022-12-18 15:34:12,431:INFO:Copying training dataset
2022-12-18 15:34:12,439:INFO:Defining folds
2022-12-18 15:34:12,439:INFO:Declaring metric variables
2022-12-18 15:34:12,444:INFO:Importing untrained model
2022-12-18 15:34:12,451:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:34:12,466:INFO:Starting cross validation
2022-12-18 15:34:12,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:12,692:INFO:Calculating mean and std
2022-12-18 15:34:12,695:INFO:Creating metrics dataframe
2022-12-18 15:34:12,698:INFO:Uploading results into container
2022-12-18 15:34:12,699:INFO:Uploading model into container now
2022-12-18 15:34:12,700:INFO:master_model_container: 26
2022-12-18 15:34:12,700:INFO:display_container: 3
2022-12-18 15:34:12,700:INFO:BayesianRidge()
2022-12-18 15:34:12,700:INFO:create_model() successfully completed......................................
2022-12-18 15:34:12,781:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:12,781:INFO:Creating metrics dataframe
2022-12-18 15:34:12,795:INFO:Initializing Passive Aggressive Regressor
2022-12-18 15:34:12,795:INFO:Total runtime is 0.05593478282292684 minutes
2022-12-18 15:34:12,798:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:12,799:INFO:Initializing create_model()
2022-12-18 15:34:12,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:12,800:INFO:Checking exceptions
2022-12-18 15:34:12,803:INFO:Importing libraries
2022-12-18 15:34:12,803:INFO:Copying training dataset
2022-12-18 15:34:12,806:INFO:Defining folds
2022-12-18 15:34:12,806:INFO:Declaring metric variables
2022-12-18 15:34:12,811:INFO:Importing untrained model
2022-12-18 15:34:12,817:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:34:12,832:INFO:Starting cross validation
2022-12-18 15:34:12,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:13,179:INFO:Calculating mean and std
2022-12-18 15:34:13,181:INFO:Creating metrics dataframe
2022-12-18 15:34:13,187:INFO:Uploading results into container
2022-12-18 15:34:13,188:INFO:Uploading model into container now
2022-12-18 15:34:13,189:INFO:master_model_container: 27
2022-12-18 15:34:13,189:INFO:display_container: 3
2022-12-18 15:34:13,190:INFO:PassiveAggressiveRegressor(random_state=2258)
2022-12-18 15:34:13,190:INFO:create_model() successfully completed......................................
2022-12-18 15:34:13,277:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:13,277:INFO:Creating metrics dataframe
2022-12-18 15:34:13,289:INFO:Initializing Huber Regressor
2022-12-18 15:34:13,289:INFO:Total runtime is 0.0641664743423462 minutes
2022-12-18 15:34:13,294:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:13,295:INFO:Initializing create_model()
2022-12-18 15:34:13,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:13,295:INFO:Checking exceptions
2022-12-18 15:34:13,298:INFO:Importing libraries
2022-12-18 15:34:13,298:INFO:Copying training dataset
2022-12-18 15:34:13,304:INFO:Defining folds
2022-12-18 15:34:13,304:INFO:Declaring metric variables
2022-12-18 15:34:13,313:INFO:Importing untrained model
2022-12-18 15:34:13,318:INFO:Huber Regressor Imported successfully
2022-12-18 15:34:13,335:INFO:Starting cross validation
2022-12-18 15:34:13,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:13,474:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,474:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,477:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,489:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,592:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,594:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,611:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,636:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,675:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,681:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:13,697:INFO:Calculating mean and std
2022-12-18 15:34:13,698:INFO:Creating metrics dataframe
2022-12-18 15:34:13,702:INFO:Uploading results into container
2022-12-18 15:34:13,702:INFO:Uploading model into container now
2022-12-18 15:34:13,703:INFO:master_model_container: 28
2022-12-18 15:34:13,703:INFO:display_container: 3
2022-12-18 15:34:13,703:INFO:HuberRegressor()
2022-12-18 15:34:13,703:INFO:create_model() successfully completed......................................
2022-12-18 15:34:13,782:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:13,783:INFO:Creating metrics dataframe
2022-12-18 15:34:13,797:INFO:Initializing K Neighbors Regressor
2022-12-18 15:34:13,797:INFO:Total runtime is 0.07263090610504151 minutes
2022-12-18 15:34:13,802:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:13,802:INFO:Initializing create_model()
2022-12-18 15:34:13,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:13,803:INFO:Checking exceptions
2022-12-18 15:34:13,806:INFO:Importing libraries
2022-12-18 15:34:13,806:INFO:Copying training dataset
2022-12-18 15:34:13,811:INFO:Defining folds
2022-12-18 15:34:13,811:INFO:Declaring metric variables
2022-12-18 15:34:13,814:INFO:Importing untrained model
2022-12-18 15:34:13,820:INFO:K Neighbors Regressor Imported successfully
2022-12-18 15:34:13,835:INFO:Starting cross validation
2022-12-18 15:34:13,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:14,082:INFO:Calculating mean and std
2022-12-18 15:34:14,084:INFO:Creating metrics dataframe
2022-12-18 15:34:14,088:INFO:Uploading results into container
2022-12-18 15:34:14,088:INFO:Uploading model into container now
2022-12-18 15:34:14,089:INFO:master_model_container: 29
2022-12-18 15:34:14,089:INFO:display_container: 3
2022-12-18 15:34:14,089:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-18 15:34:14,089:INFO:create_model() successfully completed......................................
2022-12-18 15:34:14,174:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:14,174:INFO:Creating metrics dataframe
2022-12-18 15:34:14,201:INFO:Initializing Decision Tree Regressor
2022-12-18 15:34:14,201:INFO:Total runtime is 0.07937364180882772 minutes
2022-12-18 15:34:14,209:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:14,210:INFO:Initializing create_model()
2022-12-18 15:34:14,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:14,210:INFO:Checking exceptions
2022-12-18 15:34:14,214:INFO:Importing libraries
2022-12-18 15:34:14,214:INFO:Copying training dataset
2022-12-18 15:34:14,223:INFO:Defining folds
2022-12-18 15:34:14,223:INFO:Declaring metric variables
2022-12-18 15:34:14,231:INFO:Importing untrained model
2022-12-18 15:34:14,239:INFO:Decision Tree Regressor Imported successfully
2022-12-18 15:34:14,257:INFO:Starting cross validation
2022-12-18 15:34:14,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:14,515:INFO:Calculating mean and std
2022-12-18 15:34:14,518:INFO:Creating metrics dataframe
2022-12-18 15:34:14,526:INFO:Uploading results into container
2022-12-18 15:34:14,526:INFO:Uploading model into container now
2022-12-18 15:34:14,527:INFO:master_model_container: 30
2022-12-18 15:34:14,527:INFO:display_container: 3
2022-12-18 15:34:14,528:INFO:DecisionTreeRegressor(random_state=2258)
2022-12-18 15:34:14,528:INFO:create_model() successfully completed......................................
2022-12-18 15:34:14,626:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:14,627:INFO:Creating metrics dataframe
2022-12-18 15:34:14,654:INFO:Initializing Random Forest Regressor
2022-12-18 15:34:14,654:INFO:Total runtime is 0.08692191044489543 minutes
2022-12-18 15:34:14,663:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:14,664:INFO:Initializing create_model()
2022-12-18 15:34:14,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:14,664:INFO:Checking exceptions
2022-12-18 15:34:14,668:INFO:Importing libraries
2022-12-18 15:34:14,668:INFO:Copying training dataset
2022-12-18 15:34:14,677:INFO:Defining folds
2022-12-18 15:34:14,677:INFO:Declaring metric variables
2022-12-18 15:34:14,686:INFO:Importing untrained model
2022-12-18 15:34:14,695:INFO:Random Forest Regressor Imported successfully
2022-12-18 15:34:14,714:INFO:Starting cross validation
2022-12-18 15:34:14,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:16,244:INFO:Calculating mean and std
2022-12-18 15:34:16,247:INFO:Creating metrics dataframe
2022-12-18 15:34:16,253:INFO:Uploading results into container
2022-12-18 15:34:16,254:INFO:Uploading model into container now
2022-12-18 15:34:16,255:INFO:master_model_container: 31
2022-12-18 15:34:16,255:INFO:display_container: 3
2022-12-18 15:34:16,259:INFO:RandomForestRegressor(n_jobs=-1, random_state=2258)
2022-12-18 15:34:16,259:INFO:create_model() successfully completed......................................
2022-12-18 15:34:16,363:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:16,363:INFO:Creating metrics dataframe
2022-12-18 15:34:16,378:INFO:Initializing Extra Trees Regressor
2022-12-18 15:34:16,378:INFO:Total runtime is 0.11566161314646403 minutes
2022-12-18 15:34:16,384:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:16,385:INFO:Initializing create_model()
2022-12-18 15:34:16,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:16,385:INFO:Checking exceptions
2022-12-18 15:34:16,388:INFO:Importing libraries
2022-12-18 15:34:16,389:INFO:Copying training dataset
2022-12-18 15:34:16,396:INFO:Defining folds
2022-12-18 15:34:16,396:INFO:Declaring metric variables
2022-12-18 15:34:16,403:INFO:Importing untrained model
2022-12-18 15:34:16,412:INFO:Extra Trees Regressor Imported successfully
2022-12-18 15:34:16,430:INFO:Starting cross validation
2022-12-18 15:34:16,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:17,552:INFO:Calculating mean and std
2022-12-18 15:34:17,556:INFO:Creating metrics dataframe
2022-12-18 15:34:17,563:INFO:Uploading results into container
2022-12-18 15:34:17,564:INFO:Uploading model into container now
2022-12-18 15:34:17,564:INFO:master_model_container: 32
2022-12-18 15:34:17,564:INFO:display_container: 3
2022-12-18 15:34:17,565:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2258)
2022-12-18 15:34:17,565:INFO:create_model() successfully completed......................................
2022-12-18 15:34:17,647:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:17,647:INFO:Creating metrics dataframe
2022-12-18 15:34:17,665:INFO:Initializing AdaBoost Regressor
2022-12-18 15:34:17,666:INFO:Total runtime is 0.1370986541112264 minutes
2022-12-18 15:34:17,670:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:17,670:INFO:Initializing create_model()
2022-12-18 15:34:17,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:17,671:INFO:Checking exceptions
2022-12-18 15:34:17,675:INFO:Importing libraries
2022-12-18 15:34:17,675:INFO:Copying training dataset
2022-12-18 15:34:17,681:INFO:Defining folds
2022-12-18 15:34:17,681:INFO:Declaring metric variables
2022-12-18 15:34:17,688:INFO:Importing untrained model
2022-12-18 15:34:17,695:INFO:AdaBoost Regressor Imported successfully
2022-12-18 15:34:17,713:INFO:Starting cross validation
2022-12-18 15:34:17,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:18,274:INFO:Calculating mean and std
2022-12-18 15:34:18,277:INFO:Creating metrics dataframe
2022-12-18 15:34:18,281:INFO:Uploading results into container
2022-12-18 15:34:18,282:INFO:Uploading model into container now
2022-12-18 15:34:18,283:INFO:master_model_container: 33
2022-12-18 15:34:18,283:INFO:display_container: 3
2022-12-18 15:34:18,283:INFO:AdaBoostRegressor(random_state=2258)
2022-12-18 15:34:18,283:INFO:create_model() successfully completed......................................
2022-12-18 15:34:18,361:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:18,361:INFO:Creating metrics dataframe
2022-12-18 15:34:18,376:INFO:Initializing Gradient Boosting Regressor
2022-12-18 15:34:18,376:INFO:Total runtime is 0.1489481012026469 minutes
2022-12-18 15:34:18,382:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:18,382:INFO:Initializing create_model()
2022-12-18 15:34:18,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:18,382:INFO:Checking exceptions
2022-12-18 15:34:18,384:INFO:Importing libraries
2022-12-18 15:34:18,384:INFO:Copying training dataset
2022-12-18 15:34:18,389:INFO:Defining folds
2022-12-18 15:34:18,389:INFO:Declaring metric variables
2022-12-18 15:34:18,397:INFO:Importing untrained model
2022-12-18 15:34:18,403:INFO:Gradient Boosting Regressor Imported successfully
2022-12-18 15:34:18,414:INFO:Starting cross validation
2022-12-18 15:34:18,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:19,138:INFO:Calculating mean and std
2022-12-18 15:34:19,143:INFO:Creating metrics dataframe
2022-12-18 15:34:19,149:INFO:Uploading results into container
2022-12-18 15:34:19,150:INFO:Uploading model into container now
2022-12-18 15:34:19,150:INFO:master_model_container: 34
2022-12-18 15:34:19,151:INFO:display_container: 3
2022-12-18 15:34:19,151:INFO:GradientBoostingRegressor(random_state=2258)
2022-12-18 15:34:19,151:INFO:create_model() successfully completed......................................
2022-12-18 15:34:19,326:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:19,326:INFO:Creating metrics dataframe
2022-12-18 15:34:19,374:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:34:19,374:INFO:Total runtime is 0.16558713515599568 minutes
2022-12-18 15:34:19,381:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:19,381:INFO:Initializing create_model()
2022-12-18 15:34:19,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:19,382:INFO:Checking exceptions
2022-12-18 15:34:19,385:INFO:Importing libraries
2022-12-18 15:34:19,385:INFO:Copying training dataset
2022-12-18 15:34:19,394:INFO:Defining folds
2022-12-18 15:34:19,394:INFO:Declaring metric variables
2022-12-18 15:34:19,401:INFO:Importing untrained model
2022-12-18 15:34:19,413:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:34:19,436:INFO:Starting cross validation
2022-12-18 15:34:19,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:19,847:INFO:Calculating mean and std
2022-12-18 15:34:19,850:INFO:Creating metrics dataframe
2022-12-18 15:34:19,859:INFO:Uploading results into container
2022-12-18 15:34:19,860:INFO:Uploading model into container now
2022-12-18 15:34:19,860:INFO:master_model_container: 35
2022-12-18 15:34:19,861:INFO:display_container: 3
2022-12-18 15:34:19,861:INFO:LGBMRegressor(random_state=2258)
2022-12-18 15:34:19,861:INFO:create_model() successfully completed......................................
2022-12-18 15:34:19,962:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:19,962:INFO:Creating metrics dataframe
2022-12-18 15:34:19,995:INFO:Initializing Dummy Regressor
2022-12-18 15:34:19,995:INFO:Total runtime is 0.17593722740809123 minutes
2022-12-18 15:34:20,004:INFO:SubProcess create_model() called ==================================
2022-12-18 15:34:20,004:INFO:Initializing create_model()
2022-12-18 15:34:20,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42F749600>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:20,005:INFO:Checking exceptions
2022-12-18 15:34:20,008:INFO:Importing libraries
2022-12-18 15:34:20,009:INFO:Copying training dataset
2022-12-18 15:34:20,015:INFO:Defining folds
2022-12-18 15:34:20,016:INFO:Declaring metric variables
2022-12-18 15:34:20,024:INFO:Importing untrained model
2022-12-18 15:34:20,032:INFO:Dummy Regressor Imported successfully
2022-12-18 15:34:20,051:INFO:Starting cross validation
2022-12-18 15:34:20,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:34:20,350:INFO:Calculating mean and std
2022-12-18 15:34:20,355:INFO:Creating metrics dataframe
2022-12-18 15:34:20,362:INFO:Uploading results into container
2022-12-18 15:34:20,364:INFO:Uploading model into container now
2022-12-18 15:34:20,364:INFO:master_model_container: 36
2022-12-18 15:34:20,364:INFO:display_container: 3
2022-12-18 15:34:20,365:INFO:DummyRegressor()
2022-12-18 15:34:20,365:INFO:create_model() successfully completed......................................
2022-12-18 15:34:20,500:INFO:SubProcess create_model() end ==================================
2022-12-18 15:34:20,500:INFO:Creating metrics dataframe
2022-12-18 15:34:20,555:INFO:Initializing create_model()
2022-12-18 15:34:20,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:20,556:INFO:Checking exceptions
2022-12-18 15:34:20,563:INFO:Importing libraries
2022-12-18 15:34:20,563:INFO:Copying training dataset
2022-12-18 15:34:20,569:INFO:Defining folds
2022-12-18 15:34:20,569:INFO:Declaring metric variables
2022-12-18 15:34:20,570:INFO:Importing untrained model
2022-12-18 15:34:20,570:INFO:Declaring custom model
2022-12-18 15:34:20,571:INFO:Huber Regressor Imported successfully
2022-12-18 15:34:20,573:INFO:Cross validation set to False
2022-12-18 15:34:20,573:INFO:Fitting Model
2022-12-18 15:34:20,676:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:34:20,677:INFO:HuberRegressor()
2022-12-18 15:34:20,677:INFO:create_model() successfully completed......................................
2022-12-18 15:34:20,808:INFO:Initializing create_model()
2022-12-18 15:34:20,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=PassiveAggressiveRegressor(random_state=2258), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:20,808:INFO:Checking exceptions
2022-12-18 15:34:20,815:INFO:Importing libraries
2022-12-18 15:34:20,815:INFO:Copying training dataset
2022-12-18 15:34:20,820:INFO:Defining folds
2022-12-18 15:34:20,820:INFO:Declaring metric variables
2022-12-18 15:34:20,821:INFO:Importing untrained model
2022-12-18 15:34:20,821:INFO:Declaring custom model
2022-12-18 15:34:20,822:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:34:20,824:INFO:Cross validation set to False
2022-12-18 15:34:20,824:INFO:Fitting Model
2022-12-18 15:34:20,853:INFO:PassiveAggressiveRegressor(random_state=2258)
2022-12-18 15:34:20,854:INFO:create_model() successfully completed......................................
2022-12-18 15:34:20,989:INFO:Initializing create_model()
2022-12-18 15:34:20,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:20,990:INFO:Checking exceptions
2022-12-18 15:34:20,997:INFO:Importing libraries
2022-12-18 15:34:20,998:INFO:Copying training dataset
2022-12-18 15:34:21,004:INFO:Defining folds
2022-12-18 15:34:21,005:INFO:Declaring metric variables
2022-12-18 15:34:21,005:INFO:Importing untrained model
2022-12-18 15:34:21,006:INFO:Declaring custom model
2022-12-18 15:34:21,006:INFO:Dummy Regressor Imported successfully
2022-12-18 15:34:21,008:INFO:Cross validation set to False
2022-12-18 15:34:21,008:INFO:Fitting Model
2022-12-18 15:34:21,033:INFO:DummyRegressor()
2022-12-18 15:34:21,033:INFO:create_model() successfully completed......................................
2022-12-18 15:34:21,153:INFO:Initializing create_model()
2022-12-18 15:34:21,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=LassoLars(random_state=2258), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:21,154:INFO:Checking exceptions
2022-12-18 15:34:21,160:INFO:Importing libraries
2022-12-18 15:34:21,160:INFO:Copying training dataset
2022-12-18 15:34:21,164:INFO:Defining folds
2022-12-18 15:34:21,164:INFO:Declaring metric variables
2022-12-18 15:34:21,164:INFO:Importing untrained model
2022-12-18 15:34:21,165:INFO:Declaring custom model
2022-12-18 15:34:21,165:INFO:Least Angle Regression Imported successfully
2022-12-18 15:34:21,166:INFO:Cross validation set to False
2022-12-18 15:34:21,167:INFO:Fitting Model
2022-12-18 15:34:21,188:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:34:21,190:INFO:LassoLars(random_state=2258)
2022-12-18 15:34:21,190:INFO:create_model() successfully completed......................................
2022-12-18 15:34:21,296:INFO:Initializing create_model()
2022-12-18 15:34:21,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:34:21,297:INFO:Checking exceptions
2022-12-18 15:34:21,305:INFO:Importing libraries
2022-12-18 15:34:21,305:INFO:Copying training dataset
2022-12-18 15:34:21,309:INFO:Defining folds
2022-12-18 15:34:21,309:INFO:Declaring metric variables
2022-12-18 15:34:21,310:INFO:Importing untrained model
2022-12-18 15:34:21,310:INFO:Declaring custom model
2022-12-18 15:34:21,310:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:34:21,311:INFO:Cross validation set to False
2022-12-18 15:34:21,311:INFO:Fitting Model
2022-12-18 15:34:21,342:INFO:BayesianRidge()
2022-12-18 15:34:21,342:INFO:create_model() successfully completed......................................
2022-12-18 15:34:21,494:INFO:master_model_container: 36
2022-12-18 15:34:21,495:INFO:display_container: 3
2022-12-18 15:34:21,497:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=2258), DummyRegressor(), LassoLars(random_state=2258), BayesianRidge()]
2022-12-18 15:34:21,497:INFO:compare_models() successfully completed......................................
2022-12-18 15:36:48,931:INFO:Initializing compare_models()
2022-12-18 15:36:48,931:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-18 15:36:48,932:INFO:Checking exceptions
2022-12-18 15:36:48,936:INFO:Preparing display monitor
2022-12-18 15:36:49,018:INFO:Initializing Linear Regression
2022-12-18 15:36:49,019:INFO:Total runtime is 1.6621748606363933e-05 minutes
2022-12-18 15:36:49,027:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:49,028:INFO:Initializing create_model()
2022-12-18 15:36:49,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:49,028:INFO:Checking exceptions
2022-12-18 15:36:49,031:INFO:Importing libraries
2022-12-18 15:36:49,032:INFO:Copying training dataset
2022-12-18 15:36:49,038:INFO:Defining folds
2022-12-18 15:36:49,038:INFO:Declaring metric variables
2022-12-18 15:36:49,047:INFO:Importing untrained model
2022-12-18 15:36:49,056:INFO:Linear Regression Imported successfully
2022-12-18 15:36:49,073:INFO:Starting cross validation
2022-12-18 15:36:49,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:49,335:INFO:Calculating mean and std
2022-12-18 15:36:49,336:INFO:Creating metrics dataframe
2022-12-18 15:36:49,342:INFO:Uploading results into container
2022-12-18 15:36:49,343:INFO:Uploading model into container now
2022-12-18 15:36:49,344:INFO:master_model_container: 37
2022-12-18 15:36:49,344:INFO:display_container: 4
2022-12-18 15:36:49,344:INFO:LinearRegression(n_jobs=-1)
2022-12-18 15:36:49,344:INFO:create_model() successfully completed......................................
2022-12-18 15:36:49,479:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:49,479:INFO:Creating metrics dataframe
2022-12-18 15:36:49,492:INFO:Initializing Lasso Regression
2022-12-18 15:36:49,492:INFO:Total runtime is 0.007903027534484863 minutes
2022-12-18 15:36:49,498:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:49,498:INFO:Initializing create_model()
2022-12-18 15:36:49,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:49,499:INFO:Checking exceptions
2022-12-18 15:36:49,503:INFO:Importing libraries
2022-12-18 15:36:49,503:INFO:Copying training dataset
2022-12-18 15:36:49,509:INFO:Defining folds
2022-12-18 15:36:49,509:INFO:Declaring metric variables
2022-12-18 15:36:49,516:INFO:Importing untrained model
2022-12-18 15:36:49,521:INFO:Lasso Regression Imported successfully
2022-12-18 15:36:49,536:INFO:Starting cross validation
2022-12-18 15:36:49,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:49,815:INFO:Calculating mean and std
2022-12-18 15:36:49,815:INFO:Creating metrics dataframe
2022-12-18 15:36:49,820:INFO:Uploading results into container
2022-12-18 15:36:49,820:INFO:Uploading model into container now
2022-12-18 15:36:49,821:INFO:master_model_container: 38
2022-12-18 15:36:49,821:INFO:display_container: 4
2022-12-18 15:36:49,821:INFO:Lasso(random_state=2258)
2022-12-18 15:36:49,821:INFO:create_model() successfully completed......................................
2022-12-18 15:36:49,909:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:49,909:INFO:Creating metrics dataframe
2022-12-18 15:36:49,920:INFO:Initializing Ridge Regression
2022-12-18 15:36:49,920:INFO:Total runtime is 0.015042527516682943 minutes
2022-12-18 15:36:49,927:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:49,928:INFO:Initializing create_model()
2022-12-18 15:36:49,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:49,928:INFO:Checking exceptions
2022-12-18 15:36:49,931:INFO:Importing libraries
2022-12-18 15:36:49,931:INFO:Copying training dataset
2022-12-18 15:36:49,934:INFO:Defining folds
2022-12-18 15:36:49,934:INFO:Declaring metric variables
2022-12-18 15:36:49,940:INFO:Importing untrained model
2022-12-18 15:36:49,946:INFO:Ridge Regression Imported successfully
2022-12-18 15:36:49,956:INFO:Starting cross validation
2022-12-18 15:36:49,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:50,279:INFO:Calculating mean and std
2022-12-18 15:36:50,283:INFO:Creating metrics dataframe
2022-12-18 15:36:50,291:INFO:Uploading results into container
2022-12-18 15:36:50,292:INFO:Uploading model into container now
2022-12-18 15:36:50,293:INFO:master_model_container: 39
2022-12-18 15:36:50,293:INFO:display_container: 4
2022-12-18 15:36:50,294:INFO:Ridge(random_state=2258)
2022-12-18 15:36:50,294:INFO:create_model() successfully completed......................................
2022-12-18 15:36:50,419:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:50,420:INFO:Creating metrics dataframe
2022-12-18 15:36:50,431:INFO:Initializing Elastic Net
2022-12-18 15:36:50,431:INFO:Total runtime is 0.02356207768122355 minutes
2022-12-18 15:36:50,436:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:50,436:INFO:Initializing create_model()
2022-12-18 15:36:50,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:50,438:INFO:Checking exceptions
2022-12-18 15:36:50,441:INFO:Importing libraries
2022-12-18 15:36:50,442:INFO:Copying training dataset
2022-12-18 15:36:50,445:INFO:Defining folds
2022-12-18 15:36:50,445:INFO:Declaring metric variables
2022-12-18 15:36:50,453:INFO:Importing untrained model
2022-12-18 15:36:50,461:INFO:Elastic Net Imported successfully
2022-12-18 15:36:50,479:INFO:Starting cross validation
2022-12-18 15:36:50,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:50,731:INFO:Calculating mean and std
2022-12-18 15:36:50,733:INFO:Creating metrics dataframe
2022-12-18 15:36:50,736:INFO:Uploading results into container
2022-12-18 15:36:50,737:INFO:Uploading model into container now
2022-12-18 15:36:50,737:INFO:master_model_container: 40
2022-12-18 15:36:50,737:INFO:display_container: 4
2022-12-18 15:36:50,739:INFO:ElasticNet(random_state=2258)
2022-12-18 15:36:50,741:INFO:create_model() successfully completed......................................
2022-12-18 15:36:50,819:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:50,819:INFO:Creating metrics dataframe
2022-12-18 15:36:50,832:INFO:Initializing Least Angle Regression
2022-12-18 15:36:50,832:INFO:Total runtime is 0.030237853527069092 minutes
2022-12-18 15:36:50,836:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:50,837:INFO:Initializing create_model()
2022-12-18 15:36:50,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:50,837:INFO:Checking exceptions
2022-12-18 15:36:50,841:INFO:Importing libraries
2022-12-18 15:36:50,841:INFO:Copying training dataset
2022-12-18 15:36:50,847:INFO:Defining folds
2022-12-18 15:36:50,847:INFO:Declaring metric variables
2022-12-18 15:36:50,852:INFO:Importing untrained model
2022-12-18 15:36:50,860:INFO:Least Angle Regression Imported successfully
2022-12-18 15:36:50,874:INFO:Starting cross validation
2022-12-18 15:36:50,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:50,934:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:50,950:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:50,960:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:50,972:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,014:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,024:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,033:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,059:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,088:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,107:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,123:INFO:Calculating mean and std
2022-12-18 15:36:51,125:INFO:Creating metrics dataframe
2022-12-18 15:36:51,129:INFO:Uploading results into container
2022-12-18 15:36:51,129:INFO:Uploading model into container now
2022-12-18 15:36:51,130:INFO:master_model_container: 41
2022-12-18 15:36:51,130:INFO:display_container: 4
2022-12-18 15:36:51,132:INFO:Lars(random_state=2258)
2022-12-18 15:36:51,132:INFO:create_model() successfully completed......................................
2022-12-18 15:36:51,244:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:51,244:INFO:Creating metrics dataframe
2022-12-18 15:36:51,266:INFO:Initializing Lasso Least Angle Regression
2022-12-18 15:36:51,267:INFO:Total runtime is 0.037491937478383384 minutes
2022-12-18 15:36:51,278:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:51,278:INFO:Initializing create_model()
2022-12-18 15:36:51,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:51,279:INFO:Checking exceptions
2022-12-18 15:36:51,283:INFO:Importing libraries
2022-12-18 15:36:51,283:INFO:Copying training dataset
2022-12-18 15:36:51,291:INFO:Defining folds
2022-12-18 15:36:51,291:INFO:Declaring metric variables
2022-12-18 15:36:51,301:INFO:Importing untrained model
2022-12-18 15:36:51,309:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:36:51,340:INFO:Starting cross validation
2022-12-18 15:36:51,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:51,414:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,424:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,433:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,447:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,477:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,502:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,513:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,543:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,553:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,560:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:36:51,583:INFO:Calculating mean and std
2022-12-18 15:36:51,585:INFO:Creating metrics dataframe
2022-12-18 15:36:51,592:INFO:Uploading results into container
2022-12-18 15:36:51,594:INFO:Uploading model into container now
2022-12-18 15:36:51,595:INFO:master_model_container: 42
2022-12-18 15:36:51,595:INFO:display_container: 4
2022-12-18 15:36:51,595:INFO:LassoLars(random_state=2258)
2022-12-18 15:36:51,595:INFO:create_model() successfully completed......................................
2022-12-18 15:36:51,675:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:51,675:INFO:Creating metrics dataframe
2022-12-18 15:36:51,687:INFO:Initializing Orthogonal Matching Pursuit
2022-12-18 15:36:51,687:INFO:Total runtime is 0.04447999397913615 minutes
2022-12-18 15:36:51,692:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:51,693:INFO:Initializing create_model()
2022-12-18 15:36:51,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:51,693:INFO:Checking exceptions
2022-12-18 15:36:51,696:INFO:Importing libraries
2022-12-18 15:36:51,696:INFO:Copying training dataset
2022-12-18 15:36:51,699:INFO:Defining folds
2022-12-18 15:36:51,699:INFO:Declaring metric variables
2022-12-18 15:36:51,707:INFO:Importing untrained model
2022-12-18 15:36:51,713:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-18 15:36:51,728:INFO:Starting cross validation
2022-12-18 15:36:51,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:51,781:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,784:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,793:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,806:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,853:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,868:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,875:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,878:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,910:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,927:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:36:51,944:INFO:Calculating mean and std
2022-12-18 15:36:51,946:INFO:Creating metrics dataframe
2022-12-18 15:36:51,949:INFO:Uploading results into container
2022-12-18 15:36:51,950:INFO:Uploading model into container now
2022-12-18 15:36:51,950:INFO:master_model_container: 43
2022-12-18 15:36:51,950:INFO:display_container: 4
2022-12-18 15:36:51,950:INFO:OrthogonalMatchingPursuit()
2022-12-18 15:36:51,951:INFO:create_model() successfully completed......................................
2022-12-18 15:36:52,082:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:52,082:INFO:Creating metrics dataframe
2022-12-18 15:36:52,096:INFO:Initializing Bayesian Ridge
2022-12-18 15:36:52,096:INFO:Total runtime is 0.051311083634694415 minutes
2022-12-18 15:36:52,101:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:52,101:INFO:Initializing create_model()
2022-12-18 15:36:52,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:52,101:INFO:Checking exceptions
2022-12-18 15:36:52,106:INFO:Importing libraries
2022-12-18 15:36:52,106:INFO:Copying training dataset
2022-12-18 15:36:52,110:INFO:Defining folds
2022-12-18 15:36:52,110:INFO:Declaring metric variables
2022-12-18 15:36:52,116:INFO:Importing untrained model
2022-12-18 15:36:52,123:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:36:52,138:INFO:Starting cross validation
2022-12-18 15:36:52,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:52,411:INFO:Calculating mean and std
2022-12-18 15:36:52,413:INFO:Creating metrics dataframe
2022-12-18 15:36:52,416:INFO:Uploading results into container
2022-12-18 15:36:52,417:INFO:Uploading model into container now
2022-12-18 15:36:52,417:INFO:master_model_container: 44
2022-12-18 15:36:52,418:INFO:display_container: 4
2022-12-18 15:36:52,418:INFO:BayesianRidge()
2022-12-18 15:36:52,418:INFO:create_model() successfully completed......................................
2022-12-18 15:36:52,509:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:52,509:INFO:Creating metrics dataframe
2022-12-18 15:36:52,522:INFO:Initializing Passive Aggressive Regressor
2022-12-18 15:36:52,523:INFO:Total runtime is 0.05842791398366292 minutes
2022-12-18 15:36:52,528:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:52,529:INFO:Initializing create_model()
2022-12-18 15:36:52,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:52,529:INFO:Checking exceptions
2022-12-18 15:36:52,532:INFO:Importing libraries
2022-12-18 15:36:52,533:INFO:Copying training dataset
2022-12-18 15:36:52,539:INFO:Defining folds
2022-12-18 15:36:52,539:INFO:Declaring metric variables
2022-12-18 15:36:52,547:INFO:Importing untrained model
2022-12-18 15:36:52,555:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:36:52,572:INFO:Starting cross validation
2022-12-18 15:36:52,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:52,808:INFO:Calculating mean and std
2022-12-18 15:36:52,811:INFO:Creating metrics dataframe
2022-12-18 15:36:52,817:INFO:Uploading results into container
2022-12-18 15:36:52,818:INFO:Uploading model into container now
2022-12-18 15:36:52,819:INFO:master_model_container: 45
2022-12-18 15:36:52,820:INFO:display_container: 4
2022-12-18 15:36:52,821:INFO:PassiveAggressiveRegressor(random_state=2258)
2022-12-18 15:36:52,821:INFO:create_model() successfully completed......................................
2022-12-18 15:36:52,907:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:52,907:INFO:Creating metrics dataframe
2022-12-18 15:36:52,919:INFO:Initializing Huber Regressor
2022-12-18 15:36:52,920:INFO:Total runtime is 0.06504291296005249 minutes
2022-12-18 15:36:52,924:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:52,925:INFO:Initializing create_model()
2022-12-18 15:36:52,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:52,925:INFO:Checking exceptions
2022-12-18 15:36:52,928:INFO:Importing libraries
2022-12-18 15:36:52,928:INFO:Copying training dataset
2022-12-18 15:36:52,932:INFO:Defining folds
2022-12-18 15:36:52,932:INFO:Declaring metric variables
2022-12-18 15:36:52,939:INFO:Importing untrained model
2022-12-18 15:36:52,945:INFO:Huber Regressor Imported successfully
2022-12-18 15:36:52,962:INFO:Starting cross validation
2022-12-18 15:36:52,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:53,100:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,107:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,113:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,123:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,223:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,224:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,238:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,257:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,302:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,305:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:53,322:INFO:Calculating mean and std
2022-12-18 15:36:53,324:INFO:Creating metrics dataframe
2022-12-18 15:36:53,328:INFO:Uploading results into container
2022-12-18 15:36:53,328:INFO:Uploading model into container now
2022-12-18 15:36:53,329:INFO:master_model_container: 46
2022-12-18 15:36:53,329:INFO:display_container: 4
2022-12-18 15:36:53,330:INFO:HuberRegressor()
2022-12-18 15:36:53,330:INFO:create_model() successfully completed......................................
2022-12-18 15:36:53,422:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:53,422:INFO:Creating metrics dataframe
2022-12-18 15:36:53,434:INFO:Initializing K Neighbors Regressor
2022-12-18 15:36:53,434:INFO:Total runtime is 0.07361189921696981 minutes
2022-12-18 15:36:53,439:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:53,440:INFO:Initializing create_model()
2022-12-18 15:36:53,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:53,440:INFO:Checking exceptions
2022-12-18 15:36:53,443:INFO:Importing libraries
2022-12-18 15:36:53,443:INFO:Copying training dataset
2022-12-18 15:36:53,447:INFO:Defining folds
2022-12-18 15:36:53,447:INFO:Declaring metric variables
2022-12-18 15:36:53,454:INFO:Importing untrained model
2022-12-18 15:36:53,462:INFO:K Neighbors Regressor Imported successfully
2022-12-18 15:36:53,476:INFO:Starting cross validation
2022-12-18 15:36:53,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:53,731:INFO:Calculating mean and std
2022-12-18 15:36:53,733:INFO:Creating metrics dataframe
2022-12-18 15:36:53,740:INFO:Uploading results into container
2022-12-18 15:36:53,741:INFO:Uploading model into container now
2022-12-18 15:36:53,741:INFO:master_model_container: 47
2022-12-18 15:36:53,741:INFO:display_container: 4
2022-12-18 15:36:53,742:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-18 15:36:53,742:INFO:create_model() successfully completed......................................
2022-12-18 15:36:53,821:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:53,821:INFO:Creating metrics dataframe
2022-12-18 15:36:53,835:INFO:Initializing Decision Tree Regressor
2022-12-18 15:36:53,835:INFO:Total runtime is 0.08028034766515096 minutes
2022-12-18 15:36:53,841:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:53,841:INFO:Initializing create_model()
2022-12-18 15:36:53,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:53,842:INFO:Checking exceptions
2022-12-18 15:36:53,844:INFO:Importing libraries
2022-12-18 15:36:53,844:INFO:Copying training dataset
2022-12-18 15:36:53,848:INFO:Defining folds
2022-12-18 15:36:53,848:INFO:Declaring metric variables
2022-12-18 15:36:53,854:INFO:Importing untrained model
2022-12-18 15:36:53,860:INFO:Decision Tree Regressor Imported successfully
2022-12-18 15:36:53,876:INFO:Starting cross validation
2022-12-18 15:36:53,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:54,099:INFO:Calculating mean and std
2022-12-18 15:36:54,101:INFO:Creating metrics dataframe
2022-12-18 15:36:54,105:INFO:Uploading results into container
2022-12-18 15:36:54,106:INFO:Uploading model into container now
2022-12-18 15:36:54,107:INFO:master_model_container: 48
2022-12-18 15:36:54,107:INFO:display_container: 4
2022-12-18 15:36:54,107:INFO:DecisionTreeRegressor(random_state=2258)
2022-12-18 15:36:54,107:INFO:create_model() successfully completed......................................
2022-12-18 15:36:54,190:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:54,191:INFO:Creating metrics dataframe
2022-12-18 15:36:54,204:INFO:Initializing Random Forest Regressor
2022-12-18 15:36:54,204:INFO:Total runtime is 0.0864402969678243 minutes
2022-12-18 15:36:54,209:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:54,210:INFO:Initializing create_model()
2022-12-18 15:36:54,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:54,210:INFO:Checking exceptions
2022-12-18 15:36:54,213:INFO:Importing libraries
2022-12-18 15:36:54,213:INFO:Copying training dataset
2022-12-18 15:36:54,217:INFO:Defining folds
2022-12-18 15:36:54,217:INFO:Declaring metric variables
2022-12-18 15:36:54,224:INFO:Importing untrained model
2022-12-18 15:36:54,231:INFO:Random Forest Regressor Imported successfully
2022-12-18 15:36:54,241:INFO:Starting cross validation
2022-12-18 15:36:54,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:55,790:INFO:Calculating mean and std
2022-12-18 15:36:55,792:INFO:Creating metrics dataframe
2022-12-18 15:36:55,795:INFO:Uploading results into container
2022-12-18 15:36:55,796:INFO:Uploading model into container now
2022-12-18 15:36:55,796:INFO:master_model_container: 49
2022-12-18 15:36:55,797:INFO:display_container: 4
2022-12-18 15:36:55,797:INFO:RandomForestRegressor(n_jobs=-1, random_state=2258)
2022-12-18 15:36:55,798:INFO:create_model() successfully completed......................................
2022-12-18 15:36:55,877:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:55,877:INFO:Creating metrics dataframe
2022-12-18 15:36:55,891:INFO:Initializing Extra Trees Regressor
2022-12-18 15:36:55,891:INFO:Total runtime is 0.11455558935801188 minutes
2022-12-18 15:36:55,897:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:55,897:INFO:Initializing create_model()
2022-12-18 15:36:55,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:55,897:INFO:Checking exceptions
2022-12-18 15:36:55,899:INFO:Importing libraries
2022-12-18 15:36:55,899:INFO:Copying training dataset
2022-12-18 15:36:55,905:INFO:Defining folds
2022-12-18 15:36:55,905:INFO:Declaring metric variables
2022-12-18 15:36:55,911:INFO:Importing untrained model
2022-12-18 15:36:55,917:INFO:Extra Trees Regressor Imported successfully
2022-12-18 15:36:55,935:INFO:Starting cross validation
2022-12-18 15:36:55,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:57,043:INFO:Calculating mean and std
2022-12-18 15:36:57,044:INFO:Creating metrics dataframe
2022-12-18 15:36:57,048:INFO:Uploading results into container
2022-12-18 15:36:57,051:INFO:Uploading model into container now
2022-12-18 15:36:57,052:INFO:master_model_container: 50
2022-12-18 15:36:57,052:INFO:display_container: 4
2022-12-18 15:36:57,053:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2258)
2022-12-18 15:36:57,053:INFO:create_model() successfully completed......................................
2022-12-18 15:36:57,141:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:57,141:INFO:Creating metrics dataframe
2022-12-18 15:36:57,163:INFO:Initializing AdaBoost Regressor
2022-12-18 15:36:57,163:INFO:Total runtime is 0.13576000928878784 minutes
2022-12-18 15:36:57,170:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:57,170:INFO:Initializing create_model()
2022-12-18 15:36:57,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:57,171:INFO:Checking exceptions
2022-12-18 15:36:57,174:INFO:Importing libraries
2022-12-18 15:36:57,174:INFO:Copying training dataset
2022-12-18 15:36:57,180:INFO:Defining folds
2022-12-18 15:36:57,180:INFO:Declaring metric variables
2022-12-18 15:36:57,188:INFO:Importing untrained model
2022-12-18 15:36:57,196:INFO:AdaBoost Regressor Imported successfully
2022-12-18 15:36:57,213:INFO:Starting cross validation
2022-12-18 15:36:57,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:57,730:INFO:Calculating mean and std
2022-12-18 15:36:57,733:INFO:Creating metrics dataframe
2022-12-18 15:36:57,737:INFO:Uploading results into container
2022-12-18 15:36:57,737:INFO:Uploading model into container now
2022-12-18 15:36:57,738:INFO:master_model_container: 51
2022-12-18 15:36:57,738:INFO:display_container: 4
2022-12-18 15:36:57,739:INFO:AdaBoostRegressor(random_state=2258)
2022-12-18 15:36:57,740:INFO:create_model() successfully completed......................................
2022-12-18 15:36:57,818:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:57,818:INFO:Creating metrics dataframe
2022-12-18 15:36:57,832:INFO:Initializing Gradient Boosting Regressor
2022-12-18 15:36:57,833:INFO:Total runtime is 0.14691915114720663 minutes
2022-12-18 15:36:57,836:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:57,837:INFO:Initializing create_model()
2022-12-18 15:36:57,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:57,837:INFO:Checking exceptions
2022-12-18 15:36:57,840:INFO:Importing libraries
2022-12-18 15:36:57,840:INFO:Copying training dataset
2022-12-18 15:36:57,844:INFO:Defining folds
2022-12-18 15:36:57,844:INFO:Declaring metric variables
2022-12-18 15:36:57,849:INFO:Importing untrained model
2022-12-18 15:36:57,857:INFO:Gradient Boosting Regressor Imported successfully
2022-12-18 15:36:57,868:INFO:Starting cross validation
2022-12-18 15:36:57,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:58,417:INFO:Calculating mean and std
2022-12-18 15:36:58,419:INFO:Creating metrics dataframe
2022-12-18 15:36:58,422:INFO:Uploading results into container
2022-12-18 15:36:58,423:INFO:Uploading model into container now
2022-12-18 15:36:58,423:INFO:master_model_container: 52
2022-12-18 15:36:58,423:INFO:display_container: 4
2022-12-18 15:36:58,425:INFO:GradientBoostingRegressor(random_state=2258)
2022-12-18 15:36:58,425:INFO:create_model() successfully completed......................................
2022-12-18 15:36:58,504:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:58,504:INFO:Creating metrics dataframe
2022-12-18 15:36:58,518:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:36:58,518:INFO:Total runtime is 0.15833600362141928 minutes
2022-12-18 15:36:58,523:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:58,523:INFO:Initializing create_model()
2022-12-18 15:36:58,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:58,524:INFO:Checking exceptions
2022-12-18 15:36:58,526:INFO:Importing libraries
2022-12-18 15:36:58,527:INFO:Copying training dataset
2022-12-18 15:36:58,532:INFO:Defining folds
2022-12-18 15:36:58,532:INFO:Declaring metric variables
2022-12-18 15:36:58,538:INFO:Importing untrained model
2022-12-18 15:36:58,545:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:36:58,555:INFO:Starting cross validation
2022-12-18 15:36:58,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:58,972:INFO:Calculating mean and std
2022-12-18 15:36:58,973:INFO:Creating metrics dataframe
2022-12-18 15:36:58,977:INFO:Uploading results into container
2022-12-18 15:36:58,978:INFO:Uploading model into container now
2022-12-18 15:36:58,978:INFO:master_model_container: 53
2022-12-18 15:36:58,979:INFO:display_container: 4
2022-12-18 15:36:58,981:INFO:LGBMRegressor(random_state=2258)
2022-12-18 15:36:58,981:INFO:create_model() successfully completed......................................
2022-12-18 15:36:59,069:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:59,069:INFO:Creating metrics dataframe
2022-12-18 15:36:59,084:INFO:Initializing Dummy Regressor
2022-12-18 15:36:59,084:INFO:Total runtime is 0.16777823368708294 minutes
2022-12-18 15:36:59,090:INFO:SubProcess create_model() called ==================================
2022-12-18 15:36:59,091:INFO:Initializing create_model()
2022-12-18 15:36:59,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711EFE0>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:59,091:INFO:Checking exceptions
2022-12-18 15:36:59,093:INFO:Importing libraries
2022-12-18 15:36:59,093:INFO:Copying training dataset
2022-12-18 15:36:59,102:INFO:Defining folds
2022-12-18 15:36:59,102:INFO:Declaring metric variables
2022-12-18 15:36:59,110:INFO:Importing untrained model
2022-12-18 15:36:59,119:INFO:Dummy Regressor Imported successfully
2022-12-18 15:36:59,133:INFO:Starting cross validation
2022-12-18 15:36:59,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:36:59,360:INFO:Calculating mean and std
2022-12-18 15:36:59,364:INFO:Creating metrics dataframe
2022-12-18 15:36:59,370:INFO:Uploading results into container
2022-12-18 15:36:59,371:INFO:Uploading model into container now
2022-12-18 15:36:59,371:INFO:master_model_container: 54
2022-12-18 15:36:59,371:INFO:display_container: 4
2022-12-18 15:36:59,372:INFO:DummyRegressor()
2022-12-18 15:36:59,372:INFO:create_model() successfully completed......................................
2022-12-18 15:36:59,454:INFO:SubProcess create_model() end ==================================
2022-12-18 15:36:59,455:INFO:Creating metrics dataframe
2022-12-18 15:36:59,484:INFO:Initializing create_model()
2022-12-18 15:36:59,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:59,484:INFO:Checking exceptions
2022-12-18 15:36:59,489:INFO:Importing libraries
2022-12-18 15:36:59,489:INFO:Copying training dataset
2022-12-18 15:36:59,493:INFO:Defining folds
2022-12-18 15:36:59,493:INFO:Declaring metric variables
2022-12-18 15:36:59,493:INFO:Importing untrained model
2022-12-18 15:36:59,493:INFO:Declaring custom model
2022-12-18 15:36:59,494:INFO:Huber Regressor Imported successfully
2022-12-18 15:36:59,494:INFO:Cross validation set to False
2022-12-18 15:36:59,495:INFO:Fitting Model
2022-12-18 15:36:59,559:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:36:59,560:INFO:HuberRegressor()
2022-12-18 15:36:59,561:INFO:create_model() successfully completed......................................
2022-12-18 15:36:59,650:INFO:Initializing create_model()
2022-12-18 15:36:59,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=PassiveAggressiveRegressor(random_state=2258), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:59,652:INFO:Checking exceptions
2022-12-18 15:36:59,658:INFO:Importing libraries
2022-12-18 15:36:59,658:INFO:Copying training dataset
2022-12-18 15:36:59,662:INFO:Defining folds
2022-12-18 15:36:59,662:INFO:Declaring metric variables
2022-12-18 15:36:59,662:INFO:Importing untrained model
2022-12-18 15:36:59,662:INFO:Declaring custom model
2022-12-18 15:36:59,664:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:36:59,665:INFO:Cross validation set to False
2022-12-18 15:36:59,665:INFO:Fitting Model
2022-12-18 15:36:59,680:INFO:PassiveAggressiveRegressor(random_state=2258)
2022-12-18 15:36:59,680:INFO:create_model() successfully completed......................................
2022-12-18 15:36:59,766:INFO:Initializing create_model()
2022-12-18 15:36:59,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:36:59,766:INFO:Checking exceptions
2022-12-18 15:36:59,771:INFO:Importing libraries
2022-12-18 15:36:59,771:INFO:Copying training dataset
2022-12-18 15:36:59,773:INFO:Defining folds
2022-12-18 15:36:59,773:INFO:Declaring metric variables
2022-12-18 15:36:59,774:INFO:Importing untrained model
2022-12-18 15:36:59,774:INFO:Declaring custom model
2022-12-18 15:36:59,774:INFO:Dummy Regressor Imported successfully
2022-12-18 15:36:59,775:INFO:Cross validation set to False
2022-12-18 15:36:59,775:INFO:Fitting Model
2022-12-18 15:36:59,790:INFO:DummyRegressor()
2022-12-18 15:36:59,790:INFO:create_model() successfully completed......................................
2022-12-18 15:36:59,917:INFO:master_model_container: 54
2022-12-18 15:36:59,918:INFO:display_container: 4
2022-12-18 15:36:59,919:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=2258), DummyRegressor()]
2022-12-18 15:36:59,919:INFO:compare_models() successfully completed......................................
2022-12-18 15:38:53,277:INFO:Initializing create_model()
2022-12-18 15:38:53,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=llar, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:38:53,278:INFO:Checking exceptions
2022-12-18 15:38:53,333:INFO:Importing libraries
2022-12-18 15:38:53,334:INFO:Copying training dataset
2022-12-18 15:38:53,341:INFO:Defining folds
2022-12-18 15:38:53,341:INFO:Declaring metric variables
2022-12-18 15:38:53,347:INFO:Importing untrained model
2022-12-18 15:38:53,358:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:38:53,375:INFO:Starting cross validation
2022-12-18 15:38:53,377:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:38:53,670:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:53,688:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:53,700:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:53,719:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,157:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,179:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,228:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,243:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,636:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,657:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,727:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:54,752:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,069:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,070:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,103:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,138:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,440:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,477:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,506:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,644:INFO:Calculating mean and std
2022-12-18 15:38:55,646:INFO:Creating metrics dataframe
2022-12-18 15:38:55,653:INFO:Finalizing model
2022-12-18 15:38:55,669:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:38:55,677:INFO:Uploading results into container
2022-12-18 15:38:55,678:INFO:Uploading model into container now
2022-12-18 15:38:55,700:INFO:master_model_container: 55
2022-12-18 15:38:55,701:INFO:display_container: 5
2022-12-18 15:38:55,701:INFO:LassoLars(random_state=2258)
2022-12-18 15:38:55,702:INFO:create_model() successfully completed......................................
2022-12-18 15:39:17,236:INFO:Initializing create_model()
2022-12-18 15:39:17,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, estimator=llar, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:39:17,237:INFO:Checking exceptions
2022-12-18 15:39:17,302:INFO:Importing libraries
2022-12-18 15:39:17,304:INFO:Copying training dataset
2022-12-18 15:39:17,314:INFO:Defining folds
2022-12-18 15:39:17,314:INFO:Declaring metric variables
2022-12-18 15:39:17,321:INFO:Importing untrained model
2022-12-18 15:39:17,331:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:39:17,348:INFO:Starting cross validation
2022-12-18 15:39:17,350:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:39:17,471:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,491:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,580:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,699:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,858:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,887:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,906:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:17,959:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,023:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,037:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,181:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,185:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,204:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,205:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,307:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,307:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,364:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,374:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,408:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,439:INFO:Calculating mean and std
2022-12-18 15:39:18,442:INFO:Creating metrics dataframe
2022-12-18 15:39:18,452:INFO:Finalizing model
2022-12-18 15:39:18,483:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:39:18,496:INFO:Uploading results into container
2022-12-18 15:39:18,498:INFO:Uploading model into container now
2022-12-18 15:39:18,523:INFO:master_model_container: 56
2022-12-18 15:39:18,523:INFO:display_container: 6
2022-12-18 15:39:18,524:INFO:LassoLars(random_state=2258)
2022-12-18 15:39:18,524:INFO:create_model() successfully completed......................................
2022-12-18 15:40:06,346:INFO:Initializing plot_model()
2022-12-18 15:40:06,347:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LassoLars(random_state=2258), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, system=True)
2022-12-18 15:40:06,347:INFO:Checking exceptions
2022-12-18 15:40:06,355:INFO:Preloading libraries
2022-12-18 15:40:06,356:INFO:Copying training dataset
2022-12-18 15:40:06,356:INFO:Plot type: residuals
2022-12-18 15:40:06,597:INFO:Fitting Model
2022-12-18 15:40:06,598:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LassoLars was fitted with feature names
  warnings.warn(

2022-12-18 15:40:06,641:INFO:Scoring test/hold-out set
2022-12-18 15:40:07,502:INFO:Visual Rendered Successfully
2022-12-18 15:40:07,592:INFO:plot_model() successfully completed......................................
2022-12-18 15:40:30,334:INFO:Initializing plot_model()
2022-12-18 15:40:30,334:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LassoLars(random_state=2258), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, system=True)
2022-12-18 15:40:30,335:INFO:Checking exceptions
2022-12-18 15:40:30,342:INFO:Preloading libraries
2022-12-18 15:40:30,343:INFO:Copying training dataset
2022-12-18 15:40:30,343:INFO:Plot type: vc
2022-12-18 15:40:30,344:INFO:Determining param_name
2022-12-18 15:40:30,344:INFO:param_name: alpha
2022-12-18 15:40:30,475:INFO:Fitting Model
2022-12-18 15:40:30,543:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,545:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,546:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,555:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,556:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,559:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,560:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,567:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,569:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,570:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,575:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,581:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,581:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,582:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,592:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,593:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,594:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,595:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,603:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,603:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,605:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,608:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,617:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,637:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,637:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,643:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,651:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,654:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,662:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,665:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,666:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,667:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,674:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,677:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,682:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,685:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,686:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,695:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,696:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,699:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,706:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,711:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,743:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,752:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,758:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,763:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,764:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,767:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,774:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,781:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,786:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,793:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,803:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,816:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,820:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,825:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,828:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,842:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,848:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,853:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,854:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,857:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,865:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,866:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,870:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,877:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,882:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,886:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,904:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,904:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,916:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,916:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,923:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,926:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,927:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,935:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,936:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,950:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,953:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,927:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,966:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,969:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,982:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,984:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,987:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:30,997:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,002:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,003:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,007:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,009:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,014:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,016:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,018:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,030:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,031:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,035:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:40:31,615:INFO:Visual Rendered Successfully
2022-12-18 15:40:31,792:INFO:plot_model() successfully completed......................................
2022-12-18 15:40:53,713:INFO:Initializing plot_model()
2022-12-18 15:40:53,713:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LassoLars(random_state=2258), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C42F749240>, system=True)
2022-12-18 15:40:53,713:INFO:Checking exceptions
2022-12-18 15:40:53,722:INFO:Preloading libraries
2022-12-18 15:40:53,723:INFO:Copying training dataset
2022-12-18 15:40:53,723:INFO:Plot type: error
2022-12-18 15:40:53,936:INFO:Fitting Model
2022-12-18 15:40:53,937:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LassoLars was fitted with feature names
  warnings.warn(

2022-12-18 15:40:53,937:INFO:Scoring test/hold-out set
2022-12-18 15:40:54,987:INFO:Visual Rendered Successfully
2022-12-18 15:40:55,280:INFO:plot_model() successfully completed......................................
2022-12-18 15:41:11,510:INFO:PyCaret ClassificationExperiment
2022-12-18 15:41:11,511:INFO:Logging name: clf-default-name
2022-12-18 15:41:11,511:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-18 15:41:11,511:INFO:version 3.0.0.rc4
2022-12-18 15:41:11,511:INFO:Initializing setup()
2022-12-18 15:41:11,511:INFO:self.USI: 8262
2022-12-18 15:41:11,511:INFO:self.variable_keys: {'exp_name_log', 'y', 'X', '_available_plots', 'seed', '_gpu_n_jobs_param', 'idx', 'n_jobs_param', 'variable_keys', 'html_param', 'fold_shuffle_param', 'fold_groups_param', '_all_metrics', 'memory', 'pipeline', 'data', 'logging_param', 'X_test', 'fix_imbalance', 'y_test', 'USI', '_is_multiclass', 'log_plots_param', 'gpu_param', 'X_train', '_all_models_internal', 'exp_id', 'target_param', '_ml_usecase', 'y_train', 'master_model_container', '_all_models', 'display_container', 'fold_generator'}
2022-12-18 15:41:11,511:INFO:Checking environment
2022-12-18 15:41:11,511:INFO:python_version: 3.10.4
2022-12-18 15:41:11,511:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-12-18 15:41:11,511:INFO:machine: AMD64
2022-12-18 15:41:11,511:INFO:platform: Windows-10-10.0.19045-SP0
2022-12-18 15:41:11,512:INFO:Memory: svmem(total=8503136256, available=1588625408, percent=81.3, used=6914510848, free=1588625408)
2022-12-18 15:41:11,512:INFO:Physical Core: 2
2022-12-18 15:41:11,512:INFO:Logical Core: 4
2022-12-18 15:41:11,512:INFO:Checking libraries
2022-12-18 15:41:11,512:INFO:System:
2022-12-18 15:41:11,513:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-12-18 15:41:11,513:INFO:executable: c:\Python3.10\python.exe
2022-12-18 15:41:11,513:INFO:   machine: Windows-10-10.0.19045-SP0
2022-12-18 15:41:11,513:INFO:PyCaret required dependencies:
2022-12-18 15:41:11,513:INFO:                 pip: 22.2.2
2022-12-18 15:41:11,513:INFO:          setuptools: 58.1.0
2022-12-18 15:41:11,513:INFO:             pycaret: 3.0.0rc4
2022-12-18 15:41:11,514:INFO:             IPython: 8.4.0
2022-12-18 15:41:11,514:INFO:          ipywidgets: 8.0.2
2022-12-18 15:41:11,514:INFO:                tqdm: 4.64.0
2022-12-18 15:41:11,514:INFO:               numpy: 1.22.1
2022-12-18 15:41:11,514:INFO:              pandas: 1.4.2
2022-12-18 15:41:11,514:INFO:              jinja2: 3.1.2
2022-12-18 15:41:11,514:INFO:               scipy: 1.8.1
2022-12-18 15:41:11,514:INFO:              joblib: 1.2.0
2022-12-18 15:41:11,514:INFO:             sklearn: 1.1.2
2022-12-18 15:41:11,514:INFO:                pyod: 1.0.6
2022-12-18 15:41:11,515:INFO:            imblearn: 0.9.1
2022-12-18 15:41:11,515:INFO:   category_encoders: 2.5.1.post0
2022-12-18 15:41:11,515:INFO:            lightgbm: 3.3.3
2022-12-18 15:41:11,515:INFO:               numba: 0.55.2
2022-12-18 15:41:11,515:INFO:            requests: 2.28.1
2022-12-18 15:41:11,515:INFO:          matplotlib: 3.5.1
2022-12-18 15:41:11,515:INFO:          scikitplot: 0.3.7
2022-12-18 15:41:11,516:INFO:         yellowbrick: 1.5
2022-12-18 15:41:11,516:INFO:              plotly: 5.11.0
2022-12-18 15:41:11,516:INFO:             kaleido: 0.2.1
2022-12-18 15:41:11,516:INFO:         statsmodels: 0.13.5
2022-12-18 15:41:11,517:INFO:              sktime: 0.13.4
2022-12-18 15:41:11,517:INFO:               tbats: 1.1.1
2022-12-18 15:41:11,517:INFO:            pmdarima: 1.8.5
2022-12-18 15:41:11,517:INFO:              psutil: 5.9.1
2022-12-18 15:41:11,517:INFO:PyCaret optional dependencies:
2022-12-18 15:41:11,518:INFO:                shap: Not installed
2022-12-18 15:41:11,518:INFO:           interpret: Not installed
2022-12-18 15:41:11,518:INFO:                umap: Not installed
2022-12-18 15:41:11,518:INFO:    pandas_profiling: Not installed
2022-12-18 15:41:11,518:INFO:  explainerdashboard: Not installed
2022-12-18 15:41:11,518:INFO:             autoviz: Not installed
2022-12-18 15:41:11,518:INFO:           fairlearn: Not installed
2022-12-18 15:41:11,518:INFO:             xgboost: Not installed
2022-12-18 15:41:11,518:INFO:            catboost: Not installed
2022-12-18 15:41:11,518:INFO:              kmodes: Not installed
2022-12-18 15:41:11,518:INFO:             mlxtend: Not installed
2022-12-18 15:41:11,518:INFO:       statsforecast: Not installed
2022-12-18 15:41:11,518:INFO:        tune_sklearn: Not installed
2022-12-18 15:41:11,518:INFO:                 ray: Not installed
2022-12-18 15:41:11,519:INFO:            hyperopt: Not installed
2022-12-18 15:41:11,519:INFO:              optuna: Not installed
2022-12-18 15:41:11,519:INFO:               skopt: Not installed
2022-12-18 15:41:11,519:INFO:              mlflow: Not installed
2022-12-18 15:41:11,519:INFO:              gradio: Not installed
2022-12-18 15:41:11,519:INFO:             fastapi: Not installed
2022-12-18 15:41:11,519:INFO:             uvicorn: Not installed
2022-12-18 15:41:11,519:INFO:              m2cgen: Not installed
2022-12-18 15:41:11,519:INFO:           evidently: Not installed
2022-12-18 15:41:11,519:INFO:                nltk: 3.7
2022-12-18 15:41:11,520:INFO:            pyLDAvis: Not installed
2022-12-18 15:41:11,520:INFO:              gensim: Not installed
2022-12-18 15:41:11,520:INFO:               spacy: 3.4.3
2022-12-18 15:41:11,520:INFO:           wordcloud: Not installed
2022-12-18 15:41:11,520:INFO:            textblob: Not installed
2022-12-18 15:41:11,520:INFO:               fugue: Not installed
2022-12-18 15:41:11,520:INFO:           streamlit: Not installed
2022-12-18 15:41:11,520:INFO:             prophet: Not installed
2022-12-18 15:41:11,520:INFO:None
2022-12-18 15:41:11,521:INFO:Set up data.
2022-12-18 15:41:11,529:INFO:Set up train/test split.
2022-12-18 15:41:11,537:INFO:Set up index.
2022-12-18 15:41:11,538:INFO:Assigning column types.
2022-12-18 15:41:11,543:INFO:Set up folding strategy.
2022-12-18 15:41:11,543:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-18 15:41:11,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:41:11,632:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:41:11,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:41:11,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:41:11,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,776:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-18 15:41:11,854:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:41:11,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,948:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:41:11,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:11,991:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-12-18 15:41:12,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,203:INFO:Preparing preprocessing pipeline...
2022-12-18 15:41:12,219:INFO:Set up simple imputation.
2022-12-18 15:41:12,219:INFO:Set up variance threshold.
2022-12-18 15:41:12,279:INFO:Finished creating preprocessing pipeline.
2022-12-18 15:41:12,288:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-18 15:41:12,288:INFO:Creating final display dataframe.
2022-12-18 15:41:12,612:INFO:Setup display_container:                     Description             Value
0                    Session id              6348
1                        Target              area
2                   Target type            Binary
3           Original data shape          (517, 9)
4        Transformed data shape          (517, 9)
5   Transformed train set shape          (361, 9)
6    Transformed test set shape          (156, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation          constant
12       Low variance threshold                 0
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              8262
2022-12-18 15:41:12,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:41:12,919:INFO:setup() successfully completed in 1.41s...............
2022-12-18 15:41:21,971:INFO:Initializing compare_models()
2022-12-18 15:41:21,971:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-12-18 15:41:21,971:INFO:Checking exceptions
2022-12-18 15:41:21,978:INFO:Preparing display monitor
2022-12-18 15:41:22,050:INFO:Initializing Logistic Regression
2022-12-18 15:41:22,051:INFO:Total runtime is 1.9510587056477863e-05 minutes
2022-12-18 15:41:22,064:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:22,065:INFO:Initializing create_model()
2022-12-18 15:41:22,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:22,065:INFO:Checking exceptions
2022-12-18 15:41:22,068:INFO:Importing libraries
2022-12-18 15:41:22,069:INFO:Copying training dataset
2022-12-18 15:41:22,074:INFO:Defining folds
2022-12-18 15:41:22,074:INFO:Declaring metric variables
2022-12-18 15:41:22,080:INFO:Importing untrained model
2022-12-18 15:41:22,092:INFO:Logistic Regression Imported successfully
2022-12-18 15:41:22,110:INFO:Starting cross validation
2022-12-18 15:41:22,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:23,969:INFO:Calculating mean and std
2022-12-18 15:41:23,972:INFO:Creating metrics dataframe
2022-12-18 15:41:23,976:INFO:Uploading results into container
2022-12-18 15:41:23,977:INFO:Uploading model into container now
2022-12-18 15:41:23,977:INFO:master_model_container: 1
2022-12-18 15:41:23,977:INFO:display_container: 2
2022-12-18 15:41:23,978:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6348, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-18 15:41:23,979:INFO:create_model() successfully completed......................................
2022-12-18 15:41:24,072:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:24,072:INFO:Creating metrics dataframe
2022-12-18 15:41:24,082:INFO:Initializing K Neighbors Classifier
2022-12-18 15:41:24,082:INFO:Total runtime is 0.03386292457580567 minutes
2022-12-18 15:41:24,088:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:24,089:INFO:Initializing create_model()
2022-12-18 15:41:24,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:24,089:INFO:Checking exceptions
2022-12-18 15:41:24,092:INFO:Importing libraries
2022-12-18 15:41:24,092:INFO:Copying training dataset
2022-12-18 15:41:24,098:INFO:Defining folds
2022-12-18 15:41:24,098:INFO:Declaring metric variables
2022-12-18 15:41:24,106:INFO:Importing untrained model
2022-12-18 15:41:24,110:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:41:24,125:INFO:Starting cross validation
2022-12-18 15:41:24,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:24,598:INFO:Calculating mean and std
2022-12-18 15:41:24,600:INFO:Creating metrics dataframe
2022-12-18 15:41:24,606:INFO:Uploading results into container
2022-12-18 15:41:24,606:INFO:Uploading model into container now
2022-12-18 15:41:24,607:INFO:master_model_container: 2
2022-12-18 15:41:24,607:INFO:display_container: 2
2022-12-18 15:41:24,609:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:41:24,609:INFO:create_model() successfully completed......................................
2022-12-18 15:41:24,694:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:24,694:INFO:Creating metrics dataframe
2022-12-18 15:41:24,706:INFO:Initializing Naive Bayes
2022-12-18 15:41:24,706:INFO:Total runtime is 0.04427160819371542 minutes
2022-12-18 15:41:24,710:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:24,711:INFO:Initializing create_model()
2022-12-18 15:41:24,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:24,712:INFO:Checking exceptions
2022-12-18 15:41:24,714:INFO:Importing libraries
2022-12-18 15:41:24,714:INFO:Copying training dataset
2022-12-18 15:41:24,718:INFO:Defining folds
2022-12-18 15:41:24,718:INFO:Declaring metric variables
2022-12-18 15:41:24,724:INFO:Importing untrained model
2022-12-18 15:41:24,731:INFO:Naive Bayes Imported successfully
2022-12-18 15:41:24,746:INFO:Starting cross validation
2022-12-18 15:41:24,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:25,023:INFO:Calculating mean and std
2022-12-18 15:41:25,024:INFO:Creating metrics dataframe
2022-12-18 15:41:25,029:INFO:Uploading results into container
2022-12-18 15:41:25,030:INFO:Uploading model into container now
2022-12-18 15:41:25,030:INFO:master_model_container: 3
2022-12-18 15:41:25,030:INFO:display_container: 2
2022-12-18 15:41:25,031:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-12-18 15:41:25,031:INFO:create_model() successfully completed......................................
2022-12-18 15:41:25,114:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:25,114:INFO:Creating metrics dataframe
2022-12-18 15:41:25,127:INFO:Initializing Decision Tree Classifier
2022-12-18 15:41:25,127:INFO:Total runtime is 0.05128071705500286 minutes
2022-12-18 15:41:25,131:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:25,132:INFO:Initializing create_model()
2022-12-18 15:41:25,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:25,133:INFO:Checking exceptions
2022-12-18 15:41:25,135:INFO:Importing libraries
2022-12-18 15:41:25,137:INFO:Copying training dataset
2022-12-18 15:41:25,140:INFO:Defining folds
2022-12-18 15:41:25,141:INFO:Declaring metric variables
2022-12-18 15:41:25,147:INFO:Importing untrained model
2022-12-18 15:41:25,155:INFO:Decision Tree Classifier Imported successfully
2022-12-18 15:41:25,166:INFO:Starting cross validation
2022-12-18 15:41:25,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:25,440:INFO:Calculating mean and std
2022-12-18 15:41:25,442:INFO:Creating metrics dataframe
2022-12-18 15:41:25,445:INFO:Uploading results into container
2022-12-18 15:41:25,446:INFO:Uploading model into container now
2022-12-18 15:41:25,446:INFO:master_model_container: 4
2022-12-18 15:41:25,446:INFO:display_container: 2
2022-12-18 15:41:25,447:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6348, splitter='best')
2022-12-18 15:41:25,447:INFO:create_model() successfully completed......................................
2022-12-18 15:41:25,531:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:25,532:INFO:Creating metrics dataframe
2022-12-18 15:41:25,546:INFO:Initializing SVM - Linear Kernel
2022-12-18 15:41:25,546:INFO:Total runtime is 0.0582596778869629 minutes
2022-12-18 15:41:25,550:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:25,551:INFO:Initializing create_model()
2022-12-18 15:41:25,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:25,552:INFO:Checking exceptions
2022-12-18 15:41:25,556:INFO:Importing libraries
2022-12-18 15:41:25,556:INFO:Copying training dataset
2022-12-18 15:41:25,561:INFO:Defining folds
2022-12-18 15:41:25,561:INFO:Declaring metric variables
2022-12-18 15:41:25,565:INFO:Importing untrained model
2022-12-18 15:41:25,573:INFO:SVM - Linear Kernel Imported successfully
2022-12-18 15:41:25,592:INFO:Starting cross validation
2022-12-18 15:41:25,594:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:25,758:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:41:25,811:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:41:25,870:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:41:25,884:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:41:25,913:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:41:25,948:INFO:Calculating mean and std
2022-12-18 15:41:25,949:INFO:Creating metrics dataframe
2022-12-18 15:41:25,955:INFO:Uploading results into container
2022-12-18 15:41:25,956:INFO:Uploading model into container now
2022-12-18 15:41:25,956:INFO:master_model_container: 5
2022-12-18 15:41:25,956:INFO:display_container: 2
2022-12-18 15:41:25,957:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6348, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-18 15:41:25,957:INFO:create_model() successfully completed......................................
2022-12-18 15:41:26,043:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:26,043:INFO:Creating metrics dataframe
2022-12-18 15:41:26,061:INFO:Initializing Ridge Classifier
2022-12-18 15:41:26,061:INFO:Total runtime is 0.06685349543889364 minutes
2022-12-18 15:41:26,066:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:26,066:INFO:Initializing create_model()
2022-12-18 15:41:26,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:26,066:INFO:Checking exceptions
2022-12-18 15:41:26,072:INFO:Importing libraries
2022-12-18 15:41:26,072:INFO:Copying training dataset
2022-12-18 15:41:26,075:INFO:Defining folds
2022-12-18 15:41:26,075:INFO:Declaring metric variables
2022-12-18 15:41:26,081:INFO:Importing untrained model
2022-12-18 15:41:26,088:INFO:Ridge Classifier Imported successfully
2022-12-18 15:41:26,110:INFO:Starting cross validation
2022-12-18 15:41:26,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:26,333:INFO:Calculating mean and std
2022-12-18 15:41:26,337:INFO:Creating metrics dataframe
2022-12-18 15:41:26,341:INFO:Uploading results into container
2022-12-18 15:41:26,341:INFO:Uploading model into container now
2022-12-18 15:41:26,342:INFO:master_model_container: 6
2022-12-18 15:41:26,342:INFO:display_container: 2
2022-12-18 15:41:26,343:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6348, solver='auto', tol=0.001)
2022-12-18 15:41:26,343:INFO:create_model() successfully completed......................................
2022-12-18 15:41:26,429:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:26,429:INFO:Creating metrics dataframe
2022-12-18 15:41:26,443:INFO:Initializing Random Forest Classifier
2022-12-18 15:41:26,443:INFO:Total runtime is 0.0732109824816386 minutes
2022-12-18 15:41:26,448:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:26,448:INFO:Initializing create_model()
2022-12-18 15:41:26,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:26,448:INFO:Checking exceptions
2022-12-18 15:41:26,450:INFO:Importing libraries
2022-12-18 15:41:26,450:INFO:Copying training dataset
2022-12-18 15:41:26,456:INFO:Defining folds
2022-12-18 15:41:26,456:INFO:Declaring metric variables
2022-12-18 15:41:26,462:INFO:Importing untrained model
2022-12-18 15:41:26,470:INFO:Random Forest Classifier Imported successfully
2022-12-18 15:41:26,485:INFO:Starting cross validation
2022-12-18 15:41:26,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:28,094:INFO:Calculating mean and std
2022-12-18 15:41:28,096:INFO:Creating metrics dataframe
2022-12-18 15:41:28,100:INFO:Uploading results into container
2022-12-18 15:41:28,102:INFO:Uploading model into container now
2022-12-18 15:41:28,103:INFO:master_model_container: 7
2022-12-18 15:41:28,103:INFO:display_container: 2
2022-12-18 15:41:28,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:41:28,104:INFO:create_model() successfully completed......................................
2022-12-18 15:41:28,186:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:28,186:INFO:Creating metrics dataframe
2022-12-18 15:41:28,198:INFO:Initializing Quadratic Discriminant Analysis
2022-12-18 15:41:28,198:INFO:Total runtime is 0.10245836973190309 minutes
2022-12-18 15:41:28,202:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:28,203:INFO:Initializing create_model()
2022-12-18 15:41:28,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:28,204:INFO:Checking exceptions
2022-12-18 15:41:28,206:INFO:Importing libraries
2022-12-18 15:41:28,206:INFO:Copying training dataset
2022-12-18 15:41:28,213:INFO:Defining folds
2022-12-18 15:41:28,213:INFO:Declaring metric variables
2022-12-18 15:41:28,219:INFO:Importing untrained model
2022-12-18 15:41:28,225:INFO:Quadratic Discriminant Analysis Imported successfully
2022-12-18 15:41:28,242:INFO:Starting cross validation
2022-12-18 15:41:28,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:28,427:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:41:28,443:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:41:28,444:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:41:28,444:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:41:28,462:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:41:28,463:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:41:28,463:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:41:28,532:INFO:Calculating mean and std
2022-12-18 15:41:28,535:INFO:Creating metrics dataframe
2022-12-18 15:41:28,539:INFO:Uploading results into container
2022-12-18 15:41:28,539:INFO:Uploading model into container now
2022-12-18 15:41:28,540:INFO:master_model_container: 8
2022-12-18 15:41:28,540:INFO:display_container: 2
2022-12-18 15:41:28,540:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-12-18 15:41:28,540:INFO:create_model() successfully completed......................................
2022-12-18 15:41:28,630:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:28,630:INFO:Creating metrics dataframe
2022-12-18 15:41:28,645:INFO:Initializing Ada Boost Classifier
2022-12-18 15:41:28,646:INFO:Total runtime is 0.10992347399393719 minutes
2022-12-18 15:41:28,652:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:28,653:INFO:Initializing create_model()
2022-12-18 15:41:28,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:28,653:INFO:Checking exceptions
2022-12-18 15:41:28,656:INFO:Importing libraries
2022-12-18 15:41:28,656:INFO:Copying training dataset
2022-12-18 15:41:28,659:INFO:Defining folds
2022-12-18 15:41:28,659:INFO:Declaring metric variables
2022-12-18 15:41:28,662:INFO:Importing untrained model
2022-12-18 15:41:28,671:INFO:Ada Boost Classifier Imported successfully
2022-12-18 15:41:28,685:INFO:Starting cross validation
2022-12-18 15:41:28,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:29,503:INFO:Calculating mean and std
2022-12-18 15:41:29,505:INFO:Creating metrics dataframe
2022-12-18 15:41:29,509:INFO:Uploading results into container
2022-12-18 15:41:29,509:INFO:Uploading model into container now
2022-12-18 15:41:29,510:INFO:master_model_container: 9
2022-12-18 15:41:29,510:INFO:display_container: 2
2022-12-18 15:41:29,510:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6348)
2022-12-18 15:41:29,510:INFO:create_model() successfully completed......................................
2022-12-18 15:41:29,605:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:29,606:INFO:Creating metrics dataframe
2022-12-18 15:41:29,622:INFO:Initializing Gradient Boosting Classifier
2022-12-18 15:41:29,622:INFO:Total runtime is 0.12619653940200806 minutes
2022-12-18 15:41:29,629:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:29,630:INFO:Initializing create_model()
2022-12-18 15:41:29,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:29,630:INFO:Checking exceptions
2022-12-18 15:41:29,635:INFO:Importing libraries
2022-12-18 15:41:29,635:INFO:Copying training dataset
2022-12-18 15:41:29,642:INFO:Defining folds
2022-12-18 15:41:29,642:INFO:Declaring metric variables
2022-12-18 15:41:29,651:INFO:Importing untrained model
2022-12-18 15:41:29,657:INFO:Gradient Boosting Classifier Imported successfully
2022-12-18 15:41:29,669:INFO:Starting cross validation
2022-12-18 15:41:29,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:30,532:INFO:Calculating mean and std
2022-12-18 15:41:30,534:INFO:Creating metrics dataframe
2022-12-18 15:41:30,538:INFO:Uploading results into container
2022-12-18 15:41:30,538:INFO:Uploading model into container now
2022-12-18 15:41:30,538:INFO:master_model_container: 10
2022-12-18 15:41:30,538:INFO:display_container: 2
2022-12-18 15:41:30,538:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6348, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-18 15:41:30,538:INFO:create_model() successfully completed......................................
2022-12-18 15:41:30,624:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:30,625:INFO:Creating metrics dataframe
2022-12-18 15:41:30,640:INFO:Initializing Linear Discriminant Analysis
2022-12-18 15:41:30,640:INFO:Total runtime is 0.14317056735356648 minutes
2022-12-18 15:41:30,644:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:30,645:INFO:Initializing create_model()
2022-12-18 15:41:30,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:30,645:INFO:Checking exceptions
2022-12-18 15:41:30,650:INFO:Importing libraries
2022-12-18 15:41:30,650:INFO:Copying training dataset
2022-12-18 15:41:30,653:INFO:Defining folds
2022-12-18 15:41:30,653:INFO:Declaring metric variables
2022-12-18 15:41:30,658:INFO:Importing untrained model
2022-12-18 15:41:30,666:INFO:Linear Discriminant Analysis Imported successfully
2022-12-18 15:41:30,674:INFO:Starting cross validation
2022-12-18 15:41:30,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:30,971:INFO:Calculating mean and std
2022-12-18 15:41:30,972:INFO:Creating metrics dataframe
2022-12-18 15:41:30,976:INFO:Uploading results into container
2022-12-18 15:41:30,977:INFO:Uploading model into container now
2022-12-18 15:41:30,977:INFO:master_model_container: 11
2022-12-18 15:41:30,977:INFO:display_container: 2
2022-12-18 15:41:30,977:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-12-18 15:41:30,978:INFO:create_model() successfully completed......................................
2022-12-18 15:41:31,064:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:31,064:INFO:Creating metrics dataframe
2022-12-18 15:41:31,077:INFO:Initializing Extra Trees Classifier
2022-12-18 15:41:31,078:INFO:Total runtime is 0.15046822627385456 minutes
2022-12-18 15:41:31,083:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:31,084:INFO:Initializing create_model()
2022-12-18 15:41:31,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:31,084:INFO:Checking exceptions
2022-12-18 15:41:31,087:INFO:Importing libraries
2022-12-18 15:41:31,087:INFO:Copying training dataset
2022-12-18 15:41:31,090:INFO:Defining folds
2022-12-18 15:41:31,091:INFO:Declaring metric variables
2022-12-18 15:41:31,095:INFO:Importing untrained model
2022-12-18 15:41:31,102:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:41:31,112:INFO:Starting cross validation
2022-12-18 15:41:31,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:32,472:INFO:Calculating mean and std
2022-12-18 15:41:32,473:INFO:Creating metrics dataframe
2022-12-18 15:41:32,477:INFO:Uploading results into container
2022-12-18 15:41:32,480:INFO:Uploading model into container now
2022-12-18 15:41:32,481:INFO:master_model_container: 12
2022-12-18 15:41:32,481:INFO:display_container: 2
2022-12-18 15:41:32,482:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:41:32,482:INFO:create_model() successfully completed......................................
2022-12-18 15:41:32,566:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:32,566:INFO:Creating metrics dataframe
2022-12-18 15:41:32,581:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:41:32,581:INFO:Total runtime is 0.17551896174748738 minutes
2022-12-18 15:41:32,585:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:32,586:INFO:Initializing create_model()
2022-12-18 15:41:32,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:32,586:INFO:Checking exceptions
2022-12-18 15:41:32,590:INFO:Importing libraries
2022-12-18 15:41:32,590:INFO:Copying training dataset
2022-12-18 15:41:32,597:INFO:Defining folds
2022-12-18 15:41:32,597:INFO:Declaring metric variables
2022-12-18 15:41:32,603:INFO:Importing untrained model
2022-12-18 15:41:32,611:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:41:32,621:INFO:Starting cross validation
2022-12-18 15:41:32,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:32,989:INFO:Calculating mean and std
2022-12-18 15:41:32,991:INFO:Creating metrics dataframe
2022-12-18 15:41:32,997:INFO:Uploading results into container
2022-12-18 15:41:32,998:INFO:Uploading model into container now
2022-12-18 15:41:32,998:INFO:master_model_container: 13
2022-12-18 15:41:32,998:INFO:display_container: 2
2022-12-18 15:41:32,999:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6348, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-18 15:41:33,000:INFO:create_model() successfully completed......................................
2022-12-18 15:41:33,084:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:33,084:INFO:Creating metrics dataframe
2022-12-18 15:41:33,101:INFO:Initializing Dummy Classifier
2022-12-18 15:41:33,101:INFO:Total runtime is 0.18418529431025185 minutes
2022-12-18 15:41:33,105:INFO:SubProcess create_model() called ==================================
2022-12-18 15:41:33,106:INFO:Initializing create_model()
2022-12-18 15:41:33,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711F580>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:33,106:INFO:Checking exceptions
2022-12-18 15:41:33,109:INFO:Importing libraries
2022-12-18 15:41:33,109:INFO:Copying training dataset
2022-12-18 15:41:33,115:INFO:Defining folds
2022-12-18 15:41:33,115:INFO:Declaring metric variables
2022-12-18 15:41:33,121:INFO:Importing untrained model
2022-12-18 15:41:33,126:INFO:Dummy Classifier Imported successfully
2022-12-18 15:41:33,137:INFO:Starting cross validation
2022-12-18 15:41:33,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:41:33,452:INFO:Calculating mean and std
2022-12-18 15:41:33,453:INFO:Creating metrics dataframe
2022-12-18 15:41:33,458:INFO:Uploading results into container
2022-12-18 15:41:33,459:INFO:Uploading model into container now
2022-12-18 15:41:33,460:INFO:master_model_container: 14
2022-12-18 15:41:33,462:INFO:display_container: 2
2022-12-18 15:41:33,463:INFO:DummyClassifier(constant=None, random_state=6348, strategy='prior')
2022-12-18 15:41:33,463:INFO:create_model() successfully completed......................................
2022-12-18 15:41:33,554:INFO:SubProcess create_model() end ==================================
2022-12-18 15:41:33,554:INFO:Creating metrics dataframe
2022-12-18 15:41:33,595:INFO:Initializing create_model()
2022-12-18 15:41:33,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:41:33,598:INFO:Checking exceptions
2022-12-18 15:41:33,604:INFO:Importing libraries
2022-12-18 15:41:33,604:INFO:Copying training dataset
2022-12-18 15:41:33,608:INFO:Defining folds
2022-12-18 15:41:33,608:INFO:Declaring metric variables
2022-12-18 15:41:33,608:INFO:Importing untrained model
2022-12-18 15:41:33,608:INFO:Declaring custom model
2022-12-18 15:41:33,609:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:41:33,610:INFO:Cross validation set to False
2022-12-18 15:41:33,610:INFO:Fitting Model
2022-12-18 15:41:33,840:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:41:33,840:INFO:create_model() successfully completed......................................
2022-12-18 15:41:33,976:INFO:master_model_container: 14
2022-12-18 15:41:33,976:INFO:display_container: 2
2022-12-18 15:41:33,977:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:41:33,979:INFO:compare_models() successfully completed......................................
2022-12-18 15:42:20,463:INFO:Initializing create_model()
2022-12-18 15:42:20,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=et, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:42:20,464:INFO:Checking exceptions
2022-12-18 15:42:20,526:INFO:Importing libraries
2022-12-18 15:42:20,527:INFO:Copying training dataset
2022-12-18 15:42:20,535:INFO:Defining folds
2022-12-18 15:42:20,537:INFO:Declaring metric variables
2022-12-18 15:42:20,541:INFO:Importing untrained model
2022-12-18 15:42:20,554:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:42:20,571:INFO:Starting cross validation
2022-12-18 15:42:20,573:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:42:25,124:INFO:Calculating mean and std
2022-12-18 15:42:25,126:INFO:Creating metrics dataframe
2022-12-18 15:42:25,134:INFO:Finalizing model
2022-12-18 15:42:25,306:INFO:Uploading results into container
2022-12-18 15:42:25,307:INFO:Uploading model into container now
2022-12-18 15:42:25,324:INFO:master_model_container: 15
2022-12-18 15:42:25,324:INFO:display_container: 3
2022-12-18 15:42:25,325:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:42:25,326:INFO:create_model() successfully completed......................................
2022-12-18 15:42:32,240:INFO:Initializing plot_model()
2022-12-18 15:42:32,241:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, system=True)
2022-12-18 15:42:32,241:INFO:Checking exceptions
2022-12-18 15:42:32,293:INFO:Preloading libraries
2022-12-18 15:42:32,317:INFO:Copying training dataset
2022-12-18 15:42:32,317:INFO:Plot type: auc
2022-12-18 15:42:32,416:INFO:Fitting Model
2022-12-18 15:42:32,417:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2022-12-18 15:42:32,417:INFO:Scoring test/hold-out set
2022-12-18 15:42:32,792:INFO:Visual Rendered Successfully
2022-12-18 15:42:32,873:INFO:plot_model() successfully completed......................................
2022-12-18 15:42:38,949:INFO:Initializing plot_model()
2022-12-18 15:42:38,949:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, system=True)
2022-12-18 15:42:38,949:INFO:Checking exceptions
2022-12-18 15:42:38,988:INFO:Preloading libraries
2022-12-18 15:42:39,006:INFO:Copying training dataset
2022-12-18 15:42:39,007:INFO:Plot type: learning
2022-12-18 15:42:39,068:INFO:Fitting Model
2022-12-18 15:42:51,974:INFO:Visual Rendered Successfully
2022-12-18 15:42:52,140:INFO:plot_model() successfully completed......................................
2022-12-18 15:42:56,505:INFO:Initializing tune_model()
2022-12-18 15:42:56,506:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>)
2022-12-18 15:42:56,506:INFO:Checking exceptions
2022-12-18 15:42:56,559:INFO:Copying training dataset
2022-12-18 15:42:56,565:INFO:Checking base model
2022-12-18 15:42:56,565:INFO:Base model : Extra Trees Classifier
2022-12-18 15:42:56,574:INFO:Declaring metric variables
2022-12-18 15:42:56,585:INFO:Defining Hyperparameters
2022-12-18 15:42:56,741:INFO:Tuning with n_jobs=-1
2022-12-18 15:42:56,741:INFO:Initializing RandomizedSearchCV
2022-12-18 15:43:09,395:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2022-12-18 15:43:09,396:INFO:Hyperparameter search completed
2022-12-18 15:43:09,396:INFO:SubProcess create_model() called ==================================
2022-12-18 15:43:09,397:INFO:Initializing create_model()
2022-12-18 15:43:09,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C0D43A0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 180, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': False})
2022-12-18 15:43:09,398:INFO:Checking exceptions
2022-12-18 15:43:09,403:INFO:Importing libraries
2022-12-18 15:43:09,403:INFO:Copying training dataset
2022-12-18 15:43:09,406:INFO:Defining folds
2022-12-18 15:43:09,406:INFO:Declaring metric variables
2022-12-18 15:43:09,409:INFO:Importing untrained model
2022-12-18 15:43:09,409:INFO:Declaring custom model
2022-12-18 15:43:09,414:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:43:09,426:INFO:Starting cross validation
2022-12-18 15:43:09,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:43:11,146:INFO:Calculating mean and std
2022-12-18 15:43:11,148:INFO:Creating metrics dataframe
2022-12-18 15:43:11,155:INFO:Finalizing model
2022-12-18 15:43:11,495:INFO:Uploading results into container
2022-12-18 15:43:11,496:INFO:Uploading model into container now
2022-12-18 15:43:11,497:INFO:master_model_container: 16
2022-12-18 15:43:11,497:INFO:display_container: 4
2022-12-18 15:43:11,498:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=4, max_features='log2',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0001, min_samples_leaf=6,
                     min_samples_split=10, min_weight_fraction_leaf=0.0,
                     n_estimators=180, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:43:11,499:INFO:create_model() successfully completed......................................
2022-12-18 15:43:11,629:INFO:SubProcess create_model() end ==================================
2022-12-18 15:43:11,629:INFO:choose_better activated
2022-12-18 15:43:11,634:INFO:SubProcess create_model() called ==================================
2022-12-18 15:43:11,638:INFO:Initializing create_model()
2022-12-18 15:43:11,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:43:11,638:INFO:Checking exceptions
2022-12-18 15:43:11,643:INFO:Importing libraries
2022-12-18 15:43:11,643:INFO:Copying training dataset
2022-12-18 15:43:11,649:INFO:Defining folds
2022-12-18 15:43:11,650:INFO:Declaring metric variables
2022-12-18 15:43:11,650:INFO:Importing untrained model
2022-12-18 15:43:11,650:INFO:Declaring custom model
2022-12-18 15:43:11,651:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:43:11,655:INFO:Starting cross validation
2022-12-18 15:43:11,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:43:13,083:INFO:Calculating mean and std
2022-12-18 15:43:13,083:INFO:Creating metrics dataframe
2022-12-18 15:43:13,093:INFO:Finalizing model
2022-12-18 15:43:13,333:INFO:Uploading results into container
2022-12-18 15:43:13,333:INFO:Uploading model into container now
2022-12-18 15:43:13,333:INFO:master_model_container: 17
2022-12-18 15:43:13,333:INFO:display_container: 5
2022-12-18 15:43:13,333:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:43:13,333:INFO:create_model() successfully completed......................................
2022-12-18 15:43:13,413:INFO:SubProcess create_model() end ==================================
2022-12-18 15:43:13,423:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False) result for Accuracy is 0.5983
2022-12-18 15:43:13,423:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=4, max_features='log2',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0001, min_samples_leaf=6,
                     min_samples_split=10, min_weight_fraction_leaf=0.0,
                     n_estimators=180, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False) result for Accuracy is 0.5926
2022-12-18 15:43:13,423:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False) is best model
2022-12-18 15:43:13,423:INFO:choose_better completed
2022-12-18 15:43:13,423:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-12-18 15:43:13,433:INFO:master_model_container: 17
2022-12-18 15:43:13,433:INFO:display_container: 4
2022-12-18 15:43:13,433:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:43:13,433:INFO:tune_model() successfully completed......................................
2022-12-18 15:43:57,425:INFO:Initializing tune_model()
2022-12-18 15:43:57,425:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>)
2022-12-18 15:43:57,425:INFO:Checking exceptions
2022-12-18 15:43:57,491:INFO:Copying training dataset
2022-12-18 15:43:57,502:INFO:Checking base model
2022-12-18 15:43:57,502:INFO:Base model : Extra Trees Classifier
2022-12-18 15:43:57,508:INFO:Declaring metric variables
2022-12-18 15:43:57,517:INFO:Defining Hyperparameters
2022-12-18 15:43:57,694:INFO:Tuning with n_jobs=-1
2022-12-18 15:43:57,694:INFO:Initializing RandomizedSearchCV
2022-12-18 15:44:09,040:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2022-12-18 15:44:09,041:INFO:Hyperparameter search completed
2022-12-18 15:44:09,042:INFO:SubProcess create_model() called ==================================
2022-12-18 15:44:09,045:INFO:Initializing create_model()
2022-12-18 15:44:09,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C5715A0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 180, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': False})
2022-12-18 15:44:09,045:INFO:Checking exceptions
2022-12-18 15:44:09,047:INFO:Importing libraries
2022-12-18 15:44:09,047:INFO:Copying training dataset
2022-12-18 15:44:09,052:INFO:Defining folds
2022-12-18 15:44:09,052:INFO:Declaring metric variables
2022-12-18 15:44:09,061:INFO:Importing untrained model
2022-12-18 15:44:09,061:INFO:Declaring custom model
2022-12-18 15:44:09,068:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:44:09,080:INFO:Starting cross validation
2022-12-18 15:44:09,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:44:11,361:INFO:Calculating mean and std
2022-12-18 15:44:11,366:INFO:Creating metrics dataframe
2022-12-18 15:44:11,379:INFO:Finalizing model
2022-12-18 15:44:11,767:INFO:Uploading results into container
2022-12-18 15:44:11,769:INFO:Uploading model into container now
2022-12-18 15:44:11,769:INFO:master_model_container: 18
2022-12-18 15:44:11,769:INFO:display_container: 5
2022-12-18 15:44:11,771:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=4, max_features='log2',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0001, min_samples_leaf=6,
                     min_samples_split=10, min_weight_fraction_leaf=0.0,
                     n_estimators=180, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:44:11,771:INFO:create_model() successfully completed......................................
2022-12-18 15:44:11,862:INFO:SubProcess create_model() end ==================================
2022-12-18 15:44:11,862:INFO:choose_better activated
2022-12-18 15:44:11,869:INFO:SubProcess create_model() called ==================================
2022-12-18 15:44:11,870:INFO:Initializing create_model()
2022-12-18 15:44:11,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:44:11,870:INFO:Checking exceptions
2022-12-18 15:44:11,878:INFO:Importing libraries
2022-12-18 15:44:11,878:INFO:Copying training dataset
2022-12-18 15:44:11,881:INFO:Defining folds
2022-12-18 15:44:11,882:INFO:Declaring metric variables
2022-12-18 15:44:11,882:INFO:Importing untrained model
2022-12-18 15:44:11,882:INFO:Declaring custom model
2022-12-18 15:44:11,882:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:44:11,883:INFO:Starting cross validation
2022-12-18 15:44:11,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:44:13,325:INFO:Calculating mean and std
2022-12-18 15:44:13,326:INFO:Creating metrics dataframe
2022-12-18 15:44:13,329:INFO:Finalizing model
2022-12-18 15:44:13,505:INFO:Uploading results into container
2022-12-18 15:44:13,506:INFO:Uploading model into container now
2022-12-18 15:44:13,506:INFO:master_model_container: 19
2022-12-18 15:44:13,506:INFO:display_container: 6
2022-12-18 15:44:13,507:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:44:13,507:INFO:create_model() successfully completed......................................
2022-12-18 15:44:13,589:INFO:SubProcess create_model() end ==================================
2022-12-18 15:44:13,590:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False) result for Accuracy is 0.5983
2022-12-18 15:44:13,591:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=4, max_features='log2',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0001, min_samples_leaf=6,
                     min_samples_split=10, min_weight_fraction_leaf=0.0,
                     n_estimators=180, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False) result for Accuracy is 0.5926
2022-12-18 15:44:13,591:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False) is best model
2022-12-18 15:44:13,592:INFO:choose_better completed
2022-12-18 15:44:13,592:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-12-18 15:44:13,607:INFO:master_model_container: 19
2022-12-18 15:44:13,607:INFO:display_container: 5
2022-12-18 15:44:13,608:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False)
2022-12-18 15:44:13,609:INFO:tune_model() successfully completed......................................
2022-12-18 15:44:16,563:INFO:Initializing plot_model()
2022-12-18 15:44:16,564:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C42FE32AA0>, system=True)
2022-12-18 15:44:16,564:INFO:Checking exceptions
2022-12-18 15:44:16,606:INFO:Preloading libraries
2022-12-18 15:44:16,621:INFO:Copying training dataset
2022-12-18 15:44:16,621:INFO:Plot type: learning
2022-12-18 15:44:16,665:INFO:Fitting Model
2022-12-18 15:44:27,737:INFO:Visual Rendered Successfully
2022-12-18 15:44:27,962:INFO:plot_model() successfully completed......................................
2022-12-18 15:44:30,249:INFO:Initializing save_model()
2022-12-18 15:44:30,250:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6348, verbose=0, warm_start=False), model_name=forestfiremodel, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-12-18 15:44:30,250:INFO:Adding model into prep_pipe
2022-12-18 15:44:30,350:INFO:forestfiremodel.pkl saved in current working directory
2022-12-18 15:44:30,363:INFO:Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Trans...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=6348,
                                      verbose=0, warm_start=False))],
         verbose=False)
2022-12-18 15:44:30,363:INFO:save_model() successfully completed......................................
2022-12-18 15:44:55,444:INFO:PyCaret RegressionExperiment
2022-12-18 15:44:55,444:INFO:Logging name: reg-default-name
2022-12-18 15:44:55,444:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-18 15:44:55,444:INFO:version 3.0.0.rc4
2022-12-18 15:44:55,445:INFO:Initializing setup()
2022-12-18 15:44:55,445:INFO:self.USI: 2815
2022-12-18 15:44:55,445:INFO:self.variable_keys: {'exp_name_log', 'y', 'X', '_available_plots', 'seed', '_gpu_n_jobs_param', 'idx', 'n_jobs_param', 'variable_keys', 'html_param', 'fold_shuffle_param', 'fold_groups_param', '_all_metrics', 'memory', 'pipeline', 'data', 'transform_target_param', 'logging_param', 'transform_target_method_param', 'X_test', 'y_test', 'USI', 'log_plots_param', 'gpu_param', 'X_train', '_all_models_internal', 'exp_id', 'target_param', '_ml_usecase', 'y_train', 'master_model_container', '_all_models', 'display_container', 'fold_generator'}
2022-12-18 15:44:55,445:INFO:Checking environment
2022-12-18 15:44:55,445:INFO:python_version: 3.10.4
2022-12-18 15:44:55,445:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-12-18 15:44:55,445:INFO:machine: AMD64
2022-12-18 15:44:55,446:INFO:platform: Windows-10-10.0.19045-SP0
2022-12-18 15:44:55,446:INFO:Memory: svmem(total=8503136256, available=1766445056, percent=79.2, used=6736691200, free=1766445056)
2022-12-18 15:44:55,446:INFO:Physical Core: 2
2022-12-18 15:44:55,446:INFO:Logical Core: 4
2022-12-18 15:44:55,446:INFO:Checking libraries
2022-12-18 15:44:55,447:INFO:System:
2022-12-18 15:44:55,447:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-12-18 15:44:55,447:INFO:executable: c:\Python3.10\python.exe
2022-12-18 15:44:55,447:INFO:   machine: Windows-10-10.0.19045-SP0
2022-12-18 15:44:55,447:INFO:PyCaret required dependencies:
2022-12-18 15:44:55,447:INFO:                 pip: 22.2.2
2022-12-18 15:44:55,447:INFO:          setuptools: 58.1.0
2022-12-18 15:44:55,447:INFO:             pycaret: 3.0.0rc4
2022-12-18 15:44:55,448:INFO:             IPython: 8.4.0
2022-12-18 15:44:55,448:INFO:          ipywidgets: 8.0.2
2022-12-18 15:44:55,449:INFO:                tqdm: 4.64.0
2022-12-18 15:44:55,449:INFO:               numpy: 1.22.1
2022-12-18 15:44:55,449:INFO:              pandas: 1.4.2
2022-12-18 15:44:55,449:INFO:              jinja2: 3.1.2
2022-12-18 15:44:55,449:INFO:               scipy: 1.8.1
2022-12-18 15:44:55,449:INFO:              joblib: 1.2.0
2022-12-18 15:44:55,449:INFO:             sklearn: 1.1.2
2022-12-18 15:44:55,449:INFO:                pyod: 1.0.6
2022-12-18 15:44:55,450:INFO:            imblearn: 0.9.1
2022-12-18 15:44:55,450:INFO:   category_encoders: 2.5.1.post0
2022-12-18 15:44:55,450:INFO:            lightgbm: 3.3.3
2022-12-18 15:44:55,450:INFO:               numba: 0.55.2
2022-12-18 15:44:55,450:INFO:            requests: 2.28.1
2022-12-18 15:44:55,450:INFO:          matplotlib: 3.5.1
2022-12-18 15:44:55,450:INFO:          scikitplot: 0.3.7
2022-12-18 15:44:55,450:INFO:         yellowbrick: 1.5
2022-12-18 15:44:55,450:INFO:              plotly: 5.11.0
2022-12-18 15:44:55,450:INFO:             kaleido: 0.2.1
2022-12-18 15:44:55,451:INFO:         statsmodels: 0.13.5
2022-12-18 15:44:55,451:INFO:              sktime: 0.13.4
2022-12-18 15:44:55,451:INFO:               tbats: 1.1.1
2022-12-18 15:44:55,451:INFO:            pmdarima: 1.8.5
2022-12-18 15:44:55,451:INFO:              psutil: 5.9.1
2022-12-18 15:44:55,451:INFO:PyCaret optional dependencies:
2022-12-18 15:44:55,451:INFO:                shap: Not installed
2022-12-18 15:44:55,452:INFO:           interpret: Not installed
2022-12-18 15:44:55,452:INFO:                umap: Not installed
2022-12-18 15:44:55,452:INFO:    pandas_profiling: Not installed
2022-12-18 15:44:55,452:INFO:  explainerdashboard: Not installed
2022-12-18 15:44:55,452:INFO:             autoviz: Not installed
2022-12-18 15:44:55,452:INFO:           fairlearn: Not installed
2022-12-18 15:44:55,452:INFO:             xgboost: Not installed
2022-12-18 15:44:55,452:INFO:            catboost: Not installed
2022-12-18 15:44:55,453:INFO:              kmodes: Not installed
2022-12-18 15:44:55,453:INFO:             mlxtend: Not installed
2022-12-18 15:44:55,453:INFO:       statsforecast: Not installed
2022-12-18 15:44:55,453:INFO:        tune_sklearn: Not installed
2022-12-18 15:44:55,453:INFO:                 ray: Not installed
2022-12-18 15:44:55,453:INFO:            hyperopt: Not installed
2022-12-18 15:44:55,453:INFO:              optuna: Not installed
2022-12-18 15:44:55,453:INFO:               skopt: Not installed
2022-12-18 15:44:55,453:INFO:              mlflow: Not installed
2022-12-18 15:44:55,454:INFO:              gradio: Not installed
2022-12-18 15:44:55,454:INFO:             fastapi: Not installed
2022-12-18 15:44:55,454:INFO:             uvicorn: Not installed
2022-12-18 15:44:55,455:INFO:              m2cgen: Not installed
2022-12-18 15:44:55,455:INFO:           evidently: Not installed
2022-12-18 15:44:55,455:INFO:                nltk: 3.7
2022-12-18 15:44:55,455:INFO:            pyLDAvis: Not installed
2022-12-18 15:44:55,455:INFO:              gensim: Not installed
2022-12-18 15:44:55,455:INFO:               spacy: 3.4.3
2022-12-18 15:44:55,456:INFO:           wordcloud: Not installed
2022-12-18 15:44:55,456:INFO:            textblob: Not installed
2022-12-18 15:44:55,456:INFO:               fugue: Not installed
2022-12-18 15:44:55,456:INFO:           streamlit: Not installed
2022-12-18 15:44:55,456:INFO:             prophet: Not installed
2022-12-18 15:44:55,456:INFO:None
2022-12-18 15:44:55,457:INFO:Set up data.
2022-12-18 15:44:55,471:INFO:Set up train/test split.
2022-12-18 15:44:55,478:INFO:Set up index.
2022-12-18 15:44:55,479:INFO:Set up folding strategy.
2022-12-18 15:44:55,479:INFO:Assigning column types.
2022-12-18 15:44:55,486:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-18 15:44:55,486:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,491:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,498:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,601:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:55,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:55,729:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,743:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:55,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:55,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:55,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-18 15:44:56,001:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,319:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:56,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:56,332:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:56,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:56,592:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-18 15:44:56,610:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:56,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:56,821:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:44:56,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,022:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-18 15:44:57,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,491:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,546:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-18 15:44:57,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:44:57,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:57,864:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-18 15:44:58,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:58,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:58,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:58,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:58,319:INFO:Preparing preprocessing pipeline...
2022-12-18 15:44:58,320:INFO:Set up simple imputation.
2022-12-18 15:44:58,320:INFO:Set up variance threshold.
2022-12-18 15:44:58,375:INFO:Finished creating preprocessing pipeline.
2022-12-18 15:44:58,380:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-18 15:44:58,381:INFO:Creating final display dataframe.
2022-12-18 15:44:58,646:INFO:Setup display_container:                Description             Value
0               Session id              4359
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              2815
2022-12-18 15:44:58,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:58,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:59,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:59,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:44:59,022:INFO:setup() successfully completed in 3.58s...............
2022-12-18 15:44:59,125:INFO:Initializing compare_models()
2022-12-18 15:44:59,125:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-18 15:44:59,125:INFO:Checking exceptions
2022-12-18 15:44:59,130:INFO:Preparing display monitor
2022-12-18 15:44:59,241:INFO:Initializing Linear Regression
2022-12-18 15:44:59,241:INFO:Total runtime is 0.0 minutes
2022-12-18 15:44:59,249:INFO:SubProcess create_model() called ==================================
2022-12-18 15:44:59,249:INFO:Initializing create_model()
2022-12-18 15:44:59,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:44:59,250:INFO:Checking exceptions
2022-12-18 15:44:59,253:INFO:Importing libraries
2022-12-18 15:44:59,253:INFO:Copying training dataset
2022-12-18 15:44:59,257:INFO:Defining folds
2022-12-18 15:44:59,257:INFO:Declaring metric variables
2022-12-18 15:44:59,264:INFO:Importing untrained model
2022-12-18 15:44:59,292:INFO:Linear Regression Imported successfully
2022-12-18 15:44:59,306:INFO:Starting cross validation
2022-12-18 15:44:59,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:00,646:INFO:Calculating mean and std
2022-12-18 15:45:00,647:INFO:Creating metrics dataframe
2022-12-18 15:45:00,651:INFO:Uploading results into container
2022-12-18 15:45:00,652:INFO:Uploading model into container now
2022-12-18 15:45:00,652:INFO:master_model_container: 1
2022-12-18 15:45:00,652:INFO:display_container: 2
2022-12-18 15:45:00,653:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1,
                 normalize='deprecated', positive=False)
2022-12-18 15:45:00,653:INFO:create_model() successfully completed......................................
2022-12-18 15:45:00,737:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:00,737:INFO:Creating metrics dataframe
2022-12-18 15:45:00,749:INFO:Initializing Lasso Regression
2022-12-18 15:45:00,749:INFO:Total runtime is 0.025139351685841877 minutes
2022-12-18 15:45:00,753:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:00,753:INFO:Initializing create_model()
2022-12-18 15:45:00,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:00,754:INFO:Checking exceptions
2022-12-18 15:45:00,757:INFO:Importing libraries
2022-12-18 15:45:00,757:INFO:Copying training dataset
2022-12-18 15:45:00,762:INFO:Defining folds
2022-12-18 15:45:00,762:INFO:Declaring metric variables
2022-12-18 15:45:00,768:INFO:Importing untrained model
2022-12-18 15:45:00,773:INFO:Lasso Regression Imported successfully
2022-12-18 15:45:00,783:INFO:Starting cross validation
2022-12-18 15:45:00,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:01,095:INFO:Calculating mean and std
2022-12-18 15:45:01,098:INFO:Creating metrics dataframe
2022-12-18 15:45:01,104:INFO:Uploading results into container
2022-12-18 15:45:01,105:INFO:Uploading model into container now
2022-12-18 15:45:01,105:INFO:master_model_container: 2
2022-12-18 15:45:01,106:INFO:display_container: 2
2022-12-18 15:45:01,107:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize='deprecated', positive=False, precompute=False,
      random_state=4359, selection='cyclic', tol=0.0001, warm_start=False)
2022-12-18 15:45:01,108:INFO:create_model() successfully completed......................................
2022-12-18 15:45:01,198:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:01,198:INFO:Creating metrics dataframe
2022-12-18 15:45:01,212:INFO:Initializing Ridge Regression
2022-12-18 15:45:01,213:INFO:Total runtime is 0.032878788312276204 minutes
2022-12-18 15:45:01,218:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:01,218:INFO:Initializing create_model()
2022-12-18 15:45:01,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:01,219:INFO:Checking exceptions
2022-12-18 15:45:01,222:INFO:Importing libraries
2022-12-18 15:45:01,222:INFO:Copying training dataset
2022-12-18 15:45:01,230:INFO:Defining folds
2022-12-18 15:45:01,230:INFO:Declaring metric variables
2022-12-18 15:45:01,237:INFO:Importing untrained model
2022-12-18 15:45:01,245:INFO:Ridge Regression Imported successfully
2022-12-18 15:45:01,253:INFO:Starting cross validation
2022-12-18 15:45:01,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:01,445:INFO:Calculating mean and std
2022-12-18 15:45:01,446:INFO:Creating metrics dataframe
2022-12-18 15:45:01,450:INFO:Uploading results into container
2022-12-18 15:45:01,450:INFO:Uploading model into container now
2022-12-18 15:45:01,451:INFO:master_model_container: 3
2022-12-18 15:45:01,451:INFO:display_container: 2
2022-12-18 15:45:01,452:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize='deprecated', positive=False, random_state=4359, solver='auto',
      tol=0.001)
2022-12-18 15:45:01,452:INFO:create_model() successfully completed......................................
2022-12-18 15:45:01,533:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:01,533:INFO:Creating metrics dataframe
2022-12-18 15:45:01,546:INFO:Initializing Elastic Net
2022-12-18 15:45:01,546:INFO:Total runtime is 0.03842589855194092 minutes
2022-12-18 15:45:01,550:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:01,550:INFO:Initializing create_model()
2022-12-18 15:45:01,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:01,551:INFO:Checking exceptions
2022-12-18 15:45:01,554:INFO:Importing libraries
2022-12-18 15:45:01,554:INFO:Copying training dataset
2022-12-18 15:45:01,558:INFO:Defining folds
2022-12-18 15:45:01,559:INFO:Declaring metric variables
2022-12-18 15:45:01,563:INFO:Importing untrained model
2022-12-18 15:45:01,569:INFO:Elastic Net Imported successfully
2022-12-18 15:45:01,579:INFO:Starting cross validation
2022-12-18 15:45:01,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:01,749:INFO:Calculating mean and std
2022-12-18 15:45:01,750:INFO:Creating metrics dataframe
2022-12-18 15:45:01,754:INFO:Uploading results into container
2022-12-18 15:45:01,755:INFO:Uploading model into container now
2022-12-18 15:45:01,755:INFO:master_model_container: 4
2022-12-18 15:45:01,755:INFO:display_container: 2
2022-12-18 15:45:01,756:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize='deprecated', positive=False,
           precompute=False, random_state=4359, selection='cyclic', tol=0.0001,
           warm_start=False)
2022-12-18 15:45:01,756:INFO:create_model() successfully completed......................................
2022-12-18 15:45:01,836:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:01,836:INFO:Creating metrics dataframe
2022-12-18 15:45:01,849:INFO:Initializing Least Angle Regression
2022-12-18 15:45:01,849:INFO:Total runtime is 0.043475210666656494 minutes
2022-12-18 15:45:01,854:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:01,855:INFO:Initializing create_model()
2022-12-18 15:45:01,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:01,855:INFO:Checking exceptions
2022-12-18 15:45:01,857:INFO:Importing libraries
2022-12-18 15:45:01,858:INFO:Copying training dataset
2022-12-18 15:45:01,861:INFO:Defining folds
2022-12-18 15:45:01,861:INFO:Declaring metric variables
2022-12-18 15:45:01,867:INFO:Importing untrained model
2022-12-18 15:45:01,874:INFO:Least Angle Regression Imported successfully
2022-12-18 15:45:01,884:INFO:Starting cross validation
2022-12-18 15:45:01,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:01,931:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:01,937:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:01,950:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:01,964:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:01,996:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,005:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,009:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,030:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,043:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,050:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,065:INFO:Calculating mean and std
2022-12-18 15:45:02,067:INFO:Creating metrics dataframe
2022-12-18 15:45:02,071:INFO:Uploading results into container
2022-12-18 15:45:02,071:INFO:Uploading model into container now
2022-12-18 15:45:02,072:INFO:master_model_container: 5
2022-12-18 15:45:02,072:INFO:display_container: 2
2022-12-18 15:45:02,073:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=4359, verbose=False)
2022-12-18 15:45:02,073:INFO:create_model() successfully completed......................................
2022-12-18 15:45:02,155:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:02,156:INFO:Creating metrics dataframe
2022-12-18 15:45:02,167:INFO:Initializing Lasso Least Angle Regression
2022-12-18 15:45:02,167:INFO:Total runtime is 0.04877395629882812 minutes
2022-12-18 15:45:02,172:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:02,172:INFO:Initializing create_model()
2022-12-18 15:45:02,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:02,174:INFO:Checking exceptions
2022-12-18 15:45:02,177:INFO:Importing libraries
2022-12-18 15:45:02,177:INFO:Copying training dataset
2022-12-18 15:45:02,180:INFO:Defining folds
2022-12-18 15:45:02,180:INFO:Declaring metric variables
2022-12-18 15:45:02,184:INFO:Importing untrained model
2022-12-18 15:45:02,192:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:45:02,201:INFO:Starting cross validation
2022-12-18 15:45:02,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:02,246:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,255:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,260:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,272:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,303:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,313:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,324:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,333:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,357:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,363:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:02,376:INFO:Calculating mean and std
2022-12-18 15:45:02,377:INFO:Creating metrics dataframe
2022-12-18 15:45:02,381:INFO:Uploading results into container
2022-12-18 15:45:02,381:INFO:Uploading model into container now
2022-12-18 15:45:02,382:INFO:master_model_container: 6
2022-12-18 15:45:02,382:INFO:display_container: 2
2022-12-18 15:45:02,383:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False)
2022-12-18 15:45:02,383:INFO:create_model() successfully completed......................................
2022-12-18 15:45:02,464:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:02,464:INFO:Creating metrics dataframe
2022-12-18 15:45:02,481:INFO:Initializing Orthogonal Matching Pursuit
2022-12-18 15:45:02,481:INFO:Total runtime is 0.053998863697052 minutes
2022-12-18 15:45:02,485:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:02,486:INFO:Initializing create_model()
2022-12-18 15:45:02,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:02,486:INFO:Checking exceptions
2022-12-18 15:45:02,491:INFO:Importing libraries
2022-12-18 15:45:02,491:INFO:Copying training dataset
2022-12-18 15:45:02,497:INFO:Defining folds
2022-12-18 15:45:02,497:INFO:Declaring metric variables
2022-12-18 15:45:02,507:INFO:Importing untrained model
2022-12-18 15:45:02,515:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-18 15:45:02,530:INFO:Starting cross validation
2022-12-18 15:45:02,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:02,574:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,583:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,589:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,602:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,627:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,637:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,647:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,655:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,693:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,693:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:45:02,716:INFO:Calculating mean and std
2022-12-18 15:45:02,718:INFO:Creating metrics dataframe
2022-12-18 15:45:02,726:INFO:Uploading results into container
2022-12-18 15:45:02,727:INFO:Uploading model into container now
2022-12-18 15:45:02,728:INFO:master_model_container: 7
2022-12-18 15:45:02,729:INFO:display_container: 2
2022-12-18 15:45:02,730:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2022-12-18 15:45:02,730:INFO:create_model() successfully completed......................................
2022-12-18 15:45:02,829:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:02,829:INFO:Creating metrics dataframe
2022-12-18 15:45:02,842:INFO:Initializing Bayesian Ridge
2022-12-18 15:45:02,842:INFO:Total runtime is 0.060026605923970536 minutes
2022-12-18 15:45:02,846:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:02,847:INFO:Initializing create_model()
2022-12-18 15:45:02,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:02,847:INFO:Checking exceptions
2022-12-18 15:45:02,850:INFO:Importing libraries
2022-12-18 15:45:02,850:INFO:Copying training dataset
2022-12-18 15:45:02,854:INFO:Defining folds
2022-12-18 15:45:02,854:INFO:Declaring metric variables
2022-12-18 15:45:02,862:INFO:Importing untrained model
2022-12-18 15:45:02,867:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:45:02,877:INFO:Starting cross validation
2022-12-18 15:45:02,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:03,060:INFO:Calculating mean and std
2022-12-18 15:45:03,061:INFO:Creating metrics dataframe
2022-12-18 15:45:03,065:INFO:Uploading results into container
2022-12-18 15:45:03,065:INFO:Uploading model into container now
2022-12-18 15:45:03,066:INFO:master_model_container: 8
2022-12-18 15:45:03,066:INFO:display_container: 2
2022-12-18 15:45:03,067:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2022-12-18 15:45:03,067:INFO:create_model() successfully completed......................................
2022-12-18 15:45:03,150:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:03,150:INFO:Creating metrics dataframe
2022-12-18 15:45:03,164:INFO:Initializing Passive Aggressive Regressor
2022-12-18 15:45:03,164:INFO:Total runtime is 0.06539841890335082 minutes
2022-12-18 15:45:03,168:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:03,169:INFO:Initializing create_model()
2022-12-18 15:45:03,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:03,170:INFO:Checking exceptions
2022-12-18 15:45:03,174:INFO:Importing libraries
2022-12-18 15:45:03,174:INFO:Copying training dataset
2022-12-18 15:45:03,178:INFO:Defining folds
2022-12-18 15:45:03,178:INFO:Declaring metric variables
2022-12-18 15:45:03,182:INFO:Importing untrained model
2022-12-18 15:45:03,191:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:45:03,199:INFO:Starting cross validation
2022-12-18 15:45:03,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:03,367:INFO:Calculating mean and std
2022-12-18 15:45:03,369:INFO:Creating metrics dataframe
2022-12-18 15:45:03,374:INFO:Uploading results into container
2022-12-18 15:45:03,374:INFO:Uploading model into container now
2022-12-18 15:45:03,375:INFO:master_model_container: 9
2022-12-18 15:45:03,375:INFO:display_container: 2
2022-12-18 15:45:03,375:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=4359, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-18 15:45:03,376:INFO:create_model() successfully completed......................................
2022-12-18 15:45:03,458:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:03,458:INFO:Creating metrics dataframe
2022-12-18 15:45:03,471:INFO:Initializing Huber Regressor
2022-12-18 15:45:03,471:INFO:Total runtime is 0.07050583759943643 minutes
2022-12-18 15:45:03,477:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:03,478:INFO:Initializing create_model()
2022-12-18 15:45:03,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:03,478:INFO:Checking exceptions
2022-12-18 15:45:03,481:INFO:Importing libraries
2022-12-18 15:45:03,481:INFO:Copying training dataset
2022-12-18 15:45:03,484:INFO:Defining folds
2022-12-18 15:45:03,484:INFO:Declaring metric variables
2022-12-18 15:45:03,491:INFO:Importing untrained model
2022-12-18 15:45:03,496:INFO:Huber Regressor Imported successfully
2022-12-18 15:45:03,508:INFO:Starting cross validation
2022-12-18 15:45:03,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:03,608:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,614:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,646:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,708:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,711:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,716:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,749:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,793:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:03,804:INFO:Calculating mean and std
2022-12-18 15:45:03,807:INFO:Creating metrics dataframe
2022-12-18 15:45:03,810:INFO:Uploading results into container
2022-12-18 15:45:03,811:INFO:Uploading model into container now
2022-12-18 15:45:03,811:INFO:master_model_container: 10
2022-12-18 15:45:03,811:INFO:display_container: 2
2022-12-18 15:45:03,812:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-12-18 15:45:03,812:INFO:create_model() successfully completed......................................
2022-12-18 15:45:03,939:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:03,939:INFO:Creating metrics dataframe
2022-12-18 15:45:03,955:INFO:Initializing K Neighbors Regressor
2022-12-18 15:45:03,955:INFO:Total runtime is 0.07858030398686726 minutes
2022-12-18 15:45:03,959:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:03,960:INFO:Initializing create_model()
2022-12-18 15:45:03,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:03,960:INFO:Checking exceptions
2022-12-18 15:45:03,963:INFO:Importing libraries
2022-12-18 15:45:03,963:INFO:Copying training dataset
2022-12-18 15:45:03,967:INFO:Defining folds
2022-12-18 15:45:03,967:INFO:Declaring metric variables
2022-12-18 15:45:03,973:INFO:Importing untrained model
2022-12-18 15:45:03,979:INFO:K Neighbors Regressor Imported successfully
2022-12-18 15:45:03,989:INFO:Starting cross validation
2022-12-18 15:45:03,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:04,194:INFO:Calculating mean and std
2022-12-18 15:45:04,195:INFO:Creating metrics dataframe
2022-12-18 15:45:04,199:INFO:Uploading results into container
2022-12-18 15:45:04,199:INFO:Uploading model into container now
2022-12-18 15:45:04,200:INFO:master_model_container: 11
2022-12-18 15:45:04,200:INFO:display_container: 2
2022-12-18 15:45:04,201:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2022-12-18 15:45:04,202:INFO:create_model() successfully completed......................................
2022-12-18 15:45:04,284:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:04,284:INFO:Creating metrics dataframe
2022-12-18 15:45:04,297:INFO:Initializing Decision Tree Regressor
2022-12-18 15:45:04,297:INFO:Total runtime is 0.08427621920903523 minutes
2022-12-18 15:45:04,301:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:04,302:INFO:Initializing create_model()
2022-12-18 15:45:04,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:04,302:INFO:Checking exceptions
2022-12-18 15:45:04,307:INFO:Importing libraries
2022-12-18 15:45:04,307:INFO:Copying training dataset
2022-12-18 15:45:04,310:INFO:Defining folds
2022-12-18 15:45:04,310:INFO:Declaring metric variables
2022-12-18 15:45:04,315:INFO:Importing untrained model
2022-12-18 15:45:04,323:INFO:Decision Tree Regressor Imported successfully
2022-12-18 15:45:04,332:INFO:Starting cross validation
2022-12-18 15:45:04,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:04,503:INFO:Calculating mean and std
2022-12-18 15:45:04,506:INFO:Creating metrics dataframe
2022-12-18 15:45:04,510:INFO:Uploading results into container
2022-12-18 15:45:04,511:INFO:Uploading model into container now
2022-12-18 15:45:04,511:INFO:master_model_container: 12
2022-12-18 15:45:04,511:INFO:display_container: 2
2022-12-18 15:45:04,512:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=4359, splitter='best')
2022-12-18 15:45:04,512:INFO:create_model() successfully completed......................................
2022-12-18 15:45:04,592:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:04,593:INFO:Creating metrics dataframe
2022-12-18 15:45:04,607:INFO:Initializing Random Forest Regressor
2022-12-18 15:45:04,608:INFO:Total runtime is 0.08945902585983276 minutes
2022-12-18 15:45:04,613:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:04,613:INFO:Initializing create_model()
2022-12-18 15:45:04,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:04,614:INFO:Checking exceptions
2022-12-18 15:45:04,615:INFO:Importing libraries
2022-12-18 15:45:04,615:INFO:Copying training dataset
2022-12-18 15:45:04,619:INFO:Defining folds
2022-12-18 15:45:04,619:INFO:Declaring metric variables
2022-12-18 15:45:04,625:INFO:Importing untrained model
2022-12-18 15:45:04,632:INFO:Random Forest Regressor Imported successfully
2022-12-18 15:45:04,642:INFO:Starting cross validation
2022-12-18 15:45:04,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:05,976:INFO:Calculating mean and std
2022-12-18 15:45:05,978:INFO:Creating metrics dataframe
2022-12-18 15:45:05,982:INFO:Uploading results into container
2022-12-18 15:45:05,982:INFO:Uploading model into container now
2022-12-18 15:45:05,983:INFO:master_model_container: 13
2022-12-18 15:45:05,983:INFO:display_container: 2
2022-12-18 15:45:05,984:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=4359, verbose=0,
                      warm_start=False)
2022-12-18 15:45:05,984:INFO:create_model() successfully completed......................................
2022-12-18 15:45:06,066:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:06,066:INFO:Creating metrics dataframe
2022-12-18 15:45:06,081:INFO:Initializing Extra Trees Regressor
2022-12-18 15:45:06,081:INFO:Total runtime is 0.11400209665298461 minutes
2022-12-18 15:45:06,085:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:06,085:INFO:Initializing create_model()
2022-12-18 15:45:06,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:06,087:INFO:Checking exceptions
2022-12-18 15:45:06,090:INFO:Importing libraries
2022-12-18 15:45:06,090:INFO:Copying training dataset
2022-12-18 15:45:06,093:INFO:Defining folds
2022-12-18 15:45:06,094:INFO:Declaring metric variables
2022-12-18 15:45:06,098:INFO:Importing untrained model
2022-12-18 15:45:06,105:INFO:Extra Trees Regressor Imported successfully
2022-12-18 15:45:06,115:INFO:Starting cross validation
2022-12-18 15:45:06,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:07,032:INFO:Calculating mean and std
2022-12-18 15:45:07,034:INFO:Creating metrics dataframe
2022-12-18 15:45:07,038:INFO:Uploading results into container
2022-12-18 15:45:07,040:INFO:Uploading model into container now
2022-12-18 15:45:07,042:INFO:master_model_container: 14
2022-12-18 15:45:07,042:INFO:display_container: 2
2022-12-18 15:45:07,043:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=4359, verbose=0,
                    warm_start=False)
2022-12-18 15:45:07,043:INFO:create_model() successfully completed......................................
2022-12-18 15:45:07,123:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:07,123:INFO:Creating metrics dataframe
2022-12-18 15:45:07,139:INFO:Initializing AdaBoost Regressor
2022-12-18 15:45:07,139:INFO:Total runtime is 0.1316476265589396 minutes
2022-12-18 15:45:07,145:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:07,146:INFO:Initializing create_model()
2022-12-18 15:45:07,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:07,146:INFO:Checking exceptions
2022-12-18 15:45:07,149:INFO:Importing libraries
2022-12-18 15:45:07,149:INFO:Copying training dataset
2022-12-18 15:45:07,171:INFO:Defining folds
2022-12-18 15:45:07,186:INFO:Declaring metric variables
2022-12-18 15:45:07,193:INFO:Importing untrained model
2022-12-18 15:45:07,233:INFO:AdaBoost Regressor Imported successfully
2022-12-18 15:45:07,247:INFO:Starting cross validation
2022-12-18 15:45:07,248:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:07,733:INFO:Calculating mean and std
2022-12-18 15:45:07,736:INFO:Creating metrics dataframe
2022-12-18 15:45:07,739:INFO:Uploading results into container
2022-12-18 15:45:07,740:INFO:Uploading model into container now
2022-12-18 15:45:07,740:INFO:master_model_container: 15
2022-12-18 15:45:07,740:INFO:display_container: 2
2022-12-18 15:45:07,740:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=4359)
2022-12-18 15:45:07,741:INFO:create_model() successfully completed......................................
2022-12-18 15:45:07,821:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:07,822:INFO:Creating metrics dataframe
2022-12-18 15:45:07,838:INFO:Initializing Gradient Boosting Regressor
2022-12-18 15:45:07,838:INFO:Total runtime is 0.1432876944541931 minutes
2022-12-18 15:45:07,842:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:07,843:INFO:Initializing create_model()
2022-12-18 15:45:07,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:07,844:INFO:Checking exceptions
2022-12-18 15:45:07,847:INFO:Importing libraries
2022-12-18 15:45:07,847:INFO:Copying training dataset
2022-12-18 15:45:07,850:INFO:Defining folds
2022-12-18 15:45:07,850:INFO:Declaring metric variables
2022-12-18 15:45:07,856:INFO:Importing untrained model
2022-12-18 15:45:07,862:INFO:Gradient Boosting Regressor Imported successfully
2022-12-18 15:45:07,872:INFO:Starting cross validation
2022-12-18 15:45:07,874:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:08,372:INFO:Calculating mean and std
2022-12-18 15:45:08,373:INFO:Creating metrics dataframe
2022-12-18 15:45:08,377:INFO:Uploading results into container
2022-12-18 15:45:08,378:INFO:Uploading model into container now
2022-12-18 15:45:08,378:INFO:master_model_container: 16
2022-12-18 15:45:08,379:INFO:display_container: 2
2022-12-18 15:45:08,380:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=4359, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-18 15:45:08,381:INFO:create_model() successfully completed......................................
2022-12-18 15:45:08,477:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:08,478:INFO:Creating metrics dataframe
2022-12-18 15:45:08,493:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:45:08,493:INFO:Total runtime is 0.15421042839686075 minutes
2022-12-18 15:45:08,498:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:08,498:INFO:Initializing create_model()
2022-12-18 15:45:08,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:08,499:INFO:Checking exceptions
2022-12-18 15:45:08,503:INFO:Importing libraries
2022-12-18 15:45:08,504:INFO:Copying training dataset
2022-12-18 15:45:08,507:INFO:Defining folds
2022-12-18 15:45:08,507:INFO:Declaring metric variables
2022-12-18 15:45:08,512:INFO:Importing untrained model
2022-12-18 15:45:08,519:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:45:08,529:INFO:Starting cross validation
2022-12-18 15:45:08,531:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:08,791:INFO:Calculating mean and std
2022-12-18 15:45:08,793:INFO:Creating metrics dataframe
2022-12-18 15:45:08,796:INFO:Uploading results into container
2022-12-18 15:45:08,797:INFO:Uploading model into container now
2022-12-18 15:45:08,797:INFO:master_model_container: 17
2022-12-18 15:45:08,798:INFO:display_container: 2
2022-12-18 15:45:08,799:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=4359, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-18 15:45:08,801:INFO:create_model() successfully completed......................................
2022-12-18 15:45:08,881:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:08,881:INFO:Creating metrics dataframe
2022-12-18 15:45:08,897:INFO:Initializing Dummy Regressor
2022-12-18 15:45:08,897:INFO:Total runtime is 0.16093552907307943 minutes
2022-12-18 15:45:08,902:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:08,902:INFO:Initializing create_model()
2022-12-18 15:45:08,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C076680>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:08,903:INFO:Checking exceptions
2022-12-18 15:45:08,906:INFO:Importing libraries
2022-12-18 15:45:08,906:INFO:Copying training dataset
2022-12-18 15:45:08,909:INFO:Defining folds
2022-12-18 15:45:08,910:INFO:Declaring metric variables
2022-12-18 15:45:08,914:INFO:Importing untrained model
2022-12-18 15:45:08,922:INFO:Dummy Regressor Imported successfully
2022-12-18 15:45:08,930:INFO:Starting cross validation
2022-12-18 15:45:08,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:09,087:INFO:Calculating mean and std
2022-12-18 15:45:09,089:INFO:Creating metrics dataframe
2022-12-18 15:45:09,092:INFO:Uploading results into container
2022-12-18 15:45:09,093:INFO:Uploading model into container now
2022-12-18 15:45:09,093:INFO:master_model_container: 18
2022-12-18 15:45:09,094:INFO:display_container: 2
2022-12-18 15:45:09,094:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-12-18 15:45:09,094:INFO:create_model() successfully completed......................................
2022-12-18 15:45:09,175:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:09,175:INFO:Creating metrics dataframe
2022-12-18 15:45:09,207:INFO:Initializing create_model()
2022-12-18 15:45:09,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:09,207:INFO:Checking exceptions
2022-12-18 15:45:09,211:INFO:Importing libraries
2022-12-18 15:45:09,211:INFO:Copying training dataset
2022-12-18 15:45:09,213:INFO:Defining folds
2022-12-18 15:45:09,214:INFO:Declaring metric variables
2022-12-18 15:45:09,214:INFO:Importing untrained model
2022-12-18 15:45:09,214:INFO:Declaring custom model
2022-12-18 15:45:09,215:INFO:Huber Regressor Imported successfully
2022-12-18 15:45:09,217:INFO:Cross validation set to False
2022-12-18 15:45:09,218:INFO:Fitting Model
2022-12-18 15:45:09,305:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:45:09,305:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-12-18 15:45:09,305:INFO:create_model() successfully completed......................................
2022-12-18 15:45:09,393:INFO:Initializing create_model()
2022-12-18 15:45:09,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:09,394:INFO:Checking exceptions
2022-12-18 15:45:09,398:INFO:Importing libraries
2022-12-18 15:45:09,398:INFO:Copying training dataset
2022-12-18 15:45:09,402:INFO:Defining folds
2022-12-18 15:45:09,402:INFO:Declaring metric variables
2022-12-18 15:45:09,402:INFO:Importing untrained model
2022-12-18 15:45:09,402:INFO:Declaring custom model
2022-12-18 15:45:09,403:INFO:Least Angle Regression Imported successfully
2022-12-18 15:45:09,404:INFO:Cross validation set to False
2022-12-18 15:45:09,404:INFO:Fitting Model
2022-12-18 15:45:09,422:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:09,423:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False)
2022-12-18 15:45:09,423:INFO:create_model() successfully completed......................................
2022-12-18 15:45:09,507:INFO:Initializing create_model()
2022-12-18 15:45:09,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=DummyRegressor(constant=None, quantile=None, strategy='mean'), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:09,507:INFO:Checking exceptions
2022-12-18 15:45:09,512:INFO:Importing libraries
2022-12-18 15:45:09,512:INFO:Copying training dataset
2022-12-18 15:45:09,515:INFO:Defining folds
2022-12-18 15:45:09,515:INFO:Declaring metric variables
2022-12-18 15:45:09,515:INFO:Importing untrained model
2022-12-18 15:45:09,516:INFO:Declaring custom model
2022-12-18 15:45:09,517:INFO:Dummy Regressor Imported successfully
2022-12-18 15:45:09,518:INFO:Cross validation set to False
2022-12-18 15:45:09,518:INFO:Fitting Model
2022-12-18 15:45:09,528:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-12-18 15:45:09,528:INFO:create_model() successfully completed......................................
2022-12-18 15:45:09,650:INFO:master_model_container: 18
2022-12-18 15:45:09,651:INFO:display_container: 2
2022-12-18 15:45:09,652:INFO:[HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False), DummyRegressor(constant=None, quantile=None, strategy='mean')]
2022-12-18 15:45:09,652:INFO:compare_models() successfully completed......................................
2022-12-18 15:45:09,895:INFO:Initializing create_model()
2022-12-18 15:45:09,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, estimator=llar, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:09,896:INFO:Checking exceptions
2022-12-18 15:45:09,961:INFO:Importing libraries
2022-12-18 15:45:09,961:INFO:Copying training dataset
2022-12-18 15:45:09,967:INFO:Defining folds
2022-12-18 15:45:09,973:INFO:Declaring metric variables
2022-12-18 15:45:09,983:INFO:Importing untrained model
2022-12-18 15:45:09,989:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:45:10,009:INFO:Starting cross validation
2022-12-18 15:45:10,011:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:10,247:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,253:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,256:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,280:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,645:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,661:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,662:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:10,688:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,084:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,123:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,146:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,173:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,606:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,622:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,630:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:11,642:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:12,439:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:12,460:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:12,478:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:12,482:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:12,650:INFO:Calculating mean and std
2022-12-18 15:45:12,654:INFO:Creating metrics dataframe
2022-12-18 15:45:12,668:INFO:Finalizing model
2022-12-18 15:45:12,692:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:12,706:INFO:Uploading results into container
2022-12-18 15:45:12,708:INFO:Uploading model into container now
2022-12-18 15:45:12,733:INFO:master_model_container: 19
2022-12-18 15:45:12,734:INFO:display_container: 3
2022-12-18 15:45:12,734:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False)
2022-12-18 15:45:12,735:INFO:create_model() successfully completed......................................
2022-12-18 15:45:12,934:INFO:Initializing plot_model()
2022-12-18 15:45:12,935:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, system=True)
2022-12-18 15:45:12,935:INFO:Checking exceptions
2022-12-18 15:45:12,941:INFO:Preloading libraries
2022-12-18 15:45:12,941:INFO:Copying training dataset
2022-12-18 15:45:12,942:INFO:Plot type: residuals
2022-12-18 15:45:13,032:INFO:Fitting Model
2022-12-18 15:45:13,032:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LassoLars was fitted with feature names
  warnings.warn(

2022-12-18 15:45:13,065:INFO:Scoring test/hold-out set
2022-12-18 15:45:13,513:INFO:Visual Rendered Successfully
2022-12-18 15:45:13,598:INFO:plot_model() successfully completed......................................
2022-12-18 15:45:13,640:INFO:Initializing plot_model()
2022-12-18 15:45:13,640:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, system=True)
2022-12-18 15:45:13,641:INFO:Checking exceptions
2022-12-18 15:45:13,647:INFO:Preloading libraries
2022-12-18 15:45:13,647:INFO:Copying training dataset
2022-12-18 15:45:13,648:INFO:Plot type: vc
2022-12-18 15:45:13,649:INFO:Determining param_name
2022-12-18 15:45:13,649:INFO:param_name: alpha
2022-12-18 15:45:13,768:INFO:Fitting Model
2022-12-18 15:45:13,855:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,856:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,857:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,859:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,868:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,869:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,870:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,877:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,878:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,881:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,886:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,891:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,896:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,897:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,899:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,904:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,906:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,914:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,914:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,919:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,921:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,925:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,925:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,934:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,935:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,937:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,941:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,947:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,948:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,949:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,956:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,958:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,960:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,966:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,969:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,973:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,973:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,977:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,982:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,985:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,987:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,991:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,994:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:13,994:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,003:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,005:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,006:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,016:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,020:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,021:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,022:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,026:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,032:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,038:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,042:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,048:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,048:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,054:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,065:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,068:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,074:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,076:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,075:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,085:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,086:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,097:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,097:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,098:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,107:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,108:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,109:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,114:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,119:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,121:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,131:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,132:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,132:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,135:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,140:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,142:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,143:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,153:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,155:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,156:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,156:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,163:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,166:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,167:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,173:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,177:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,179:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,188:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,189:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,191:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,191:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,198:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,200:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,209:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:45:14,410:INFO:Visual Rendered Successfully
2022-12-18 15:45:14,499:INFO:plot_model() successfully completed......................................
2022-12-18 15:45:14,597:INFO:Initializing plot_model()
2022-12-18 15:45:14,598:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=4359, verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C43C0D43A0>, system=True)
2022-12-18 15:45:14,598:INFO:Checking exceptions
2022-12-18 15:45:14,605:INFO:Preloading libraries
2022-12-18 15:45:14,606:INFO:Copying training dataset
2022-12-18 15:45:14,606:INFO:Plot type: error
2022-12-18 15:45:14,667:INFO:Fitting Model
2022-12-18 15:45:14,667:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LassoLars was fitted with feature names
  warnings.warn(

2022-12-18 15:45:14,667:INFO:Scoring test/hold-out set
2022-12-18 15:45:14,975:INFO:Visual Rendered Successfully
2022-12-18 15:45:15,067:INFO:plot_model() successfully completed......................................
2022-12-18 15:45:15,444:INFO:PyCaret ClassificationExperiment
2022-12-18 15:45:15,445:INFO:Logging name: clf-default-name
2022-12-18 15:45:15,445:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-18 15:45:15,446:INFO:version 3.0.0.rc4
2022-12-18 15:45:15,446:INFO:Initializing setup()
2022-12-18 15:45:15,446:INFO:self.USI: ebc5
2022-12-18 15:45:15,446:INFO:self.variable_keys: {'exp_name_log', 'y', 'X', '_available_plots', 'seed', '_gpu_n_jobs_param', 'idx', 'n_jobs_param', 'variable_keys', 'html_param', 'fold_shuffle_param', 'fold_groups_param', '_all_metrics', 'memory', 'pipeline', 'data', 'logging_param', 'X_test', 'fix_imbalance', 'y_test', 'USI', '_is_multiclass', 'log_plots_param', 'gpu_param', 'X_train', '_all_models_internal', 'exp_id', 'target_param', '_ml_usecase', 'y_train', 'master_model_container', '_all_models', 'display_container', 'fold_generator'}
2022-12-18 15:45:15,446:INFO:Checking environment
2022-12-18 15:45:15,447:INFO:python_version: 3.10.4
2022-12-18 15:45:15,447:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-12-18 15:45:15,447:INFO:machine: AMD64
2022-12-18 15:45:15,447:INFO:platform: Windows-10-10.0.19045-SP0
2022-12-18 15:45:15,447:INFO:Memory: svmem(total=8503136256, available=1712234496, percent=79.9, used=6790901760, free=1712234496)
2022-12-18 15:45:15,447:INFO:Physical Core: 2
2022-12-18 15:45:15,447:INFO:Logical Core: 4
2022-12-18 15:45:15,447:INFO:Checking libraries
2022-12-18 15:45:15,448:INFO:System:
2022-12-18 15:45:15,448:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-12-18 15:45:15,448:INFO:executable: c:\Python3.10\python.exe
2022-12-18 15:45:15,448:INFO:   machine: Windows-10-10.0.19045-SP0
2022-12-18 15:45:15,448:INFO:PyCaret required dependencies:
2022-12-18 15:45:15,448:INFO:                 pip: 22.2.2
2022-12-18 15:45:15,448:INFO:          setuptools: 58.1.0
2022-12-18 15:45:15,449:INFO:             pycaret: 3.0.0rc4
2022-12-18 15:45:15,449:INFO:             IPython: 8.4.0
2022-12-18 15:45:15,449:INFO:          ipywidgets: 8.0.2
2022-12-18 15:45:15,449:INFO:                tqdm: 4.64.0
2022-12-18 15:45:15,449:INFO:               numpy: 1.22.1
2022-12-18 15:45:15,449:INFO:              pandas: 1.4.2
2022-12-18 15:45:15,449:INFO:              jinja2: 3.1.2
2022-12-18 15:45:15,450:INFO:               scipy: 1.8.1
2022-12-18 15:45:15,450:INFO:              joblib: 1.2.0
2022-12-18 15:45:15,450:INFO:             sklearn: 1.1.2
2022-12-18 15:45:15,450:INFO:                pyod: 1.0.6
2022-12-18 15:45:15,450:INFO:            imblearn: 0.9.1
2022-12-18 15:45:15,451:INFO:   category_encoders: 2.5.1.post0
2022-12-18 15:45:15,451:INFO:            lightgbm: 3.3.3
2022-12-18 15:45:15,451:INFO:               numba: 0.55.2
2022-12-18 15:45:15,451:INFO:            requests: 2.28.1
2022-12-18 15:45:15,451:INFO:          matplotlib: 3.5.1
2022-12-18 15:45:15,451:INFO:          scikitplot: 0.3.7
2022-12-18 15:45:15,451:INFO:         yellowbrick: 1.5
2022-12-18 15:45:15,452:INFO:              plotly: 5.11.0
2022-12-18 15:45:15,452:INFO:             kaleido: 0.2.1
2022-12-18 15:45:15,452:INFO:         statsmodels: 0.13.5
2022-12-18 15:45:15,452:INFO:              sktime: 0.13.4
2022-12-18 15:45:15,452:INFO:               tbats: 1.1.1
2022-12-18 15:45:15,452:INFO:            pmdarima: 1.8.5
2022-12-18 15:45:15,452:INFO:              psutil: 5.9.1
2022-12-18 15:45:15,452:INFO:PyCaret optional dependencies:
2022-12-18 15:45:15,453:INFO:                shap: Not installed
2022-12-18 15:45:15,453:INFO:           interpret: Not installed
2022-12-18 15:45:15,453:INFO:                umap: Not installed
2022-12-18 15:45:15,453:INFO:    pandas_profiling: Not installed
2022-12-18 15:45:15,453:INFO:  explainerdashboard: Not installed
2022-12-18 15:45:15,453:INFO:             autoviz: Not installed
2022-12-18 15:45:15,453:INFO:           fairlearn: Not installed
2022-12-18 15:45:15,454:INFO:             xgboost: Not installed
2022-12-18 15:45:15,454:INFO:            catboost: Not installed
2022-12-18 15:45:15,454:INFO:              kmodes: Not installed
2022-12-18 15:45:15,454:INFO:             mlxtend: Not installed
2022-12-18 15:45:15,454:INFO:       statsforecast: Not installed
2022-12-18 15:45:15,454:INFO:        tune_sklearn: Not installed
2022-12-18 15:45:15,454:INFO:                 ray: Not installed
2022-12-18 15:45:15,454:INFO:            hyperopt: Not installed
2022-12-18 15:45:15,454:INFO:              optuna: Not installed
2022-12-18 15:45:15,455:INFO:               skopt: Not installed
2022-12-18 15:45:15,455:INFO:              mlflow: Not installed
2022-12-18 15:45:15,455:INFO:              gradio: Not installed
2022-12-18 15:45:15,455:INFO:             fastapi: Not installed
2022-12-18 15:45:15,455:INFO:             uvicorn: Not installed
2022-12-18 15:45:15,455:INFO:              m2cgen: Not installed
2022-12-18 15:45:15,455:INFO:           evidently: Not installed
2022-12-18 15:45:15,456:INFO:                nltk: 3.7
2022-12-18 15:45:15,456:INFO:            pyLDAvis: Not installed
2022-12-18 15:45:15,456:INFO:              gensim: Not installed
2022-12-18 15:45:15,456:INFO:               spacy: 3.4.3
2022-12-18 15:45:15,456:INFO:           wordcloud: Not installed
2022-12-18 15:45:15,456:INFO:            textblob: Not installed
2022-12-18 15:45:15,456:INFO:               fugue: Not installed
2022-12-18 15:45:15,456:INFO:           streamlit: Not installed
2022-12-18 15:45:15,456:INFO:             prophet: Not installed
2022-12-18 15:45:15,457:INFO:None
2022-12-18 15:45:15,457:INFO:Set up data.
2022-12-18 15:45:15,468:INFO:Set up train/test split.
2022-12-18 15:45:15,485:INFO:Set up index.
2022-12-18 15:45:15,486:INFO:Assigning column types.
2022-12-18 15:45:15,493:INFO:Set up folding strategy.
2022-12-18 15:45:15,494:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-18 15:45:15,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:45:15,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:45:15,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:15,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:15,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:45:15,752:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:45:15,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:15,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:15,815:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-18 15:45:15,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:45:15,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:15,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,037:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:45:16,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,216:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-12-18 15:45:16,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:16,624:INFO:Preparing preprocessing pipeline...
2022-12-18 15:45:16,626:INFO:Set up simple imputation.
2022-12-18 15:45:16,627:INFO:Set up variance threshold.
2022-12-18 15:45:16,686:INFO:Finished creating preprocessing pipeline.
2022-12-18 15:45:16,693:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-18 15:45:16,693:INFO:Creating final display dataframe.
2022-12-18 15:45:17,054:INFO:Setup display_container:                     Description             Value
0                    Session id              3601
1                        Target              area
2                   Target type            Binary
3           Original data shape          (517, 9)
4        Transformed data shape          (517, 9)
5   Transformed train set shape          (361, 9)
6    Transformed test set shape          (156, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation          constant
12       Low variance threshold                 0
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              ebc5
2022-12-18 15:45:17,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:17,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:17,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:17,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:45:17,395:INFO:setup() successfully completed in 1.95s...............
2022-12-18 15:45:17,561:INFO:Initializing compare_models()
2022-12-18 15:45:17,561:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-12-18 15:45:17,562:INFO:Checking exceptions
2022-12-18 15:45:17,570:INFO:Preparing display monitor
2022-12-18 15:45:17,643:INFO:Initializing Logistic Regression
2022-12-18 15:45:17,644:INFO:Total runtime is 1.5938282012939452e-05 minutes
2022-12-18 15:45:17,651:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:17,652:INFO:Initializing create_model()
2022-12-18 15:45:17,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:17,652:INFO:Checking exceptions
2022-12-18 15:45:17,656:INFO:Importing libraries
2022-12-18 15:45:17,656:INFO:Copying training dataset
2022-12-18 15:45:17,662:INFO:Defining folds
2022-12-18 15:45:17,663:INFO:Declaring metric variables
2022-12-18 15:45:17,668:INFO:Importing untrained model
2022-12-18 15:45:17,676:INFO:Logistic Regression Imported successfully
2022-12-18 15:45:17,690:INFO:Starting cross validation
2022-12-18 15:45:17,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:19,508:INFO:Calculating mean and std
2022-12-18 15:45:19,511:INFO:Creating metrics dataframe
2022-12-18 15:45:19,516:INFO:Uploading results into container
2022-12-18 15:45:19,517:INFO:Uploading model into container now
2022-12-18 15:45:19,517:INFO:master_model_container: 1
2022-12-18 15:45:19,518:INFO:display_container: 2
2022-12-18 15:45:19,519:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3601, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-18 15:45:19,519:INFO:create_model() successfully completed......................................
2022-12-18 15:45:19,593:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:19,593:INFO:Creating metrics dataframe
2022-12-18 15:45:19,614:INFO:Initializing K Neighbors Classifier
2022-12-18 15:45:19,614:INFO:Total runtime is 0.032843430836995445 minutes
2022-12-18 15:45:19,620:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:19,620:INFO:Initializing create_model()
2022-12-18 15:45:19,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:19,621:INFO:Checking exceptions
2022-12-18 15:45:19,624:INFO:Importing libraries
2022-12-18 15:45:19,624:INFO:Copying training dataset
2022-12-18 15:45:19,629:INFO:Defining folds
2022-12-18 15:45:19,630:INFO:Declaring metric variables
2022-12-18 15:45:19,638:INFO:Importing untrained model
2022-12-18 15:45:19,647:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:45:19,662:INFO:Starting cross validation
2022-12-18 15:45:19,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:20,198:INFO:Calculating mean and std
2022-12-18 15:45:20,201:INFO:Creating metrics dataframe
2022-12-18 15:45:20,209:INFO:Uploading results into container
2022-12-18 15:45:20,210:INFO:Uploading model into container now
2022-12-18 15:45:20,210:INFO:master_model_container: 2
2022-12-18 15:45:20,210:INFO:display_container: 2
2022-12-18 15:45:20,210:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:45:20,210:INFO:create_model() successfully completed......................................
2022-12-18 15:45:20,295:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:20,295:INFO:Creating metrics dataframe
2022-12-18 15:45:20,306:INFO:Initializing Naive Bayes
2022-12-18 15:45:20,307:INFO:Total runtime is 0.04440086285273234 minutes
2022-12-18 15:45:20,311:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:20,312:INFO:Initializing create_model()
2022-12-18 15:45:20,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:20,312:INFO:Checking exceptions
2022-12-18 15:45:20,315:INFO:Importing libraries
2022-12-18 15:45:20,315:INFO:Copying training dataset
2022-12-18 15:45:20,318:INFO:Defining folds
2022-12-18 15:45:20,319:INFO:Declaring metric variables
2022-12-18 15:45:20,326:INFO:Importing untrained model
2022-12-18 15:45:20,332:INFO:Naive Bayes Imported successfully
2022-12-18 15:45:20,346:INFO:Starting cross validation
2022-12-18 15:45:20,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:20,629:INFO:Calculating mean and std
2022-12-18 15:45:20,632:INFO:Creating metrics dataframe
2022-12-18 15:45:20,636:INFO:Uploading results into container
2022-12-18 15:45:20,636:INFO:Uploading model into container now
2022-12-18 15:45:20,637:INFO:master_model_container: 3
2022-12-18 15:45:20,637:INFO:display_container: 2
2022-12-18 15:45:20,637:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-12-18 15:45:20,637:INFO:create_model() successfully completed......................................
2022-12-18 15:45:20,723:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:20,723:INFO:Creating metrics dataframe
2022-12-18 15:45:20,734:INFO:Initializing Decision Tree Classifier
2022-12-18 15:45:20,734:INFO:Total runtime is 0.051518205801645914 minutes
2022-12-18 15:45:20,740:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:20,741:INFO:Initializing create_model()
2022-12-18 15:45:20,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:20,741:INFO:Checking exceptions
2022-12-18 15:45:20,743:INFO:Importing libraries
2022-12-18 15:45:20,743:INFO:Copying training dataset
2022-12-18 15:45:20,746:INFO:Defining folds
2022-12-18 15:45:20,746:INFO:Declaring metric variables
2022-12-18 15:45:20,750:INFO:Importing untrained model
2022-12-18 15:45:20,758:INFO:Decision Tree Classifier Imported successfully
2022-12-18 15:45:20,773:INFO:Starting cross validation
2022-12-18 15:45:20,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:21,041:INFO:Calculating mean and std
2022-12-18 15:45:21,043:INFO:Creating metrics dataframe
2022-12-18 15:45:21,046:INFO:Uploading results into container
2022-12-18 15:45:21,046:INFO:Uploading model into container now
2022-12-18 15:45:21,047:INFO:master_model_container: 4
2022-12-18 15:45:21,047:INFO:display_container: 2
2022-12-18 15:45:21,048:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3601, splitter='best')
2022-12-18 15:45:21,048:INFO:create_model() successfully completed......................................
2022-12-18 15:45:21,133:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:21,133:INFO:Creating metrics dataframe
2022-12-18 15:45:21,150:INFO:Initializing SVM - Linear Kernel
2022-12-18 15:45:21,150:INFO:Total runtime is 0.05844498475392659 minutes
2022-12-18 15:45:21,163:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:21,163:INFO:Initializing create_model()
2022-12-18 15:45:21,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:21,163:INFO:Checking exceptions
2022-12-18 15:45:21,166:INFO:Importing libraries
2022-12-18 15:45:21,166:INFO:Copying training dataset
2022-12-18 15:45:21,175:INFO:Defining folds
2022-12-18 15:45:21,175:INFO:Declaring metric variables
2022-12-18 15:45:21,192:INFO:Importing untrained model
2022-12-18 15:45:21,201:INFO:SVM - Linear Kernel Imported successfully
2022-12-18 15:45:21,215:INFO:Starting cross validation
2022-12-18 15:45:21,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:21,321:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:45:21,425:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:45:21,471:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:45:21,532:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:45:21,542:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:45:21,546:INFO:Calculating mean and std
2022-12-18 15:45:21,548:INFO:Creating metrics dataframe
2022-12-18 15:45:21,553:INFO:Uploading results into container
2022-12-18 15:45:21,556:INFO:Uploading model into container now
2022-12-18 15:45:21,557:INFO:master_model_container: 5
2022-12-18 15:45:21,558:INFO:display_container: 2
2022-12-18 15:45:21,558:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3601, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-18 15:45:21,558:INFO:create_model() successfully completed......................................
2022-12-18 15:45:21,661:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:21,661:INFO:Creating metrics dataframe
2022-12-18 15:45:21,677:INFO:Initializing Ridge Classifier
2022-12-18 15:45:21,677:INFO:Total runtime is 0.0672355850537618 minutes
2022-12-18 15:45:21,683:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:21,683:INFO:Initializing create_model()
2022-12-18 15:45:21,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:21,684:INFO:Checking exceptions
2022-12-18 15:45:21,686:INFO:Importing libraries
2022-12-18 15:45:21,689:INFO:Copying training dataset
2022-12-18 15:45:21,694:INFO:Defining folds
2022-12-18 15:45:21,694:INFO:Declaring metric variables
2022-12-18 15:45:21,702:INFO:Importing untrained model
2022-12-18 15:45:21,708:INFO:Ridge Classifier Imported successfully
2022-12-18 15:45:21,722:INFO:Starting cross validation
2022-12-18 15:45:21,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:21,965:INFO:Calculating mean and std
2022-12-18 15:45:21,966:INFO:Creating metrics dataframe
2022-12-18 15:45:21,973:INFO:Uploading results into container
2022-12-18 15:45:21,974:INFO:Uploading model into container now
2022-12-18 15:45:21,975:INFO:master_model_container: 6
2022-12-18 15:45:21,975:INFO:display_container: 2
2022-12-18 15:45:21,976:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=3601, solver='auto', tol=0.001)
2022-12-18 15:45:21,976:INFO:create_model() successfully completed......................................
2022-12-18 15:45:22,060:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:22,060:INFO:Creating metrics dataframe
2022-12-18 15:45:22,075:INFO:Initializing Random Forest Classifier
2022-12-18 15:45:22,075:INFO:Total runtime is 0.07386993567148845 minutes
2022-12-18 15:45:22,080:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:22,081:INFO:Initializing create_model()
2022-12-18 15:45:22,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:22,081:INFO:Checking exceptions
2022-12-18 15:45:22,084:INFO:Importing libraries
2022-12-18 15:45:22,084:INFO:Copying training dataset
2022-12-18 15:45:22,090:INFO:Defining folds
2022-12-18 15:45:22,090:INFO:Declaring metric variables
2022-12-18 15:45:22,094:INFO:Importing untrained model
2022-12-18 15:45:22,100:INFO:Random Forest Classifier Imported successfully
2022-12-18 15:45:22,115:INFO:Starting cross validation
2022-12-18 15:45:22,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:23,673:INFO:Calculating mean and std
2022-12-18 15:45:23,675:INFO:Creating metrics dataframe
2022-12-18 15:45:23,679:INFO:Uploading results into container
2022-12-18 15:45:23,680:INFO:Uploading model into container now
2022-12-18 15:45:23,681:INFO:master_model_container: 7
2022-12-18 15:45:23,681:INFO:display_container: 2
2022-12-18 15:45:23,682:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:45:23,682:INFO:create_model() successfully completed......................................
2022-12-18 15:45:23,776:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:23,777:INFO:Creating metrics dataframe
2022-12-18 15:45:23,790:INFO:Initializing Quadratic Discriminant Analysis
2022-12-18 15:45:23,790:INFO:Total runtime is 0.10244656006495158 minutes
2022-12-18 15:45:23,795:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:23,796:INFO:Initializing create_model()
2022-12-18 15:45:23,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:23,796:INFO:Checking exceptions
2022-12-18 15:45:23,798:INFO:Importing libraries
2022-12-18 15:45:23,798:INFO:Copying training dataset
2022-12-18 15:45:23,801:INFO:Defining folds
2022-12-18 15:45:23,801:INFO:Declaring metric variables
2022-12-18 15:45:23,806:INFO:Importing untrained model
2022-12-18 15:45:23,816:INFO:Quadratic Discriminant Analysis Imported successfully
2022-12-18 15:45:23,832:INFO:Starting cross validation
2022-12-18 15:45:23,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:23,889:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:23,893:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:23,903:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:23,912:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,912:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,913:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,915:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:23,933:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,933:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,933:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,934:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,934:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,935:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,941:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,942:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,942:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,942:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,942:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,942:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,957:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,957:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,958:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,961:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,961:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,962:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

in self.scalings_])

2022-12-18 15:45:23,962:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:23,962:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:23,999:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:24,007:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:24,011:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:24,016:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:24,025:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,025:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,025:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,029:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,029:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))


2022-12-18 15:45:24,029:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,029:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,030:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,036:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,037:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,038:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,042:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,044:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,044:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,047:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,047:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,047:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,049:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,049:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,049:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,078:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:24,079:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-18 15:45:24,092:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,092:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,092:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,092:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,093:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,093:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,105:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,105:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,106:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,106:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,106:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-12-18 15:45:24,106:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-12-18 15:45:24,111:INFO:Calculating mean and std
2022-12-18 15:45:24,113:INFO:Creating metrics dataframe
2022-12-18 15:45:24,117:INFO:Uploading results into container
2022-12-18 15:45:24,117:INFO:Uploading model into container now
2022-12-18 15:45:24,118:INFO:master_model_container: 8
2022-12-18 15:45:24,118:INFO:display_container: 2
2022-12-18 15:45:24,120:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-12-18 15:45:24,121:INFO:create_model() successfully completed......................................
2022-12-18 15:45:24,209:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:24,209:INFO:Creating metrics dataframe
2022-12-18 15:45:24,224:INFO:Initializing Ada Boost Classifier
2022-12-18 15:45:24,224:INFO:Total runtime is 0.10968654950459798 minutes
2022-12-18 15:45:24,228:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:24,229:INFO:Initializing create_model()
2022-12-18 15:45:24,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:24,229:INFO:Checking exceptions
2022-12-18 15:45:24,232:INFO:Importing libraries
2022-12-18 15:45:24,232:INFO:Copying training dataset
2022-12-18 15:45:24,239:INFO:Defining folds
2022-12-18 15:45:24,239:INFO:Declaring metric variables
2022-12-18 15:45:24,247:INFO:Importing untrained model
2022-12-18 15:45:24,264:INFO:Ada Boost Classifier Imported successfully
2022-12-18 15:45:24,288:INFO:Starting cross validation
2022-12-18 15:45:24,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:25,072:INFO:Calculating mean and std
2022-12-18 15:45:25,075:INFO:Creating metrics dataframe
2022-12-18 15:45:25,082:INFO:Uploading results into container
2022-12-18 15:45:25,083:INFO:Uploading model into container now
2022-12-18 15:45:25,083:INFO:master_model_container: 9
2022-12-18 15:45:25,085:INFO:display_container: 2
2022-12-18 15:45:25,087:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3601)
2022-12-18 15:45:25,087:INFO:create_model() successfully completed......................................
2022-12-18 15:45:25,179:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:25,179:INFO:Creating metrics dataframe
2022-12-18 15:45:25,194:INFO:Initializing Gradient Boosting Classifier
2022-12-18 15:45:25,195:INFO:Total runtime is 0.12586172421773276 minutes
2022-12-18 15:45:25,200:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:25,200:INFO:Initializing create_model()
2022-12-18 15:45:25,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:25,202:INFO:Checking exceptions
2022-12-18 15:45:25,205:INFO:Importing libraries
2022-12-18 15:45:25,205:INFO:Copying training dataset
2022-12-18 15:45:25,213:INFO:Defining folds
2022-12-18 15:45:25,214:INFO:Declaring metric variables
2022-12-18 15:45:25,221:INFO:Importing untrained model
2022-12-18 15:45:25,230:INFO:Gradient Boosting Classifier Imported successfully
2022-12-18 15:45:25,248:INFO:Starting cross validation
2022-12-18 15:45:25,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:25,989:INFO:Calculating mean and std
2022-12-18 15:45:25,991:INFO:Creating metrics dataframe
2022-12-18 15:45:25,994:INFO:Uploading results into container
2022-12-18 15:45:25,995:INFO:Uploading model into container now
2022-12-18 15:45:25,996:INFO:master_model_container: 10
2022-12-18 15:45:25,996:INFO:display_container: 2
2022-12-18 15:45:25,996:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3601, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-18 15:45:25,996:INFO:create_model() successfully completed......................................
2022-12-18 15:45:26,079:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:26,079:INFO:Creating metrics dataframe
2022-12-18 15:45:26,093:INFO:Initializing Linear Discriminant Analysis
2022-12-18 15:45:26,093:INFO:Total runtime is 0.1408260782559713 minutes
2022-12-18 15:45:26,097:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:26,098:INFO:Initializing create_model()
2022-12-18 15:45:26,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:26,099:INFO:Checking exceptions
2022-12-18 15:45:26,102:INFO:Importing libraries
2022-12-18 15:45:26,102:INFO:Copying training dataset
2022-12-18 15:45:26,108:INFO:Defining folds
2022-12-18 15:45:26,108:INFO:Declaring metric variables
2022-12-18 15:45:26,113:INFO:Importing untrained model
2022-12-18 15:45:26,120:INFO:Linear Discriminant Analysis Imported successfully
2022-12-18 15:45:26,133:INFO:Starting cross validation
2022-12-18 15:45:26,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:26,383:INFO:Calculating mean and std
2022-12-18 15:45:26,386:INFO:Creating metrics dataframe
2022-12-18 15:45:26,390:INFO:Uploading results into container
2022-12-18 15:45:26,390:INFO:Uploading model into container now
2022-12-18 15:45:26,391:INFO:master_model_container: 11
2022-12-18 15:45:26,391:INFO:display_container: 2
2022-12-18 15:45:26,391:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-12-18 15:45:26,392:INFO:create_model() successfully completed......................................
2022-12-18 15:45:26,474:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:26,474:INFO:Creating metrics dataframe
2022-12-18 15:45:26,490:INFO:Initializing Extra Trees Classifier
2022-12-18 15:45:26,490:INFO:Total runtime is 0.14744391043980917 minutes
2022-12-18 15:45:26,495:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:26,495:INFO:Initializing create_model()
2022-12-18 15:45:26,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:26,495:INFO:Checking exceptions
2022-12-18 15:45:26,498:INFO:Importing libraries
2022-12-18 15:45:26,498:INFO:Copying training dataset
2022-12-18 15:45:26,504:INFO:Defining folds
2022-12-18 15:45:26,504:INFO:Declaring metric variables
2022-12-18 15:45:26,508:INFO:Importing untrained model
2022-12-18 15:45:26,515:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:45:26,527:INFO:Starting cross validation
2022-12-18 15:45:26,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:27,715:INFO:Calculating mean and std
2022-12-18 15:45:27,717:INFO:Creating metrics dataframe
2022-12-18 15:45:27,721:INFO:Uploading results into container
2022-12-18 15:45:27,721:INFO:Uploading model into container now
2022-12-18 15:45:27,722:INFO:master_model_container: 12
2022-12-18 15:45:27,722:INFO:display_container: 2
2022-12-18 15:45:27,723:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:45:27,723:INFO:create_model() successfully completed......................................
2022-12-18 15:45:27,806:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:27,806:INFO:Creating metrics dataframe
2022-12-18 15:45:27,822:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:45:27,822:INFO:Total runtime is 0.16964466174443563 minutes
2022-12-18 15:45:27,828:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:27,828:INFO:Initializing create_model()
2022-12-18 15:45:27,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:27,829:INFO:Checking exceptions
2022-12-18 15:45:27,831:INFO:Importing libraries
2022-12-18 15:45:27,832:INFO:Copying training dataset
2022-12-18 15:45:27,839:INFO:Defining folds
2022-12-18 15:45:27,839:INFO:Declaring metric variables
2022-12-18 15:45:27,846:INFO:Importing untrained model
2022-12-18 15:45:27,852:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:45:27,880:INFO:Starting cross validation
2022-12-18 15:45:27,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:28,342:INFO:Calculating mean and std
2022-12-18 15:45:28,343:INFO:Creating metrics dataframe
2022-12-18 15:45:28,348:INFO:Uploading results into container
2022-12-18 15:45:28,349:INFO:Uploading model into container now
2022-12-18 15:45:28,350:INFO:master_model_container: 13
2022-12-18 15:45:28,350:INFO:display_container: 2
2022-12-18 15:45:28,351:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3601, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-18 15:45:28,351:INFO:create_model() successfully completed......................................
2022-12-18 15:45:28,443:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:28,443:INFO:Creating metrics dataframe
2022-12-18 15:45:28,460:INFO:Initializing Dummy Classifier
2022-12-18 15:45:28,460:INFO:Total runtime is 0.18027611176172892 minutes
2022-12-18 15:45:28,466:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:28,467:INFO:Initializing create_model()
2022-12-18 15:45:28,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C9DD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:28,467:INFO:Checking exceptions
2022-12-18 15:45:28,470:INFO:Importing libraries
2022-12-18 15:45:28,470:INFO:Copying training dataset
2022-12-18 15:45:28,474:INFO:Defining folds
2022-12-18 15:45:28,474:INFO:Declaring metric variables
2022-12-18 15:45:28,477:INFO:Importing untrained model
2022-12-18 15:45:28,485:INFO:Dummy Classifier Imported successfully
2022-12-18 15:45:28,501:INFO:Starting cross validation
2022-12-18 15:45:28,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:28,774:INFO:Calculating mean and std
2022-12-18 15:45:28,777:INFO:Creating metrics dataframe
2022-12-18 15:45:28,785:INFO:Uploading results into container
2022-12-18 15:45:28,786:INFO:Uploading model into container now
2022-12-18 15:45:28,786:INFO:master_model_container: 14
2022-12-18 15:45:28,786:INFO:display_container: 2
2022-12-18 15:45:28,787:INFO:DummyClassifier(constant=None, random_state=3601, strategy='prior')
2022-12-18 15:45:28,787:INFO:create_model() successfully completed......................................
2022-12-18 15:45:28,883:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:28,883:INFO:Creating metrics dataframe
2022-12-18 15:45:28,924:INFO:Initializing create_model()
2022-12-18 15:45:28,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3601, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:28,924:INFO:Checking exceptions
2022-12-18 15:45:28,931:INFO:Importing libraries
2022-12-18 15:45:28,931:INFO:Copying training dataset
2022-12-18 15:45:28,935:INFO:Defining folds
2022-12-18 15:45:28,935:INFO:Declaring metric variables
2022-12-18 15:45:28,935:INFO:Importing untrained model
2022-12-18 15:45:28,936:INFO:Declaring custom model
2022-12-18 15:45:28,936:INFO:Random Forest Classifier Imported successfully
2022-12-18 15:45:28,937:INFO:Cross validation set to False
2022-12-18 15:45:28,937:INFO:Fitting Model
2022-12-18 15:45:29,214:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:45:29,214:INFO:create_model() successfully completed......................................
2022-12-18 15:45:29,342:INFO:master_model_container: 14
2022-12-18 15:45:29,343:INFO:display_container: 2
2022-12-18 15:45:29,343:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:45:29,344:INFO:compare_models() successfully completed......................................
2022-12-18 15:45:29,514:INFO:Initializing create_model()
2022-12-18 15:45:29,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=et, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:29,515:INFO:Checking exceptions
2022-12-18 15:45:29,572:INFO:Importing libraries
2022-12-18 15:45:29,572:INFO:Copying training dataset
2022-12-18 15:45:29,577:INFO:Defining folds
2022-12-18 15:45:29,577:INFO:Declaring metric variables
2022-12-18 15:45:29,583:INFO:Importing untrained model
2022-12-18 15:45:29,591:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:45:29,607:INFO:Starting cross validation
2022-12-18 15:45:29,609:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:33,746:INFO:Calculating mean and std
2022-12-18 15:45:33,748:INFO:Creating metrics dataframe
2022-12-18 15:45:33,755:INFO:Finalizing model
2022-12-18 15:45:33,921:INFO:Uploading results into container
2022-12-18 15:45:33,923:INFO:Uploading model into container now
2022-12-18 15:45:33,939:INFO:master_model_container: 15
2022-12-18 15:45:33,939:INFO:display_container: 3
2022-12-18 15:45:33,940:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:45:33,940:INFO:create_model() successfully completed......................................
2022-12-18 15:45:34,118:INFO:Initializing plot_model()
2022-12-18 15:45:34,118:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, system=True)
2022-12-18 15:45:34,118:INFO:Checking exceptions
2022-12-18 15:45:34,155:INFO:Preloading libraries
2022-12-18 15:45:34,170:INFO:Copying training dataset
2022-12-18 15:45:34,170:INFO:Plot type: auc
2022-12-18 15:45:34,215:INFO:Fitting Model
2022-12-18 15:45:34,215:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2022-12-18 15:45:34,215:INFO:Scoring test/hold-out set
2022-12-18 15:45:34,459:INFO:Visual Rendered Successfully
2022-12-18 15:45:34,618:INFO:plot_model() successfully completed......................................
2022-12-18 15:45:34,657:INFO:Initializing plot_model()
2022-12-18 15:45:34,657:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, system=True)
2022-12-18 15:45:34,657:INFO:Checking exceptions
2022-12-18 15:45:34,697:INFO:Preloading libraries
2022-12-18 15:45:34,714:INFO:Copying training dataset
2022-12-18 15:45:34,714:INFO:Plot type: learning
2022-12-18 15:45:34,762:INFO:Fitting Model
2022-12-18 15:45:44,873:INFO:Visual Rendered Successfully
2022-12-18 15:45:44,962:INFO:plot_model() successfully completed......................................
2022-12-18 15:45:45,018:INFO:Initializing tune_model()
2022-12-18 15:45:45,019:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>)
2022-12-18 15:45:45,019:INFO:Checking exceptions
2022-12-18 15:45:45,085:INFO:Copying training dataset
2022-12-18 15:45:45,096:INFO:Checking base model
2022-12-18 15:45:45,097:INFO:Base model : Extra Trees Classifier
2022-12-18 15:45:45,106:INFO:Declaring metric variables
2022-12-18 15:45:45,113:INFO:Defining Hyperparameters
2022-12-18 15:45:45,230:INFO:Tuning with n_jobs=-1
2022-12-18 15:45:45,230:INFO:Initializing RandomizedSearchCV
2022-12-18 15:45:57,775:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2022-12-18 15:45:57,776:INFO:Hyperparameter search completed
2022-12-18 15:45:57,776:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:57,777:INFO:Initializing create_model()
2022-12-18 15:45:57,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42FE32AA0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': False})
2022-12-18 15:45:57,778:INFO:Checking exceptions
2022-12-18 15:45:57,781:INFO:Importing libraries
2022-12-18 15:45:57,781:INFO:Copying training dataset
2022-12-18 15:45:57,786:INFO:Defining folds
2022-12-18 15:45:57,786:INFO:Declaring metric variables
2022-12-18 15:45:57,790:INFO:Importing untrained model
2022-12-18 15:45:57,790:INFO:Declaring custom model
2022-12-18 15:45:57,795:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:45:57,804:INFO:Starting cross validation
2022-12-18 15:45:57,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:45:58,822:INFO:Calculating mean and std
2022-12-18 15:45:58,824:INFO:Creating metrics dataframe
2022-12-18 15:45:58,831:INFO:Finalizing model
2022-12-18 15:45:59,109:INFO:Uploading results into container
2022-12-18 15:45:59,110:INFO:Uploading model into container now
2022-12-18 15:45:59,111:INFO:master_model_container: 16
2022-12-18 15:45:59,111:INFO:display_container: 4
2022-12-18 15:45:59,113:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=11, max_features='log2',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0001, min_samples_leaf=4,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:45:59,113:INFO:create_model() successfully completed......................................
2022-12-18 15:45:59,212:INFO:SubProcess create_model() end ==================================
2022-12-18 15:45:59,212:INFO:choose_better activated
2022-12-18 15:45:59,216:INFO:SubProcess create_model() called ==================================
2022-12-18 15:45:59,217:INFO:Initializing create_model()
2022-12-18 15:45:59,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:45:59,218:INFO:Checking exceptions
2022-12-18 15:45:59,222:INFO:Importing libraries
2022-12-18 15:45:59,223:INFO:Copying training dataset
2022-12-18 15:45:59,225:INFO:Defining folds
2022-12-18 15:45:59,225:INFO:Declaring metric variables
2022-12-18 15:45:59,225:INFO:Importing untrained model
2022-12-18 15:45:59,225:INFO:Declaring custom model
2022-12-18 15:45:59,226:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:45:59,226:INFO:Starting cross validation
2022-12-18 15:45:59,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:46:00,658:INFO:Calculating mean and std
2022-12-18 15:46:00,658:INFO:Creating metrics dataframe
2022-12-18 15:46:00,660:INFO:Finalizing model
2022-12-18 15:46:00,831:INFO:Uploading results into container
2022-12-18 15:46:00,832:INFO:Uploading model into container now
2022-12-18 15:46:00,832:INFO:master_model_container: 17
2022-12-18 15:46:00,833:INFO:display_container: 5
2022-12-18 15:46:00,834:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:46:00,835:INFO:create_model() successfully completed......................................
2022-12-18 15:46:00,924:INFO:SubProcess create_model() end ==================================
2022-12-18 15:46:00,924:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False) result for Accuracy is 0.5541
2022-12-18 15:46:00,925:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=11, max_features='log2',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0001, min_samples_leaf=4,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False) result for Accuracy is 0.5347
2022-12-18 15:46:00,925:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False) is best model
2022-12-18 15:46:00,926:INFO:choose_better completed
2022-12-18 15:46:00,926:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-12-18 15:46:00,939:INFO:master_model_container: 17
2022-12-18 15:46:00,940:INFO:display_container: 4
2022-12-18 15:46:00,941:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False)
2022-12-18 15:46:00,941:INFO:tune_model() successfully completed......................................
2022-12-18 15:46:01,101:INFO:Initializing plot_model()
2022-12-18 15:46:01,102:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, system=True)
2022-12-18 15:46:01,102:INFO:Checking exceptions
2022-12-18 15:46:01,144:INFO:Preloading libraries
2022-12-18 15:46:01,169:INFO:Copying training dataset
2022-12-18 15:46:01,170:INFO:Plot type: learning
2022-12-18 15:46:01,241:INFO:Fitting Model
2022-12-18 15:46:11,995:INFO:Visual Rendered Successfully
2022-12-18 15:46:12,091:INFO:plot_model() successfully completed......................................
2022-12-18 15:46:12,163:INFO:Initializing save_model()
2022-12-18 15:46:12,163:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3601, verbose=0, warm_start=False), model_name=forestfiremodel, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-12-18 15:46:12,163:INFO:Adding model into prep_pipe
2022-12-18 15:46:12,248:INFO:forestfiremodel.pkl saved in current working directory
2022-12-18 15:46:12,257:INFO:Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Trans...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=3601,
                                      verbose=0, warm_start=False))],
         verbose=False)
2022-12-18 15:46:12,257:INFO:save_model() successfully completed......................................
2022-12-18 15:48:09,931:INFO:Initializing create_model()
2022-12-18 15:48:09,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=llar, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:48:09,932:INFO:Checking exceptions
2022-12-18 15:48:25,645:INFO:Initializing create_model()
2022-12-18 15:48:25,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:48:25,645:INFO:Checking exceptions
2022-12-18 15:48:54,676:INFO:Initializing create_model()
2022-12-18 15:48:54,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C43C867A90>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:48:54,677:INFO:Checking exceptions
2022-12-18 15:48:58,603:INFO:PyCaret RegressionExperiment
2022-12-18 15:48:58,603:INFO:Logging name: reg-default-name
2022-12-18 15:48:58,603:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-18 15:48:58,604:INFO:version 3.0.0.rc4
2022-12-18 15:48:58,604:INFO:Initializing setup()
2022-12-18 15:48:58,604:INFO:self.USI: 4bff
2022-12-18 15:48:58,604:INFO:self.variable_keys: {'exp_name_log', 'y', 'X', '_available_plots', 'seed', '_gpu_n_jobs_param', 'idx', 'n_jobs_param', 'variable_keys', 'html_param', 'fold_shuffle_param', 'fold_groups_param', '_all_metrics', 'memory', 'pipeline', 'data', 'transform_target_param', 'logging_param', 'transform_target_method_param', 'X_test', 'y_test', 'USI', 'log_plots_param', 'gpu_param', 'X_train', '_all_models_internal', 'exp_id', 'target_param', '_ml_usecase', 'y_train', 'master_model_container', '_all_models', 'display_container', 'fold_generator'}
2022-12-18 15:48:58,604:INFO:Checking environment
2022-12-18 15:48:58,604:INFO:python_version: 3.10.4
2022-12-18 15:48:58,604:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-12-18 15:48:58,605:INFO:machine: AMD64
2022-12-18 15:48:58,605:INFO:platform: Windows-10-10.0.19045-SP0
2022-12-18 15:48:58,605:INFO:Memory: svmem(total=8503136256, available=1680539648, percent=80.2, used=6822596608, free=1680539648)
2022-12-18 15:48:58,605:INFO:Physical Core: 2
2022-12-18 15:48:58,605:INFO:Logical Core: 4
2022-12-18 15:48:58,605:INFO:Checking libraries
2022-12-18 15:48:58,606:INFO:System:
2022-12-18 15:48:58,606:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-12-18 15:48:58,606:INFO:executable: c:\Python3.10\python.exe
2022-12-18 15:48:58,606:INFO:   machine: Windows-10-10.0.19045-SP0
2022-12-18 15:48:58,606:INFO:PyCaret required dependencies:
2022-12-18 15:48:58,606:INFO:                 pip: 22.2.2
2022-12-18 15:48:58,606:INFO:          setuptools: 58.1.0
2022-12-18 15:48:58,606:INFO:             pycaret: 3.0.0rc4
2022-12-18 15:48:58,606:INFO:             IPython: 8.4.0
2022-12-18 15:48:58,607:INFO:          ipywidgets: 8.0.2
2022-12-18 15:48:58,607:INFO:                tqdm: 4.64.0
2022-12-18 15:48:58,607:INFO:               numpy: 1.22.1
2022-12-18 15:48:58,607:INFO:              pandas: 1.4.2
2022-12-18 15:48:58,607:INFO:              jinja2: 3.1.2
2022-12-18 15:48:58,607:INFO:               scipy: 1.8.1
2022-12-18 15:48:58,607:INFO:              joblib: 1.2.0
2022-12-18 15:48:58,608:INFO:             sklearn: 1.1.2
2022-12-18 15:48:58,608:INFO:                pyod: 1.0.6
2022-12-18 15:48:58,608:INFO:            imblearn: 0.9.1
2022-12-18 15:48:58,608:INFO:   category_encoders: 2.5.1.post0
2022-12-18 15:48:58,608:INFO:            lightgbm: 3.3.3
2022-12-18 15:48:58,608:INFO:               numba: 0.55.2
2022-12-18 15:48:58,608:INFO:            requests: 2.28.1
2022-12-18 15:48:58,608:INFO:          matplotlib: 3.5.1
2022-12-18 15:48:58,608:INFO:          scikitplot: 0.3.7
2022-12-18 15:48:58,609:INFO:         yellowbrick: 1.5
2022-12-18 15:48:58,609:INFO:              plotly: 5.11.0
2022-12-18 15:48:58,609:INFO:             kaleido: 0.2.1
2022-12-18 15:48:58,609:INFO:         statsmodels: 0.13.5
2022-12-18 15:48:58,609:INFO:              sktime: 0.13.4
2022-12-18 15:48:58,609:INFO:               tbats: 1.1.1
2022-12-18 15:48:58,610:INFO:            pmdarima: 1.8.5
2022-12-18 15:48:58,610:INFO:              psutil: 5.9.1
2022-12-18 15:48:58,610:INFO:PyCaret optional dependencies:
2022-12-18 15:48:58,610:INFO:                shap: Not installed
2022-12-18 15:48:58,610:INFO:           interpret: Not installed
2022-12-18 15:48:58,610:INFO:                umap: Not installed
2022-12-18 15:48:58,610:INFO:    pandas_profiling: Not installed
2022-12-18 15:48:58,611:INFO:  explainerdashboard: Not installed
2022-12-18 15:48:58,611:INFO:             autoviz: Not installed
2022-12-18 15:48:58,611:INFO:           fairlearn: Not installed
2022-12-18 15:48:58,611:INFO:             xgboost: Not installed
2022-12-18 15:48:58,613:INFO:            catboost: Not installed
2022-12-18 15:48:58,613:INFO:              kmodes: Not installed
2022-12-18 15:48:58,613:INFO:             mlxtend: Not installed
2022-12-18 15:48:58,614:INFO:       statsforecast: Not installed
2022-12-18 15:48:58,614:INFO:        tune_sklearn: Not installed
2022-12-18 15:48:58,615:INFO:                 ray: Not installed
2022-12-18 15:48:58,615:INFO:            hyperopt: Not installed
2022-12-18 15:48:58,615:INFO:              optuna: Not installed
2022-12-18 15:48:58,615:INFO:               skopt: Not installed
2022-12-18 15:48:58,615:INFO:              mlflow: Not installed
2022-12-18 15:48:58,615:INFO:              gradio: Not installed
2022-12-18 15:48:58,616:INFO:             fastapi: Not installed
2022-12-18 15:48:58,616:INFO:             uvicorn: Not installed
2022-12-18 15:48:58,616:INFO:              m2cgen: Not installed
2022-12-18 15:48:58,616:INFO:           evidently: Not installed
2022-12-18 15:48:58,617:INFO:                nltk: 3.7
2022-12-18 15:48:58,617:INFO:            pyLDAvis: Not installed
2022-12-18 15:48:58,617:INFO:              gensim: Not installed
2022-12-18 15:48:58,618:INFO:               spacy: 3.4.3
2022-12-18 15:48:58,618:INFO:           wordcloud: Not installed
2022-12-18 15:48:58,618:INFO:            textblob: Not installed
2022-12-18 15:48:58,618:INFO:               fugue: Not installed
2022-12-18 15:48:58,619:INFO:           streamlit: Not installed
2022-12-18 15:48:58,619:INFO:             prophet: Not installed
2022-12-18 15:48:58,619:INFO:None
2022-12-18 15:48:58,619:INFO:Set up data.
2022-12-18 15:48:58,632:INFO:Set up train/test split.
2022-12-18 15:48:58,640:INFO:Set up index.
2022-12-18 15:48:58,640:INFO:Set up folding strategy.
2022-12-18 15:48:58,643:INFO:Assigning column types.
2022-12-18 15:48:58,648:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-18 15:48:58,648:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,660:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:58,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:58,783:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,788:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,794:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:58,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:58,918:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-18 15:48:58,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:48:58,999:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,065:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,132:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,184:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-18 15:48:59,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,341:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,476:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-18 15:48:59,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,767:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-18 15:48:59,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:48:59,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:48:59,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-18 15:49:00,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,037:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-18 15:49:00,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,313:INFO:Preparing preprocessing pipeline...
2022-12-18 15:49:00,314:INFO:Set up simple imputation.
2022-12-18 15:49:00,314:INFO:Set up variance threshold.
2022-12-18 15:49:00,377:INFO:Finished creating preprocessing pipeline.
2022-12-18 15:49:00,385:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-18 15:49:00,385:INFO:Creating final display dataframe.
2022-12-18 15:49:00,674:INFO:Setup display_container:                Description             Value
0               Session id              2209
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              4bff
2022-12-18 15:49:00,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:49:00,987:INFO:setup() successfully completed in 2.39s...............
2022-12-18 15:49:01,170:INFO:Initializing compare_models()
2022-12-18 15:49:01,170:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-18 15:49:01,170:INFO:Checking exceptions
2022-12-18 15:49:01,174:INFO:Preparing display monitor
2022-12-18 15:49:01,263:INFO:Initializing Linear Regression
2022-12-18 15:49:01,263:INFO:Total runtime is 0.0 minutes
2022-12-18 15:49:01,270:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:01,271:INFO:Initializing create_model()
2022-12-18 15:49:01,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:01,271:INFO:Checking exceptions
2022-12-18 15:49:01,276:INFO:Importing libraries
2022-12-18 15:49:01,277:INFO:Copying training dataset
2022-12-18 15:49:01,282:INFO:Defining folds
2022-12-18 15:49:01,282:INFO:Declaring metric variables
2022-12-18 15:49:01,309:INFO:Importing untrained model
2022-12-18 15:49:01,316:INFO:Linear Regression Imported successfully
2022-12-18 15:49:01,329:INFO:Starting cross validation
2022-12-18 15:49:01,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:02,686:INFO:Calculating mean and std
2022-12-18 15:49:02,689:INFO:Creating metrics dataframe
2022-12-18 15:49:02,694:INFO:Uploading results into container
2022-12-18 15:49:02,695:INFO:Uploading model into container now
2022-12-18 15:49:02,695:INFO:master_model_container: 1
2022-12-18 15:49:02,695:INFO:display_container: 2
2022-12-18 15:49:02,696:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1,
                 normalize='deprecated', positive=False)
2022-12-18 15:49:02,696:INFO:create_model() successfully completed......................................
2022-12-18 15:49:02,848:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:02,848:INFO:Creating metrics dataframe
2022-12-18 15:49:02,860:INFO:Initializing Lasso Regression
2022-12-18 15:49:02,860:INFO:Total runtime is 0.026623221238454182 minutes
2022-12-18 15:49:02,865:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:02,865:INFO:Initializing create_model()
2022-12-18 15:49:02,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:02,865:INFO:Checking exceptions
2022-12-18 15:49:02,868:INFO:Importing libraries
2022-12-18 15:49:02,869:INFO:Copying training dataset
2022-12-18 15:49:02,875:INFO:Defining folds
2022-12-18 15:49:02,875:INFO:Declaring metric variables
2022-12-18 15:49:02,883:INFO:Importing untrained model
2022-12-18 15:49:02,889:INFO:Lasso Regression Imported successfully
2022-12-18 15:49:02,902:INFO:Starting cross validation
2022-12-18 15:49:02,904:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:03,243:INFO:Calculating mean and std
2022-12-18 15:49:03,245:INFO:Creating metrics dataframe
2022-12-18 15:49:03,248:INFO:Uploading results into container
2022-12-18 15:49:03,249:INFO:Uploading model into container now
2022-12-18 15:49:03,250:INFO:master_model_container: 2
2022-12-18 15:49:03,250:INFO:display_container: 2
2022-12-18 15:49:03,250:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize='deprecated', positive=False, precompute=False,
      random_state=2209, selection='cyclic', tol=0.0001, warm_start=False)
2022-12-18 15:49:03,251:INFO:create_model() successfully completed......................................
2022-12-18 15:49:03,368:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:03,368:INFO:Creating metrics dataframe
2022-12-18 15:49:03,379:INFO:Initializing Ridge Regression
2022-12-18 15:49:03,379:INFO:Total runtime is 0.035276333491007485 minutes
2022-12-18 15:49:03,383:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:03,384:INFO:Initializing create_model()
2022-12-18 15:49:03,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:03,384:INFO:Checking exceptions
2022-12-18 15:49:03,388:INFO:Importing libraries
2022-12-18 15:49:03,388:INFO:Copying training dataset
2022-12-18 15:49:03,391:INFO:Defining folds
2022-12-18 15:49:03,392:INFO:Declaring metric variables
2022-12-18 15:49:03,396:INFO:Importing untrained model
2022-12-18 15:49:03,414:INFO:Ridge Regression Imported successfully
2022-12-18 15:49:03,448:INFO:Starting cross validation
2022-12-18 15:49:03,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:03,739:INFO:Calculating mean and std
2022-12-18 15:49:03,741:INFO:Creating metrics dataframe
2022-12-18 15:49:03,747:INFO:Uploading results into container
2022-12-18 15:49:03,748:INFO:Uploading model into container now
2022-12-18 15:49:03,751:INFO:master_model_container: 3
2022-12-18 15:49:03,751:INFO:display_container: 2
2022-12-18 15:49:03,752:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize='deprecated', positive=False, random_state=2209, solver='auto',
      tol=0.001)
2022-12-18 15:49:03,752:INFO:create_model() successfully completed......................................
2022-12-18 15:49:03,929:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:03,929:INFO:Creating metrics dataframe
2022-12-18 15:49:03,948:INFO:Initializing Elastic Net
2022-12-18 15:49:03,948:INFO:Total runtime is 0.04475260575612386 minutes
2022-12-18 15:49:03,957:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:03,958:INFO:Initializing create_model()
2022-12-18 15:49:03,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:03,958:INFO:Checking exceptions
2022-12-18 15:49:03,961:INFO:Importing libraries
2022-12-18 15:49:03,962:INFO:Copying training dataset
2022-12-18 15:49:03,967:INFO:Defining folds
2022-12-18 15:49:03,967:INFO:Declaring metric variables
2022-12-18 15:49:03,978:INFO:Importing untrained model
2022-12-18 15:49:03,988:INFO:Elastic Net Imported successfully
2022-12-18 15:49:04,004:INFO:Starting cross validation
2022-12-18 15:49:04,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:04,298:INFO:Calculating mean and std
2022-12-18 15:49:04,299:INFO:Creating metrics dataframe
2022-12-18 15:49:04,306:INFO:Uploading results into container
2022-12-18 15:49:04,307:INFO:Uploading model into container now
2022-12-18 15:49:04,308:INFO:master_model_container: 4
2022-12-18 15:49:04,308:INFO:display_container: 2
2022-12-18 15:49:04,309:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize='deprecated', positive=False,
           precompute=False, random_state=2209, selection='cyclic', tol=0.0001,
           warm_start=False)
2022-12-18 15:49:04,309:INFO:create_model() successfully completed......................................
2022-12-18 15:49:04,455:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:04,455:INFO:Creating metrics dataframe
2022-12-18 15:49:04,466:INFO:Initializing Least Angle Regression
2022-12-18 15:49:04,467:INFO:Total runtime is 0.053401859601338704 minutes
2022-12-18 15:49:04,475:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:04,475:INFO:Initializing create_model()
2022-12-18 15:49:04,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:04,476:INFO:Checking exceptions
2022-12-18 15:49:04,478:INFO:Importing libraries
2022-12-18 15:49:04,479:INFO:Copying training dataset
2022-12-18 15:49:04,482:INFO:Defining folds
2022-12-18 15:49:04,482:INFO:Declaring metric variables
2022-12-18 15:49:04,490:INFO:Importing untrained model
2022-12-18 15:49:04,495:INFO:Least Angle Regression Imported successfully
2022-12-18 15:49:04,513:INFO:Starting cross validation
2022-12-18 15:49:04,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:04,575:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,589:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,598:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,608:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,644:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,668:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,675:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,680:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,744:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,761:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:04,789:INFO:Calculating mean and std
2022-12-18 15:49:04,791:INFO:Creating metrics dataframe
2022-12-18 15:49:04,796:INFO:Uploading results into container
2022-12-18 15:49:04,797:INFO:Uploading model into container now
2022-12-18 15:49:04,797:INFO:master_model_container: 5
2022-12-18 15:49:04,798:INFO:display_container: 2
2022-12-18 15:49:04,798:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=2209, verbose=False)
2022-12-18 15:49:04,798:INFO:create_model() successfully completed......................................
2022-12-18 15:49:04,927:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:04,927:INFO:Creating metrics dataframe
2022-12-18 15:49:04,941:INFO:Initializing Lasso Least Angle Regression
2022-12-18 15:49:04,941:INFO:Total runtime is 0.06130390564600627 minutes
2022-12-18 15:49:04,946:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:04,947:INFO:Initializing create_model()
2022-12-18 15:49:04,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:04,947:INFO:Checking exceptions
2022-12-18 15:49:04,949:INFO:Importing libraries
2022-12-18 15:49:04,950:INFO:Copying training dataset
2022-12-18 15:49:04,955:INFO:Defining folds
2022-12-18 15:49:04,955:INFO:Declaring metric variables
2022-12-18 15:49:04,959:INFO:Importing untrained model
2022-12-18 15:49:04,966:INFO:Lasso Least Angle Regression Imported successfully
2022-12-18 15:49:04,978:INFO:Starting cross validation
2022-12-18 15:49:04,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:05,038:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,049:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,057:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,067:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,101:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,129:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,165:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,178:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,191:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,200:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-18 15:49:05,225:INFO:Calculating mean and std
2022-12-18 15:49:05,227:INFO:Creating metrics dataframe
2022-12-18 15:49:05,231:INFO:Uploading results into container
2022-12-18 15:49:05,232:INFO:Uploading model into container now
2022-12-18 15:49:05,232:INFO:master_model_container: 6
2022-12-18 15:49:05,232:INFO:display_container: 2
2022-12-18 15:49:05,233:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=2209, verbose=False)
2022-12-18 15:49:05,233:INFO:create_model() successfully completed......................................
2022-12-18 15:49:05,346:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:05,347:INFO:Creating metrics dataframe
2022-12-18 15:49:05,362:INFO:Initializing Orthogonal Matching Pursuit
2022-12-18 15:49:05,363:INFO:Total runtime is 0.06831185817718506 minutes
2022-12-18 15:49:05,367:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:05,367:INFO:Initializing create_model()
2022-12-18 15:49:05,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:05,367:INFO:Checking exceptions
2022-12-18 15:49:05,372:INFO:Importing libraries
2022-12-18 15:49:05,372:INFO:Copying training dataset
2022-12-18 15:49:05,375:INFO:Defining folds
2022-12-18 15:49:05,376:INFO:Declaring metric variables
2022-12-18 15:49:05,380:INFO:Importing untrained model
2022-12-18 15:49:05,387:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-18 15:49:05,400:INFO:Starting cross validation
2022-12-18 15:49:05,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:05,460:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,470:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,476:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,485:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,539:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,556:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,565:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,593:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,598:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-18 15:49:05,614:INFO:Calculating mean and std
2022-12-18 15:49:05,616:INFO:Creating metrics dataframe
2022-12-18 15:49:05,623:INFO:Uploading results into container
2022-12-18 15:49:05,624:INFO:Uploading model into container now
2022-12-18 15:49:05,624:INFO:master_model_container: 7
2022-12-18 15:49:05,625:INFO:display_container: 2
2022-12-18 15:49:05,625:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2022-12-18 15:49:05,625:INFO:create_model() successfully completed......................................
2022-12-18 15:49:05,741:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:05,742:INFO:Creating metrics dataframe
2022-12-18 15:49:05,753:INFO:Initializing Bayesian Ridge
2022-12-18 15:49:05,753:INFO:Total runtime is 0.07483978271484375 minutes
2022-12-18 15:49:05,758:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:05,759:INFO:Initializing create_model()
2022-12-18 15:49:05,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:05,759:INFO:Checking exceptions
2022-12-18 15:49:05,762:INFO:Importing libraries
2022-12-18 15:49:05,762:INFO:Copying training dataset
2022-12-18 15:49:05,766:INFO:Defining folds
2022-12-18 15:49:05,766:INFO:Declaring metric variables
2022-12-18 15:49:05,772:INFO:Importing untrained model
2022-12-18 15:49:05,778:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:49:05,794:INFO:Starting cross validation
2022-12-18 15:49:05,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:06,024:INFO:Calculating mean and std
2022-12-18 15:49:06,026:INFO:Creating metrics dataframe
2022-12-18 15:49:06,030:INFO:Uploading results into container
2022-12-18 15:49:06,030:INFO:Uploading model into container now
2022-12-18 15:49:06,031:INFO:master_model_container: 8
2022-12-18 15:49:06,031:INFO:display_container: 2
2022-12-18 15:49:06,032:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2022-12-18 15:49:06,032:INFO:create_model() successfully completed......................................
2022-12-18 15:49:06,150:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:06,150:INFO:Creating metrics dataframe
2022-12-18 15:49:06,162:INFO:Initializing Passive Aggressive Regressor
2022-12-18 15:49:06,162:INFO:Total runtime is 0.08165863355000813 minutes
2022-12-18 15:49:06,162:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:06,169:INFO:Initializing create_model()
2022-12-18 15:49:06,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:06,169:INFO:Checking exceptions
2022-12-18 15:49:06,171:INFO:Importing libraries
2022-12-18 15:49:06,171:INFO:Copying training dataset
2022-12-18 15:49:06,177:INFO:Defining folds
2022-12-18 15:49:06,177:INFO:Declaring metric variables
2022-12-18 15:49:06,186:INFO:Importing untrained model
2022-12-18 15:49:06,193:INFO:Passive Aggressive Regressor Imported successfully
2022-12-18 15:49:06,207:INFO:Starting cross validation
2022-12-18 15:49:06,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:06,422:INFO:Calculating mean and std
2022-12-18 15:49:06,423:INFO:Creating metrics dataframe
2022-12-18 15:49:06,427:INFO:Uploading results into container
2022-12-18 15:49:06,427:INFO:Uploading model into container now
2022-12-18 15:49:06,428:INFO:master_model_container: 9
2022-12-18 15:49:06,428:INFO:display_container: 2
2022-12-18 15:49:06,430:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=2209, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-18 15:49:06,430:INFO:create_model() successfully completed......................................
2022-12-18 15:49:06,547:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:06,547:INFO:Creating metrics dataframe
2022-12-18 15:49:06,560:INFO:Initializing Huber Regressor
2022-12-18 15:49:06,560:INFO:Total runtime is 0.08828995625178018 minutes
2022-12-18 15:49:06,565:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:06,565:INFO:Initializing create_model()
2022-12-18 15:49:06,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:06,566:INFO:Checking exceptions
2022-12-18 15:49:06,569:INFO:Importing libraries
2022-12-18 15:49:06,570:INFO:Copying training dataset
2022-12-18 15:49:06,573:INFO:Defining folds
2022-12-18 15:49:06,573:INFO:Declaring metric variables
2022-12-18 15:49:06,578:INFO:Importing untrained model
2022-12-18 15:49:06,585:INFO:Huber Regressor Imported successfully
2022-12-18 15:49:06,600:INFO:Starting cross validation
2022-12-18 15:49:06,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:06,726:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,726:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,781:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,808:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,970:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,975:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,996:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:06,996:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:07,053:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:07,059:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:07,072:INFO:Calculating mean and std
2022-12-18 15:49:07,074:INFO:Creating metrics dataframe
2022-12-18 15:49:07,077:INFO:Uploading results into container
2022-12-18 15:49:07,078:INFO:Uploading model into container now
2022-12-18 15:49:07,078:INFO:master_model_container: 10
2022-12-18 15:49:07,079:INFO:display_container: 2
2022-12-18 15:49:07,079:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-12-18 15:49:07,080:INFO:create_model() successfully completed......................................
2022-12-18 15:49:07,195:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:07,195:INFO:Creating metrics dataframe
2022-12-18 15:49:07,209:INFO:Initializing K Neighbors Regressor
2022-12-18 15:49:07,209:INFO:Total runtime is 0.09909466505050658 minutes
2022-12-18 15:49:07,215:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:07,216:INFO:Initializing create_model()
2022-12-18 15:49:07,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:07,216:INFO:Checking exceptions
2022-12-18 15:49:07,219:INFO:Importing libraries
2022-12-18 15:49:07,219:INFO:Copying training dataset
2022-12-18 15:49:07,223:INFO:Defining folds
2022-12-18 15:49:07,223:INFO:Declaring metric variables
2022-12-18 15:49:07,231:INFO:Importing untrained model
2022-12-18 15:49:07,238:INFO:K Neighbors Regressor Imported successfully
2022-12-18 15:49:07,254:INFO:Starting cross validation
2022-12-18 15:49:07,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:07,548:INFO:Calculating mean and std
2022-12-18 15:49:07,553:INFO:Creating metrics dataframe
2022-12-18 15:49:07,559:INFO:Uploading results into container
2022-12-18 15:49:07,560:INFO:Uploading model into container now
2022-12-18 15:49:07,561:INFO:master_model_container: 11
2022-12-18 15:49:07,561:INFO:display_container: 2
2022-12-18 15:49:07,562:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2022-12-18 15:49:07,562:INFO:create_model() successfully completed......................................
2022-12-18 15:49:07,708:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:07,708:INFO:Creating metrics dataframe
2022-12-18 15:49:07,722:INFO:Initializing Decision Tree Regressor
2022-12-18 15:49:07,722:INFO:Total runtime is 0.10765695174535114 minutes
2022-12-18 15:49:07,727:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:07,728:INFO:Initializing create_model()
2022-12-18 15:49:07,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:07,728:INFO:Checking exceptions
2022-12-18 15:49:07,730:INFO:Importing libraries
2022-12-18 15:49:07,730:INFO:Copying training dataset
2022-12-18 15:49:07,736:INFO:Defining folds
2022-12-18 15:49:07,736:INFO:Declaring metric variables
2022-12-18 15:49:07,740:INFO:Importing untrained model
2022-12-18 15:49:07,747:INFO:Decision Tree Regressor Imported successfully
2022-12-18 15:49:07,758:INFO:Starting cross validation
2022-12-18 15:49:07,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:07,978:INFO:Calculating mean and std
2022-12-18 15:49:07,980:INFO:Creating metrics dataframe
2022-12-18 15:49:07,987:INFO:Uploading results into container
2022-12-18 15:49:07,988:INFO:Uploading model into container now
2022-12-18 15:49:07,989:INFO:master_model_container: 12
2022-12-18 15:49:07,989:INFO:display_container: 2
2022-12-18 15:49:07,989:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=2209, splitter='best')
2022-12-18 15:49:07,989:INFO:create_model() successfully completed......................................
2022-12-18 15:49:08,104:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:08,104:INFO:Creating metrics dataframe
2022-12-18 15:49:08,120:INFO:Initializing Random Forest Regressor
2022-12-18 15:49:08,120:INFO:Total runtime is 0.11427863041559853 minutes
2022-12-18 15:49:08,125:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:08,126:INFO:Initializing create_model()
2022-12-18 15:49:08,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:08,126:INFO:Checking exceptions
2022-12-18 15:49:08,129:INFO:Importing libraries
2022-12-18 15:49:08,129:INFO:Copying training dataset
2022-12-18 15:49:08,134:INFO:Defining folds
2022-12-18 15:49:08,134:INFO:Declaring metric variables
2022-12-18 15:49:08,140:INFO:Importing untrained model
2022-12-18 15:49:08,148:INFO:Random Forest Regressor Imported successfully
2022-12-18 15:49:08,160:INFO:Starting cross validation
2022-12-18 15:49:08,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:09,443:INFO:Calculating mean and std
2022-12-18 15:49:09,445:INFO:Creating metrics dataframe
2022-12-18 15:49:09,449:INFO:Uploading results into container
2022-12-18 15:49:09,450:INFO:Uploading model into container now
2022-12-18 15:49:09,450:INFO:master_model_container: 13
2022-12-18 15:49:09,450:INFO:display_container: 2
2022-12-18 15:49:09,451:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=2209, verbose=0,
                      warm_start=False)
2022-12-18 15:49:09,452:INFO:create_model() successfully completed......................................
2022-12-18 15:49:09,567:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:09,567:INFO:Creating metrics dataframe
2022-12-18 15:49:09,584:INFO:Initializing Extra Trees Regressor
2022-12-18 15:49:09,584:INFO:Total runtime is 0.1386808673540751 minutes
2022-12-18 15:49:09,590:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:09,590:INFO:Initializing create_model()
2022-12-18 15:49:09,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:09,590:INFO:Checking exceptions
2022-12-18 15:49:09,592:INFO:Importing libraries
2022-12-18 15:49:09,592:INFO:Copying training dataset
2022-12-18 15:49:09,596:INFO:Defining folds
2022-12-18 15:49:09,596:INFO:Declaring metric variables
2022-12-18 15:49:09,602:INFO:Importing untrained model
2022-12-18 15:49:09,608:INFO:Extra Trees Regressor Imported successfully
2022-12-18 15:49:09,634:INFO:Starting cross validation
2022-12-18 15:49:09,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:10,888:INFO:Calculating mean and std
2022-12-18 15:49:10,888:INFO:Creating metrics dataframe
2022-12-18 15:49:10,897:INFO:Uploading results into container
2022-12-18 15:49:10,899:INFO:Uploading model into container now
2022-12-18 15:49:10,900:INFO:master_model_container: 14
2022-12-18 15:49:10,900:INFO:display_container: 2
2022-12-18 15:49:10,901:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=2209, verbose=0,
                    warm_start=False)
2022-12-18 15:49:10,901:INFO:create_model() successfully completed......................................
2022-12-18 15:49:11,028:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:11,028:INFO:Creating metrics dataframe
2022-12-18 15:49:11,047:INFO:Initializing AdaBoost Regressor
2022-12-18 15:49:11,047:INFO:Total runtime is 0.1630622585614522 minutes
2022-12-18 15:49:11,052:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:11,053:INFO:Initializing create_model()
2022-12-18 15:49:11,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:11,053:INFO:Checking exceptions
2022-12-18 15:49:11,056:INFO:Importing libraries
2022-12-18 15:49:11,056:INFO:Copying training dataset
2022-12-18 15:49:11,059:INFO:Defining folds
2022-12-18 15:49:11,059:INFO:Declaring metric variables
2022-12-18 15:49:11,064:INFO:Importing untrained model
2022-12-18 15:49:11,070:INFO:AdaBoost Regressor Imported successfully
2022-12-18 15:49:11,081:INFO:Starting cross validation
2022-12-18 15:49:11,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:11,568:INFO:Calculating mean and std
2022-12-18 15:49:11,570:INFO:Creating metrics dataframe
2022-12-18 15:49:11,574:INFO:Uploading results into container
2022-12-18 15:49:11,575:INFO:Uploading model into container now
2022-12-18 15:49:11,575:INFO:master_model_container: 15
2022-12-18 15:49:11,575:INFO:display_container: 2
2022-12-18 15:49:11,576:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=2209)
2022-12-18 15:49:11,576:INFO:create_model() successfully completed......................................
2022-12-18 15:49:11,693:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:11,693:INFO:Creating metrics dataframe
2022-12-18 15:49:11,708:INFO:Initializing Gradient Boosting Regressor
2022-12-18 15:49:11,708:INFO:Total runtime is 0.1740819732348124 minutes
2022-12-18 15:49:11,713:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:11,714:INFO:Initializing create_model()
2022-12-18 15:49:11,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:11,714:INFO:Checking exceptions
2022-12-18 15:49:11,717:INFO:Importing libraries
2022-12-18 15:49:11,718:INFO:Copying training dataset
2022-12-18 15:49:11,722:INFO:Defining folds
2022-12-18 15:49:11,723:INFO:Declaring metric variables
2022-12-18 15:49:11,730:INFO:Importing untrained model
2022-12-18 15:49:11,737:INFO:Gradient Boosting Regressor Imported successfully
2022-12-18 15:49:11,750:INFO:Starting cross validation
2022-12-18 15:49:11,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:12,336:INFO:Calculating mean and std
2022-12-18 15:49:12,338:INFO:Creating metrics dataframe
2022-12-18 15:49:12,342:INFO:Uploading results into container
2022-12-18 15:49:12,342:INFO:Uploading model into container now
2022-12-18 15:49:12,343:INFO:master_model_container: 16
2022-12-18 15:49:12,343:INFO:display_container: 2
2022-12-18 15:49:12,343:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=2209, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-18 15:49:12,343:INFO:create_model() successfully completed......................................
2022-12-18 15:49:12,459:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:12,460:INFO:Creating metrics dataframe
2022-12-18 15:49:12,476:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:49:12,476:INFO:Total runtime is 0.18689117431640623 minutes
2022-12-18 15:49:12,482:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:12,483:INFO:Initializing create_model()
2022-12-18 15:49:12,483:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:12,483:INFO:Checking exceptions
2022-12-18 15:49:12,486:INFO:Importing libraries
2022-12-18 15:49:12,486:INFO:Copying training dataset
2022-12-18 15:49:12,489:INFO:Defining folds
2022-12-18 15:49:12,490:INFO:Declaring metric variables
2022-12-18 15:49:12,494:INFO:Importing untrained model
2022-12-18 15:49:12,501:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:49:12,515:INFO:Starting cross validation
2022-12-18 15:49:12,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:12,833:INFO:Calculating mean and std
2022-12-18 15:49:12,835:INFO:Creating metrics dataframe
2022-12-18 15:49:12,839:INFO:Uploading results into container
2022-12-18 15:49:12,839:INFO:Uploading model into container now
2022-12-18 15:49:12,840:INFO:master_model_container: 17
2022-12-18 15:49:12,840:INFO:display_container: 2
2022-12-18 15:49:12,842:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=2209, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-18 15:49:12,842:INFO:create_model() successfully completed......................................
2022-12-18 15:49:12,956:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:12,956:INFO:Creating metrics dataframe
2022-12-18 15:49:12,970:INFO:Initializing Dummy Regressor
2022-12-18 15:49:12,970:INFO:Total runtime is 0.19512345790863034 minutes
2022-12-18 15:49:12,974:INFO:SubProcess create_model() called ==================================
2022-12-18 15:49:12,975:INFO:Initializing create_model()
2022-12-18 15:49:12,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C442D5CD00>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:12,975:INFO:Checking exceptions
2022-12-18 15:49:12,980:INFO:Importing libraries
2022-12-18 15:49:12,991:INFO:Copying training dataset
2022-12-18 15:49:13,012:INFO:Defining folds
2022-12-18 15:49:13,012:INFO:Declaring metric variables
2022-12-18 15:49:13,018:INFO:Importing untrained model
2022-12-18 15:49:13,043:INFO:Dummy Regressor Imported successfully
2022-12-18 15:49:13,059:INFO:Starting cross validation
2022-12-18 15:49:13,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:13,329:INFO:Calculating mean and std
2022-12-18 15:49:13,331:INFO:Creating metrics dataframe
2022-12-18 15:49:13,335:INFO:Uploading results into container
2022-12-18 15:49:13,335:INFO:Uploading model into container now
2022-12-18 15:49:13,336:INFO:master_model_container: 18
2022-12-18 15:49:13,336:INFO:display_container: 2
2022-12-18 15:49:13,336:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-12-18 15:49:13,336:INFO:create_model() successfully completed......................................
2022-12-18 15:49:13,470:INFO:SubProcess create_model() end ==================================
2022-12-18 15:49:13,471:INFO:Creating metrics dataframe
2022-12-18 15:49:13,504:INFO:Initializing create_model()
2022-12-18 15:49:13,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:13,505:INFO:Checking exceptions
2022-12-18 15:49:13,511:INFO:Importing libraries
2022-12-18 15:49:13,511:INFO:Copying training dataset
2022-12-18 15:49:13,515:INFO:Defining folds
2022-12-18 15:49:13,515:INFO:Declaring metric variables
2022-12-18 15:49:13,516:INFO:Importing untrained model
2022-12-18 15:49:13,516:INFO:Declaring custom model
2022-12-18 15:49:13,516:INFO:Huber Regressor Imported successfully
2022-12-18 15:49:13,518:INFO:Cross validation set to False
2022-12-18 15:49:13,518:INFO:Fitting Model
2022-12-18 15:49:13,642:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:13,642:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-12-18 15:49:13,642:INFO:create_model() successfully completed......................................
2022-12-18 15:49:13,796:INFO:Initializing create_model()
2022-12-18 15:49:13,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:13,797:INFO:Checking exceptions
2022-12-18 15:49:13,802:INFO:Importing libraries
2022-12-18 15:49:13,802:INFO:Copying training dataset
2022-12-18 15:49:13,805:INFO:Defining folds
2022-12-18 15:49:13,805:INFO:Declaring metric variables
2022-12-18 15:49:13,806:INFO:Importing untrained model
2022-12-18 15:49:13,806:INFO:Declaring custom model
2022-12-18 15:49:13,806:INFO:Bayesian Ridge Imported successfully
2022-12-18 15:49:13,807:INFO:Cross validation set to False
2022-12-18 15:49:13,807:INFO:Fitting Model
2022-12-18 15:49:13,835:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2022-12-18 15:49:13,835:INFO:create_model() successfully completed......................................
2022-12-18 15:49:13,959:INFO:Initializing create_model()
2022-12-18 15:49:13,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=DummyRegressor(constant=None, quantile=None, strategy='mean'), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:13,960:INFO:Checking exceptions
2022-12-18 15:49:13,966:INFO:Importing libraries
2022-12-18 15:49:13,966:INFO:Copying training dataset
2022-12-18 15:49:13,969:INFO:Defining folds
2022-12-18 15:49:13,969:INFO:Declaring metric variables
2022-12-18 15:49:13,969:INFO:Importing untrained model
2022-12-18 15:49:13,970:INFO:Declaring custom model
2022-12-18 15:49:13,971:INFO:Dummy Regressor Imported successfully
2022-12-18 15:49:13,973:INFO:Cross validation set to False
2022-12-18 15:49:13,973:INFO:Fitting Model
2022-12-18 15:49:13,992:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2022-12-18 15:49:13,993:INFO:create_model() successfully completed......................................
2022-12-18 15:49:14,178:INFO:master_model_container: 18
2022-12-18 15:49:14,179:INFO:display_container: 2
2022-12-18 15:49:14,180:INFO:[HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False), DummyRegressor(constant=None, quantile=None, strategy='mean')]
2022-12-18 15:49:14,180:INFO:compare_models() successfully completed......................................
2022-12-18 15:49:41,766:INFO:Initializing create_model()
2022-12-18 15:49:41,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:49:41,767:INFO:Checking exceptions
2022-12-18 15:49:41,819:INFO:Importing libraries
2022-12-18 15:49:41,819:INFO:Copying training dataset
2022-12-18 15:49:41,826:INFO:Defining folds
2022-12-18 15:49:41,826:INFO:Declaring metric variables
2022-12-18 15:49:41,833:INFO:Importing untrained model
2022-12-18 15:49:41,839:INFO:Huber Regressor Imported successfully
2022-12-18 15:49:41,854:INFO:Starting cross validation
2022-12-18 15:49:41,856:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:49:42,342:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,343:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,368:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,404:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,813:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,827:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,854:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:42,866:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,247:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,307:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,313:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,378:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,713:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,733:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,748:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:43,778:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:44,117:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:44,123:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:44,153:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:44,188:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:44,352:INFO:Calculating mean and std
2022-12-18 15:49:44,355:INFO:Creating metrics dataframe
2022-12-18 15:49:44,361:INFO:Finalizing model
2022-12-18 15:49:44,420:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:49:44,428:INFO:Uploading results into container
2022-12-18 15:49:44,430:INFO:Uploading model into container now
2022-12-18 15:49:44,458:INFO:master_model_container: 19
2022-12-18 15:49:44,458:INFO:display_container: 3
2022-12-18 15:49:44,459:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2022-12-18 15:49:44,460:INFO:create_model() successfully completed......................................
2022-12-18 15:50:00,003:INFO:Initializing plot_model()
2022-12-18 15:50:00,003:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, system=True)
2022-12-18 15:50:00,004:INFO:Checking exceptions
2022-12-18 15:50:00,010:INFO:Preloading libraries
2022-12-18 15:50:00,011:INFO:Copying training dataset
2022-12-18 15:50:00,012:INFO:Plot type: residuals
2022-12-18 15:50:00,208:INFO:Fitting Model
2022-12-18 15:50:00,209:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-12-18 15:50:00,257:INFO:Scoring test/hold-out set
2022-12-18 15:50:00,741:INFO:Visual Rendered Successfully
2022-12-18 15:50:00,900:INFO:plot_model() successfully completed......................................
2022-12-18 15:50:06,923:INFO:Initializing plot_model()
2022-12-18 15:50:06,924:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, system=True)
2022-12-18 15:50:06,924:INFO:Checking exceptions
2022-12-18 15:50:06,931:INFO:Preloading libraries
2022-12-18 15:50:06,932:INFO:Copying training dataset
2022-12-18 15:50:06,932:INFO:Plot type: vc
2022-12-18 15:50:06,933:INFO:Determining param_name
2022-12-18 15:50:06,933:INFO:param_name: alpha
2022-12-18 15:50:07,040:INFO:Fitting Model
2022-12-18 15:50:07,170:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,170:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,238:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,239:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,284:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,319:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,366:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,377:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,405:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,425:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,482:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,515:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,537:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,548:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,589:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,620:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,628:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,631:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,684:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,714:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,716:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,727:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,749:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,779:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,810:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,814:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,834:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,856:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,873:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,884:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,901:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,921:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,936:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,964:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,976:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,983:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:07,995:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,027:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,036:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,047:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,054:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,142:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,150:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,153:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,212:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,292:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,297:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,317:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,321:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,357:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,375:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,380:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,387:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,430:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,438:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,439:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,491:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,499:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,503:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,504:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,552:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,565:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,566:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,567:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,617:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,625:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,627:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,629:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,675:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,681:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,687:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,693:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,737:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,745:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,753:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,760:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,792:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,808:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,814:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,823:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,853:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,869:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,883:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,892:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,913:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,935:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,960:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,983:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:08,996:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,000:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,038:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,056:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,076:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,111:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,112:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,115:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-18 15:50:09,340:INFO:Visual Rendered Successfully
2022-12-18 15:50:09,484:INFO:plot_model() successfully completed......................................
2022-12-18 15:50:15,665:INFO:Initializing plot_model()
2022-12-18 15:50:15,665:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4451BFB20>, system=True)
2022-12-18 15:50:15,666:INFO:Checking exceptions
2022-12-18 15:50:15,673:INFO:Preloading libraries
2022-12-18 15:50:15,674:INFO:Copying training dataset
2022-12-18 15:50:15,674:INFO:Plot type: error
2022-12-18 15:50:15,763:INFO:Fitting Model
2022-12-18 15:50:15,763:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-12-18 15:50:15,763:INFO:Scoring test/hold-out set
2022-12-18 15:50:16,030:INFO:Visual Rendered Successfully
2022-12-18 15:50:16,191:INFO:plot_model() successfully completed......................................
2022-12-18 15:50:37,445:INFO:PyCaret ClassificationExperiment
2022-12-18 15:50:37,446:INFO:Logging name: clf-default-name
2022-12-18 15:50:37,446:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-18 15:50:37,447:INFO:version 3.0.0.rc4
2022-12-18 15:50:37,447:INFO:Initializing setup()
2022-12-18 15:50:37,447:INFO:self.USI: 359e
2022-12-18 15:50:37,447:INFO:self.variable_keys: {'exp_name_log', 'y', 'X', '_available_plots', 'seed', '_gpu_n_jobs_param', 'idx', 'n_jobs_param', 'variable_keys', 'html_param', 'fold_shuffle_param', 'fold_groups_param', '_all_metrics', 'memory', 'pipeline', 'data', 'logging_param', 'X_test', 'fix_imbalance', 'y_test', 'USI', '_is_multiclass', 'log_plots_param', 'gpu_param', 'X_train', '_all_models_internal', 'exp_id', 'target_param', '_ml_usecase', 'y_train', 'master_model_container', '_all_models', 'display_container', 'fold_generator'}
2022-12-18 15:50:37,447:INFO:Checking environment
2022-12-18 15:50:37,447:INFO:python_version: 3.10.4
2022-12-18 15:50:37,448:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-12-18 15:50:37,448:INFO:machine: AMD64
2022-12-18 15:50:37,448:INFO:platform: Windows-10-10.0.19045-SP0
2022-12-18 15:50:37,448:INFO:Memory: svmem(total=8503136256, available=1689059328, percent=80.1, used=6814076928, free=1689059328)
2022-12-18 15:50:37,448:INFO:Physical Core: 2
2022-12-18 15:50:37,448:INFO:Logical Core: 4
2022-12-18 15:50:37,448:INFO:Checking libraries
2022-12-18 15:50:37,449:INFO:System:
2022-12-18 15:50:37,449:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-12-18 15:50:37,449:INFO:executable: c:\Python3.10\python.exe
2022-12-18 15:50:37,449:INFO:   machine: Windows-10-10.0.19045-SP0
2022-12-18 15:50:37,449:INFO:PyCaret required dependencies:
2022-12-18 15:50:37,450:INFO:                 pip: 22.2.2
2022-12-18 15:50:37,450:INFO:          setuptools: 58.1.0
2022-12-18 15:50:37,450:INFO:             pycaret: 3.0.0rc4
2022-12-18 15:50:37,450:INFO:             IPython: 8.4.0
2022-12-18 15:50:37,450:INFO:          ipywidgets: 8.0.2
2022-12-18 15:50:37,450:INFO:                tqdm: 4.64.0
2022-12-18 15:50:37,450:INFO:               numpy: 1.22.1
2022-12-18 15:50:37,450:INFO:              pandas: 1.4.2
2022-12-18 15:50:37,451:INFO:              jinja2: 3.1.2
2022-12-18 15:50:37,451:INFO:               scipy: 1.8.1
2022-12-18 15:50:37,451:INFO:              joblib: 1.2.0
2022-12-18 15:50:37,451:INFO:             sklearn: 1.1.2
2022-12-18 15:50:37,451:INFO:                pyod: 1.0.6
2022-12-18 15:50:37,451:INFO:            imblearn: 0.9.1
2022-12-18 15:50:37,451:INFO:   category_encoders: 2.5.1.post0
2022-12-18 15:50:37,451:INFO:            lightgbm: 3.3.3
2022-12-18 15:50:37,452:INFO:               numba: 0.55.2
2022-12-18 15:50:37,452:INFO:            requests: 2.28.1
2022-12-18 15:50:37,452:INFO:          matplotlib: 3.5.1
2022-12-18 15:50:37,452:INFO:          scikitplot: 0.3.7
2022-12-18 15:50:37,452:INFO:         yellowbrick: 1.5
2022-12-18 15:50:37,452:INFO:              plotly: 5.11.0
2022-12-18 15:50:37,452:INFO:             kaleido: 0.2.1
2022-12-18 15:50:37,452:INFO:         statsmodels: 0.13.5
2022-12-18 15:50:37,453:INFO:              sktime: 0.13.4
2022-12-18 15:50:37,453:INFO:               tbats: 1.1.1
2022-12-18 15:50:37,453:INFO:            pmdarima: 1.8.5
2022-12-18 15:50:37,453:INFO:              psutil: 5.9.1
2022-12-18 15:50:37,454:INFO:PyCaret optional dependencies:
2022-12-18 15:50:37,454:INFO:                shap: Not installed
2022-12-18 15:50:37,454:INFO:           interpret: Not installed
2022-12-18 15:50:37,454:INFO:                umap: Not installed
2022-12-18 15:50:37,454:INFO:    pandas_profiling: Not installed
2022-12-18 15:50:37,454:INFO:  explainerdashboard: Not installed
2022-12-18 15:50:37,455:INFO:             autoviz: Not installed
2022-12-18 15:50:37,455:INFO:           fairlearn: Not installed
2022-12-18 15:50:37,456:INFO:             xgboost: Not installed
2022-12-18 15:50:37,456:INFO:            catboost: Not installed
2022-12-18 15:50:37,456:INFO:              kmodes: Not installed
2022-12-18 15:50:37,457:INFO:             mlxtend: Not installed
2022-12-18 15:50:37,457:INFO:       statsforecast: Not installed
2022-12-18 15:50:37,457:INFO:        tune_sklearn: Not installed
2022-12-18 15:50:37,457:INFO:                 ray: Not installed
2022-12-18 15:50:37,458:INFO:            hyperopt: Not installed
2022-12-18 15:50:37,458:INFO:              optuna: Not installed
2022-12-18 15:50:37,458:INFO:               skopt: Not installed
2022-12-18 15:50:37,458:INFO:              mlflow: Not installed
2022-12-18 15:50:37,458:INFO:              gradio: Not installed
2022-12-18 15:50:37,458:INFO:             fastapi: Not installed
2022-12-18 15:50:37,458:INFO:             uvicorn: Not installed
2022-12-18 15:50:37,458:INFO:              m2cgen: Not installed
2022-12-18 15:50:37,459:INFO:           evidently: Not installed
2022-12-18 15:50:37,459:INFO:                nltk: 3.7
2022-12-18 15:50:37,459:INFO:            pyLDAvis: Not installed
2022-12-18 15:50:37,459:INFO:              gensim: Not installed
2022-12-18 15:50:37,459:INFO:               spacy: 3.4.3
2022-12-18 15:50:37,459:INFO:           wordcloud: Not installed
2022-12-18 15:50:37,460:INFO:            textblob: Not installed
2022-12-18 15:50:37,460:INFO:               fugue: Not installed
2022-12-18 15:50:37,460:INFO:           streamlit: Not installed
2022-12-18 15:50:37,460:INFO:             prophet: Not installed
2022-12-18 15:50:37,460:INFO:None
2022-12-18 15:50:37,460:INFO:Set up data.
2022-12-18 15:50:37,476:INFO:Set up train/test split.
2022-12-18 15:50:37,489:INFO:Set up index.
2022-12-18 15:50:37,490:INFO:Assigning column types.
2022-12-18 15:50:37,500:INFO:Set up folding strategy.
2022-12-18 15:50:37,501:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-18 15:50:37,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:50:37,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:50:37,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-18 15:50:37,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:50:37,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,804:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-18 15:50:37,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:50:37,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-18 15:50:37,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:37,990:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-12-18 15:50:38,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:38,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:38,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:38,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:38,188:INFO:Preparing preprocessing pipeline...
2022-12-18 15:50:38,189:INFO:Set up simple imputation.
2022-12-18 15:50:38,190:INFO:Set up variance threshold.
2022-12-18 15:50:38,255:INFO:Finished creating preprocessing pipeline.
2022-12-18 15:50:38,260:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-18 15:50:38,260:INFO:Creating final display dataframe.
2022-12-18 15:50:38,830:INFO:Setup display_container:                     Description             Value
0                    Session id              6515
1                        Target              area
2                   Target type            Binary
3           Original data shape          (517, 9)
4        Transformed data shape          (517, 9)
5   Transformed train set shape          (361, 9)
6    Transformed test set shape          (156, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation          constant
12       Low variance threshold                 0
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              359e
2022-12-18 15:50:38,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:38,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:39,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:39,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-18 15:50:39,049:INFO:setup() successfully completed in 1.61s...............
2022-12-18 15:50:52,395:INFO:Initializing compare_models()
2022-12-18 15:50:52,396:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-12-18 15:50:52,397:INFO:Checking exceptions
2022-12-18 15:50:52,405:INFO:Preparing display monitor
2022-12-18 15:50:52,482:INFO:Initializing Logistic Regression
2022-12-18 15:50:52,482:INFO:Total runtime is 0.0 minutes
2022-12-18 15:50:52,490:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:52,490:INFO:Initializing create_model()
2022-12-18 15:50:52,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:52,492:INFO:Checking exceptions
2022-12-18 15:50:52,498:INFO:Importing libraries
2022-12-18 15:50:52,498:INFO:Copying training dataset
2022-12-18 15:50:52,504:INFO:Defining folds
2022-12-18 15:50:52,504:INFO:Declaring metric variables
2022-12-18 15:50:52,512:INFO:Importing untrained model
2022-12-18 15:50:52,524:INFO:Logistic Regression Imported successfully
2022-12-18 15:50:52,542:INFO:Starting cross validation
2022-12-18 15:50:52,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:54,389:INFO:Calculating mean and std
2022-12-18 15:50:54,391:INFO:Creating metrics dataframe
2022-12-18 15:50:54,397:INFO:Uploading results into container
2022-12-18 15:50:54,398:INFO:Uploading model into container now
2022-12-18 15:50:54,398:INFO:master_model_container: 1
2022-12-18 15:50:54,399:INFO:display_container: 2
2022-12-18 15:50:54,399:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6515, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-18 15:50:54,400:INFO:create_model() successfully completed......................................
2022-12-18 15:50:54,619:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:54,620:INFO:Creating metrics dataframe
2022-12-18 15:50:54,642:INFO:Initializing K Neighbors Classifier
2022-12-18 15:50:54,642:INFO:Total runtime is 0.03599918286005656 minutes
2022-12-18 15:50:54,651:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:54,651:INFO:Initializing create_model()
2022-12-18 15:50:54,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:54,652:INFO:Checking exceptions
2022-12-18 15:50:54,656:INFO:Importing libraries
2022-12-18 15:50:54,656:INFO:Copying training dataset
2022-12-18 15:50:54,664:INFO:Defining folds
2022-12-18 15:50:54,664:INFO:Declaring metric variables
2022-12-18 15:50:54,672:INFO:Importing untrained model
2022-12-18 15:50:54,686:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:50:54,709:INFO:Starting cross validation
2022-12-18 15:50:54,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:55,302:INFO:Calculating mean and std
2022-12-18 15:50:55,304:INFO:Creating metrics dataframe
2022-12-18 15:50:55,309:INFO:Uploading results into container
2022-12-18 15:50:55,312:INFO:Uploading model into container now
2022-12-18 15:50:55,312:INFO:master_model_container: 2
2022-12-18 15:50:55,313:INFO:display_container: 2
2022-12-18 15:50:55,313:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:50:55,313:INFO:create_model() successfully completed......................................
2022-12-18 15:50:55,432:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:55,432:INFO:Creating metrics dataframe
2022-12-18 15:50:55,443:INFO:Initializing Naive Bayes
2022-12-18 15:50:55,443:INFO:Total runtime is 0.04934761126836141 minutes
2022-12-18 15:50:55,449:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:55,450:INFO:Initializing create_model()
2022-12-18 15:50:55,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:55,450:INFO:Checking exceptions
2022-12-18 15:50:55,452:INFO:Importing libraries
2022-12-18 15:50:55,452:INFO:Copying training dataset
2022-12-18 15:50:55,455:INFO:Defining folds
2022-12-18 15:50:55,455:INFO:Declaring metric variables
2022-12-18 15:50:55,459:INFO:Importing untrained model
2022-12-18 15:50:55,466:INFO:Naive Bayes Imported successfully
2022-12-18 15:50:55,481:INFO:Starting cross validation
2022-12-18 15:50:55,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:55,585:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:55,621:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:55,675:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:55,705:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:55,738:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:55,752:INFO:Calculating mean and std
2022-12-18 15:50:55,754:INFO:Creating metrics dataframe
2022-12-18 15:50:55,758:INFO:Uploading results into container
2022-12-18 15:50:55,759:INFO:Uploading model into container now
2022-12-18 15:50:55,761:INFO:master_model_container: 3
2022-12-18 15:50:55,762:INFO:display_container: 2
2022-12-18 15:50:55,762:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-12-18 15:50:55,763:INFO:create_model() successfully completed......................................
2022-12-18 15:50:55,885:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:55,886:INFO:Creating metrics dataframe
2022-12-18 15:50:55,898:INFO:Initializing Decision Tree Classifier
2022-12-18 15:50:55,898:INFO:Total runtime is 0.05692712068557739 minutes
2022-12-18 15:50:55,903:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:55,904:INFO:Initializing create_model()
2022-12-18 15:50:55,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:55,904:INFO:Checking exceptions
2022-12-18 15:50:55,907:INFO:Importing libraries
2022-12-18 15:50:55,907:INFO:Copying training dataset
2022-12-18 15:50:55,913:INFO:Defining folds
2022-12-18 15:50:55,913:INFO:Declaring metric variables
2022-12-18 15:50:55,921:INFO:Importing untrained model
2022-12-18 15:50:55,929:INFO:Decision Tree Classifier Imported successfully
2022-12-18 15:50:55,942:INFO:Starting cross validation
2022-12-18 15:50:55,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:56,225:INFO:Calculating mean and std
2022-12-18 15:50:56,229:INFO:Creating metrics dataframe
2022-12-18 15:50:56,234:INFO:Uploading results into container
2022-12-18 15:50:56,235:INFO:Uploading model into container now
2022-12-18 15:50:56,235:INFO:master_model_container: 4
2022-12-18 15:50:56,236:INFO:display_container: 2
2022-12-18 15:50:56,236:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6515, splitter='best')
2022-12-18 15:50:56,237:INFO:create_model() successfully completed......................................
2022-12-18 15:50:56,361:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:56,361:INFO:Creating metrics dataframe
2022-12-18 15:50:56,372:INFO:Initializing SVM - Linear Kernel
2022-12-18 15:50:56,372:INFO:Total runtime is 0.06483127673467 minutes
2022-12-18 15:50:56,378:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:56,379:INFO:Initializing create_model()
2022-12-18 15:50:56,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:56,379:INFO:Checking exceptions
2022-12-18 15:50:56,382:INFO:Importing libraries
2022-12-18 15:50:56,382:INFO:Copying training dataset
2022-12-18 15:50:56,386:INFO:Defining folds
2022-12-18 15:50:56,386:INFO:Declaring metric variables
2022-12-18 15:50:56,390:INFO:Importing untrained model
2022-12-18 15:50:56,398:INFO:SVM - Linear Kernel Imported successfully
2022-12-18 15:50:56,414:INFO:Starting cross validation
2022-12-18 15:50:56,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:56,555:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:56,594:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:56,631:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:56,632:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:56,635:INFO:Calculating mean and std
2022-12-18 15:50:56,637:INFO:Creating metrics dataframe
2022-12-18 15:50:56,640:INFO:Uploading results into container
2022-12-18 15:50:56,641:INFO:Uploading model into container now
2022-12-18 15:50:56,641:INFO:master_model_container: 5
2022-12-18 15:50:56,643:INFO:display_container: 2
2022-12-18 15:50:56,645:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6515, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-18 15:50:56,645:INFO:create_model() successfully completed......................................
2022-12-18 15:50:56,763:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:56,764:INFO:Creating metrics dataframe
2022-12-18 15:50:56,774:INFO:Initializing Ridge Classifier
2022-12-18 15:50:56,774:INFO:Total runtime is 0.07153105735778809 minutes
2022-12-18 15:50:56,782:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:56,783:INFO:Initializing create_model()
2022-12-18 15:50:56,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:56,783:INFO:Checking exceptions
2022-12-18 15:50:56,785:INFO:Importing libraries
2022-12-18 15:50:56,785:INFO:Copying training dataset
2022-12-18 15:50:56,788:INFO:Defining folds
2022-12-18 15:50:56,788:INFO:Declaring metric variables
2022-12-18 15:50:56,795:INFO:Importing untrained model
2022-12-18 15:50:56,801:INFO:Ridge Classifier Imported successfully
2022-12-18 15:50:56,815:INFO:Starting cross validation
2022-12-18 15:50:56,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:57,037:INFO:Calculating mean and std
2022-12-18 15:50:57,039:INFO:Creating metrics dataframe
2022-12-18 15:50:57,045:INFO:Uploading results into container
2022-12-18 15:50:57,046:INFO:Uploading model into container now
2022-12-18 15:50:57,046:INFO:master_model_container: 6
2022-12-18 15:50:57,046:INFO:display_container: 2
2022-12-18 15:50:57,047:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6515, solver='auto', tol=0.001)
2022-12-18 15:50:57,047:INFO:create_model() successfully completed......................................
2022-12-18 15:50:57,170:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:57,171:INFO:Creating metrics dataframe
2022-12-18 15:50:57,184:INFO:Initializing Random Forest Classifier
2022-12-18 15:50:57,184:INFO:Total runtime is 0.07836457093556722 minutes
2022-12-18 15:50:57,188:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:57,189:INFO:Initializing create_model()
2022-12-18 15:50:57,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:57,189:INFO:Checking exceptions
2022-12-18 15:50:57,194:INFO:Importing libraries
2022-12-18 15:50:57,194:INFO:Copying training dataset
2022-12-18 15:50:57,198:INFO:Defining folds
2022-12-18 15:50:57,198:INFO:Declaring metric variables
2022-12-18 15:50:57,202:INFO:Importing untrained model
2022-12-18 15:50:57,211:INFO:Random Forest Classifier Imported successfully
2022-12-18 15:50:57,231:INFO:Starting cross validation
2022-12-18 15:50:57,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:58,762:INFO:Calculating mean and std
2022-12-18 15:50:58,764:INFO:Creating metrics dataframe
2022-12-18 15:50:58,767:INFO:Uploading results into container
2022-12-18 15:50:58,768:INFO:Uploading model into container now
2022-12-18 15:50:58,769:INFO:master_model_container: 7
2022-12-18 15:50:58,769:INFO:display_container: 2
2022-12-18 15:50:58,770:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:50:58,770:INFO:create_model() successfully completed......................................
2022-12-18 15:50:58,901:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:58,901:INFO:Creating metrics dataframe
2022-12-18 15:50:58,917:INFO:Initializing Quadratic Discriminant Analysis
2022-12-18 15:50:58,918:INFO:Total runtime is 0.10726962486902872 minutes
2022-12-18 15:50:58,925:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:58,925:INFO:Initializing create_model()
2022-12-18 15:50:58,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:58,925:INFO:Checking exceptions
2022-12-18 15:50:58,927:INFO:Importing libraries
2022-12-18 15:50:58,927:INFO:Copying training dataset
2022-12-18 15:50:58,930:INFO:Defining folds
2022-12-18 15:50:58,930:INFO:Declaring metric variables
2022-12-18 15:50:58,935:INFO:Importing untrained model
2022-12-18 15:50:58,943:INFO:Quadratic Discriminant Analysis Imported successfully
2022-12-18 15:50:58,960:INFO:Starting cross validation
2022-12-18 15:50:58,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:50:59,061:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:59,226:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:50:59,232:INFO:Calculating mean and std
2022-12-18 15:50:59,234:INFO:Creating metrics dataframe
2022-12-18 15:50:59,238:INFO:Uploading results into container
2022-12-18 15:50:59,238:INFO:Uploading model into container now
2022-12-18 15:50:59,241:INFO:master_model_container: 8
2022-12-18 15:50:59,241:INFO:display_container: 2
2022-12-18 15:50:59,242:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-12-18 15:50:59,242:INFO:create_model() successfully completed......................................
2022-12-18 15:50:59,366:INFO:SubProcess create_model() end ==================================
2022-12-18 15:50:59,366:INFO:Creating metrics dataframe
2022-12-18 15:50:59,383:INFO:Initializing Ada Boost Classifier
2022-12-18 15:50:59,384:INFO:Total runtime is 0.11503225962320962 minutes
2022-12-18 15:50:59,389:INFO:SubProcess create_model() called ==================================
2022-12-18 15:50:59,390:INFO:Initializing create_model()
2022-12-18 15:50:59,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:50:59,391:INFO:Checking exceptions
2022-12-18 15:50:59,393:INFO:Importing libraries
2022-12-18 15:50:59,394:INFO:Copying training dataset
2022-12-18 15:50:59,399:INFO:Defining folds
2022-12-18 15:50:59,399:INFO:Declaring metric variables
2022-12-18 15:50:59,407:INFO:Importing untrained model
2022-12-18 15:50:59,414:INFO:Ada Boost Classifier Imported successfully
2022-12-18 15:50:59,431:INFO:Starting cross validation
2022-12-18 15:50:59,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:00,144:INFO:Calculating mean and std
2022-12-18 15:51:00,146:INFO:Creating metrics dataframe
2022-12-18 15:51:00,150:INFO:Uploading results into container
2022-12-18 15:51:00,150:INFO:Uploading model into container now
2022-12-18 15:51:00,151:INFO:master_model_container: 9
2022-12-18 15:51:00,151:INFO:display_container: 2
2022-12-18 15:51:00,152:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6515)
2022-12-18 15:51:00,153:INFO:create_model() successfully completed......................................
2022-12-18 15:51:00,276:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:00,277:INFO:Creating metrics dataframe
2022-12-18 15:51:00,291:INFO:Initializing Gradient Boosting Classifier
2022-12-18 15:51:00,291:INFO:Total runtime is 0.1301410953203837 minutes
2022-12-18 15:51:00,295:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:00,296:INFO:Initializing create_model()
2022-12-18 15:51:00,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:00,296:INFO:Checking exceptions
2022-12-18 15:51:00,299:INFO:Importing libraries
2022-12-18 15:51:00,299:INFO:Copying training dataset
2022-12-18 15:51:00,303:INFO:Defining folds
2022-12-18 15:51:00,303:INFO:Declaring metric variables
2022-12-18 15:51:00,309:INFO:Importing untrained model
2022-12-18 15:51:00,316:INFO:Gradient Boosting Classifier Imported successfully
2022-12-18 15:51:00,329:INFO:Starting cross validation
2022-12-18 15:51:00,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:01,052:INFO:Calculating mean and std
2022-12-18 15:51:01,054:INFO:Creating metrics dataframe
2022-12-18 15:51:01,059:INFO:Uploading results into container
2022-12-18 15:51:01,060:INFO:Uploading model into container now
2022-12-18 15:51:01,061:INFO:master_model_container: 10
2022-12-18 15:51:01,061:INFO:display_container: 2
2022-12-18 15:51:01,062:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6515, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-18 15:51:01,062:INFO:create_model() successfully completed......................................
2022-12-18 15:51:01,180:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:01,181:INFO:Creating metrics dataframe
2022-12-18 15:51:01,195:INFO:Initializing Linear Discriminant Analysis
2022-12-18 15:51:01,195:INFO:Total runtime is 0.14521774053573608 minutes
2022-12-18 15:51:01,199:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:01,200:INFO:Initializing create_model()
2022-12-18 15:51:01,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:01,200:INFO:Checking exceptions
2022-12-18 15:51:01,203:INFO:Importing libraries
2022-12-18 15:51:01,203:INFO:Copying training dataset
2022-12-18 15:51:01,208:INFO:Defining folds
2022-12-18 15:51:01,208:INFO:Declaring metric variables
2022-12-18 15:51:01,216:INFO:Importing untrained model
2022-12-18 15:51:01,223:INFO:Linear Discriminant Analysis Imported successfully
2022-12-18 15:51:01,238:INFO:Starting cross validation
2022-12-18 15:51:01,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:01,495:INFO:Calculating mean and std
2022-12-18 15:51:01,497:INFO:Creating metrics dataframe
2022-12-18 15:51:01,500:INFO:Uploading results into container
2022-12-18 15:51:01,501:INFO:Uploading model into container now
2022-12-18 15:51:01,501:INFO:master_model_container: 11
2022-12-18 15:51:01,501:INFO:display_container: 2
2022-12-18 15:51:01,502:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-12-18 15:51:01,502:INFO:create_model() successfully completed......................................
2022-12-18 15:51:01,627:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:01,627:INFO:Creating metrics dataframe
2022-12-18 15:51:01,642:INFO:Initializing Extra Trees Classifier
2022-12-18 15:51:01,642:INFO:Total runtime is 0.15266267458597818 minutes
2022-12-18 15:51:01,646:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:01,647:INFO:Initializing create_model()
2022-12-18 15:51:01,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:01,647:INFO:Checking exceptions
2022-12-18 15:51:01,650:INFO:Importing libraries
2022-12-18 15:51:01,650:INFO:Copying training dataset
2022-12-18 15:51:01,656:INFO:Defining folds
2022-12-18 15:51:01,656:INFO:Declaring metric variables
2022-12-18 15:51:01,679:INFO:Importing untrained model
2022-12-18 15:51:01,686:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:51:01,700:INFO:Starting cross validation
2022-12-18 15:51:01,702:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:03,271:INFO:Calculating mean and std
2022-12-18 15:51:03,273:INFO:Creating metrics dataframe
2022-12-18 15:51:03,278:INFO:Uploading results into container
2022-12-18 15:51:03,279:INFO:Uploading model into container now
2022-12-18 15:51:03,279:INFO:master_model_container: 12
2022-12-18 15:51:03,279:INFO:display_container: 2
2022-12-18 15:51:03,280:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:51:03,280:INFO:create_model() successfully completed......................................
2022-12-18 15:51:03,415:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:03,415:INFO:Creating metrics dataframe
2022-12-18 15:51:03,433:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:51:03,433:INFO:Total runtime is 0.18252185185750325 minutes
2022-12-18 15:51:03,440:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:03,441:INFO:Initializing create_model()
2022-12-18 15:51:03,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:03,442:INFO:Checking exceptions
2022-12-18 15:51:03,445:INFO:Importing libraries
2022-12-18 15:51:03,445:INFO:Copying training dataset
2022-12-18 15:51:03,448:INFO:Defining folds
2022-12-18 15:51:03,448:INFO:Declaring metric variables
2022-12-18 15:51:03,456:INFO:Importing untrained model
2022-12-18 15:51:03,461:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:51:03,479:INFO:Starting cross validation
2022-12-18 15:51:03,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:03,858:INFO:Calculating mean and std
2022-12-18 15:51:03,860:INFO:Creating metrics dataframe
2022-12-18 15:51:03,865:INFO:Uploading results into container
2022-12-18 15:51:03,866:INFO:Uploading model into container now
2022-12-18 15:51:03,866:INFO:master_model_container: 13
2022-12-18 15:51:03,866:INFO:display_container: 2
2022-12-18 15:51:03,867:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6515, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-18 15:51:03,867:INFO:create_model() successfully completed......................................
2022-12-18 15:51:04,014:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:04,014:INFO:Creating metrics dataframe
2022-12-18 15:51:04,033:INFO:Initializing Dummy Classifier
2022-12-18 15:51:04,033:INFO:Total runtime is 0.1925119161605835 minutes
2022-12-18 15:51:04,041:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:04,041:INFO:Initializing create_model()
2022-12-18 15:51:04,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:04,042:INFO:Checking exceptions
2022-12-18 15:51:04,044:INFO:Importing libraries
2022-12-18 15:51:04,045:INFO:Copying training dataset
2022-12-18 15:51:04,050:INFO:Defining folds
2022-12-18 15:51:04,050:INFO:Declaring metric variables
2022-12-18 15:51:04,058:INFO:Importing untrained model
2022-12-18 15:51:04,065:INFO:Dummy Classifier Imported successfully
2022-12-18 15:51:04,077:INFO:Starting cross validation
2022-12-18 15:51:04,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:04,341:INFO:Calculating mean and std
2022-12-18 15:51:04,343:INFO:Creating metrics dataframe
2022-12-18 15:51:04,347:INFO:Uploading results into container
2022-12-18 15:51:04,347:INFO:Uploading model into container now
2022-12-18 15:51:04,348:INFO:master_model_container: 14
2022-12-18 15:51:04,348:INFO:display_container: 2
2022-12-18 15:51:04,348:INFO:DummyClassifier(constant=None, random_state=6515, strategy='prior')
2022-12-18 15:51:04,348:INFO:create_model() successfully completed......................................
2022-12-18 15:51:04,466:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:04,466:INFO:Creating metrics dataframe
2022-12-18 15:51:04,500:INFO:Initializing create_model()
2022-12-18 15:51:04,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:04,503:INFO:Checking exceptions
2022-12-18 15:51:04,510:INFO:Importing libraries
2022-12-18 15:51:04,510:INFO:Copying training dataset
2022-12-18 15:51:04,514:INFO:Defining folds
2022-12-18 15:51:04,514:INFO:Declaring metric variables
2022-12-18 15:51:04,514:INFO:Importing untrained model
2022-12-18 15:51:04,514:INFO:Declaring custom model
2022-12-18 15:51:04,515:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:51:04,515:INFO:Cross validation set to False
2022-12-18 15:51:04,516:INFO:Fitting Model
2022-12-18 15:51:04,590:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:51:04,590:INFO:create_model() successfully completed......................................
2022-12-18 15:51:04,761:INFO:master_model_container: 14
2022-12-18 15:51:04,761:INFO:display_container: 2
2022-12-18 15:51:04,761:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:51:04,762:INFO:compare_models() successfully completed......................................
2022-12-18 15:51:14,631:INFO:Initializing compare_models()
2022-12-18 15:51:14,631:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-12-18 15:51:14,631:INFO:Checking exceptions
2022-12-18 15:51:14,637:INFO:Preparing display monitor
2022-12-18 15:51:14,706:INFO:Initializing Logistic Regression
2022-12-18 15:51:14,708:INFO:Total runtime is 3.325144449869792e-05 minutes
2022-12-18 15:51:14,714:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:14,715:INFO:Initializing create_model()
2022-12-18 15:51:14,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:14,715:INFO:Checking exceptions
2022-12-18 15:51:14,719:INFO:Importing libraries
2022-12-18 15:51:14,719:INFO:Copying training dataset
2022-12-18 15:51:14,723:INFO:Defining folds
2022-12-18 15:51:14,723:INFO:Declaring metric variables
2022-12-18 15:51:14,731:INFO:Importing untrained model
2022-12-18 15:51:14,740:INFO:Logistic Regression Imported successfully
2022-12-18 15:51:14,754:INFO:Starting cross validation
2022-12-18 15:51:14,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:15,255:INFO:Calculating mean and std
2022-12-18 15:51:15,255:INFO:Creating metrics dataframe
2022-12-18 15:51:15,263:INFO:Uploading results into container
2022-12-18 15:51:15,264:INFO:Uploading model into container now
2022-12-18 15:51:15,265:INFO:master_model_container: 15
2022-12-18 15:51:15,265:INFO:display_container: 3
2022-12-18 15:51:15,265:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6515, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-18 15:51:15,265:INFO:create_model() successfully completed......................................
2022-12-18 15:51:15,416:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:15,416:INFO:Creating metrics dataframe
2022-12-18 15:51:15,432:INFO:Initializing K Neighbors Classifier
2022-12-18 15:51:15,432:INFO:Total runtime is 0.012099949518839519 minutes
2022-12-18 15:51:15,436:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:15,437:INFO:Initializing create_model()
2022-12-18 15:51:15,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:15,437:INFO:Checking exceptions
2022-12-18 15:51:15,442:INFO:Importing libraries
2022-12-18 15:51:15,443:INFO:Copying training dataset
2022-12-18 15:51:15,446:INFO:Defining folds
2022-12-18 15:51:15,447:INFO:Declaring metric variables
2022-12-18 15:51:15,450:INFO:Importing untrained model
2022-12-18 15:51:15,456:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:51:15,476:INFO:Starting cross validation
2022-12-18 15:51:15,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:15,869:INFO:Calculating mean and std
2022-12-18 15:51:15,871:INFO:Creating metrics dataframe
2022-12-18 15:51:15,880:INFO:Uploading results into container
2022-12-18 15:51:15,881:INFO:Uploading model into container now
2022-12-18 15:51:15,882:INFO:master_model_container: 16
2022-12-18 15:51:15,882:INFO:display_container: 3
2022-12-18 15:51:15,882:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:51:15,883:INFO:create_model() successfully completed......................................
2022-12-18 15:51:16,030:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:16,030:INFO:Creating metrics dataframe
2022-12-18 15:51:16,047:INFO:Initializing Naive Bayes
2022-12-18 15:51:16,047:INFO:Total runtime is 0.022341338793436687 minutes
2022-12-18 15:51:16,051:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:16,051:INFO:Initializing create_model()
2022-12-18 15:51:16,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:16,052:INFO:Checking exceptions
2022-12-18 15:51:16,055:INFO:Importing libraries
2022-12-18 15:51:16,055:INFO:Copying training dataset
2022-12-18 15:51:16,095:INFO:Defining folds
2022-12-18 15:51:16,096:INFO:Declaring metric variables
2022-12-18 15:51:16,103:INFO:Importing untrained model
2022-12-18 15:51:16,112:INFO:Naive Bayes Imported successfully
2022-12-18 15:51:16,128:INFO:Starting cross validation
2022-12-18 15:51:16,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:16,258:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:16,318:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:16,387:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:16,417:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:16,449:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:16,467:INFO:Calculating mean and std
2022-12-18 15:51:16,469:INFO:Creating metrics dataframe
2022-12-18 15:51:16,472:INFO:Uploading results into container
2022-12-18 15:51:16,474:INFO:Uploading model into container now
2022-12-18 15:51:16,475:INFO:master_model_container: 17
2022-12-18 15:51:16,478:INFO:display_container: 3
2022-12-18 15:51:16,478:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-12-18 15:51:16,478:INFO:create_model() successfully completed......................................
2022-12-18 15:51:16,632:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:16,632:INFO:Creating metrics dataframe
2022-12-18 15:51:16,650:INFO:Initializing Decision Tree Classifier
2022-12-18 15:51:16,650:INFO:Total runtime is 0.03238914807637533 minutes
2022-12-18 15:51:16,655:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:16,655:INFO:Initializing create_model()
2022-12-18 15:51:16,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:16,655:INFO:Checking exceptions
2022-12-18 15:51:16,661:INFO:Importing libraries
2022-12-18 15:51:16,661:INFO:Copying training dataset
2022-12-18 15:51:16,668:INFO:Defining folds
2022-12-18 15:51:16,668:INFO:Declaring metric variables
2022-12-18 15:51:16,676:INFO:Importing untrained model
2022-12-18 15:51:16,683:INFO:Decision Tree Classifier Imported successfully
2022-12-18 15:51:16,701:INFO:Starting cross validation
2022-12-18 15:51:16,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:16,986:INFO:Calculating mean and std
2022-12-18 15:51:16,988:INFO:Creating metrics dataframe
2022-12-18 15:51:16,996:INFO:Uploading results into container
2022-12-18 15:51:16,997:INFO:Uploading model into container now
2022-12-18 15:51:16,998:INFO:master_model_container: 18
2022-12-18 15:51:16,998:INFO:display_container: 3
2022-12-18 15:51:16,999:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6515, splitter='best')
2022-12-18 15:51:16,999:INFO:create_model() successfully completed......................................
2022-12-18 15:51:17,130:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:17,130:INFO:Creating metrics dataframe
2022-12-18 15:51:17,143:INFO:Initializing SVM - Linear Kernel
2022-12-18 15:51:17,143:INFO:Total runtime is 0.0406034787495931 minutes
2022-12-18 15:51:17,147:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:17,148:INFO:Initializing create_model()
2022-12-18 15:51:17,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:17,148:INFO:Checking exceptions
2022-12-18 15:51:17,151:INFO:Importing libraries
2022-12-18 15:51:17,151:INFO:Copying training dataset
2022-12-18 15:51:17,155:INFO:Defining folds
2022-12-18 15:51:17,155:INFO:Declaring metric variables
2022-12-18 15:51:17,161:INFO:Importing untrained model
2022-12-18 15:51:17,168:INFO:SVM - Linear Kernel Imported successfully
2022-12-18 15:51:17,183:INFO:Starting cross validation
2022-12-18 15:51:17,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:17,341:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:17,381:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:17,433:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:17,437:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:17,451:INFO:Calculating mean and std
2022-12-18 15:51:17,453:INFO:Creating metrics dataframe
2022-12-18 15:51:17,460:INFO:Uploading results into container
2022-12-18 15:51:17,461:INFO:Uploading model into container now
2022-12-18 15:51:17,462:INFO:master_model_container: 19
2022-12-18 15:51:17,462:INFO:display_container: 3
2022-12-18 15:51:17,463:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6515, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-18 15:51:17,464:INFO:create_model() successfully completed......................................
2022-12-18 15:51:17,607:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:17,607:INFO:Creating metrics dataframe
2022-12-18 15:51:17,626:INFO:Initializing Ridge Classifier
2022-12-18 15:51:17,626:INFO:Total runtime is 0.048665277163187665 minutes
2022-12-18 15:51:17,631:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:17,632:INFO:Initializing create_model()
2022-12-18 15:51:17,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:17,633:INFO:Checking exceptions
2022-12-18 15:51:17,636:INFO:Importing libraries
2022-12-18 15:51:17,636:INFO:Copying training dataset
2022-12-18 15:51:17,643:INFO:Defining folds
2022-12-18 15:51:17,644:INFO:Declaring metric variables
2022-12-18 15:51:17,651:INFO:Importing untrained model
2022-12-18 15:51:17,658:INFO:Ridge Classifier Imported successfully
2022-12-18 15:51:17,699:INFO:Starting cross validation
2022-12-18 15:51:17,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:17,923:INFO:Calculating mean and std
2022-12-18 15:51:17,924:INFO:Creating metrics dataframe
2022-12-18 15:51:17,928:INFO:Uploading results into container
2022-12-18 15:51:17,929:INFO:Uploading model into container now
2022-12-18 15:51:17,929:INFO:master_model_container: 20
2022-12-18 15:51:17,929:INFO:display_container: 3
2022-12-18 15:51:17,930:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6515, solver='auto', tol=0.001)
2022-12-18 15:51:17,930:INFO:create_model() successfully completed......................................
2022-12-18 15:51:18,048:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:18,049:INFO:Creating metrics dataframe
2022-12-18 15:51:18,063:INFO:Initializing Random Forest Classifier
2022-12-18 15:51:18,063:INFO:Total runtime is 0.05594757000605265 minutes
2022-12-18 15:51:18,067:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:18,068:INFO:Initializing create_model()
2022-12-18 15:51:18,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:18,068:INFO:Checking exceptions
2022-12-18 15:51:18,072:INFO:Importing libraries
2022-12-18 15:51:18,073:INFO:Copying training dataset
2022-12-18 15:51:18,077:INFO:Defining folds
2022-12-18 15:51:18,077:INFO:Declaring metric variables
2022-12-18 15:51:18,081:INFO:Importing untrained model
2022-12-18 15:51:18,089:INFO:Random Forest Classifier Imported successfully
2022-12-18 15:51:18,102:INFO:Starting cross validation
2022-12-18 15:51:18,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:19,809:INFO:Calculating mean and std
2022-12-18 15:51:19,811:INFO:Creating metrics dataframe
2022-12-18 15:51:19,816:INFO:Uploading results into container
2022-12-18 15:51:19,816:INFO:Uploading model into container now
2022-12-18 15:51:19,817:INFO:master_model_container: 21
2022-12-18 15:51:19,817:INFO:display_container: 3
2022-12-18 15:51:19,818:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:51:19,819:INFO:create_model() successfully completed......................................
2022-12-18 15:51:19,939:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:19,939:INFO:Creating metrics dataframe
2022-12-18 15:51:19,950:INFO:Initializing Quadratic Discriminant Analysis
2022-12-18 15:51:19,951:INFO:Total runtime is 0.0874144196510315 minutes
2022-12-18 15:51:19,956:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:19,957:INFO:Initializing create_model()
2022-12-18 15:51:19,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:19,957:INFO:Checking exceptions
2022-12-18 15:51:19,960:INFO:Importing libraries
2022-12-18 15:51:19,960:INFO:Copying training dataset
2022-12-18 15:51:19,964:INFO:Defining folds
2022-12-18 15:51:19,964:INFO:Declaring metric variables
2022-12-18 15:51:19,971:INFO:Importing untrained model
2022-12-18 15:51:19,979:INFO:Quadratic Discriminant Analysis Imported successfully
2022-12-18 15:51:19,992:INFO:Starting cross validation
2022-12-18 15:51:19,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:20,076:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:20,215:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-18 15:51:20,221:INFO:Calculating mean and std
2022-12-18 15:51:20,222:INFO:Creating metrics dataframe
2022-12-18 15:51:20,227:INFO:Uploading results into container
2022-12-18 15:51:20,228:INFO:Uploading model into container now
2022-12-18 15:51:20,228:INFO:master_model_container: 22
2022-12-18 15:51:20,228:INFO:display_container: 3
2022-12-18 15:51:20,229:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-12-18 15:51:20,229:INFO:create_model() successfully completed......................................
2022-12-18 15:51:20,374:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:20,374:INFO:Creating metrics dataframe
2022-12-18 15:51:20,400:INFO:Initializing Ada Boost Classifier
2022-12-18 15:51:20,400:INFO:Total runtime is 0.09490007559458415 minutes
2022-12-18 15:51:20,412:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:20,412:INFO:Initializing create_model()
2022-12-18 15:51:20,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:20,413:INFO:Checking exceptions
2022-12-18 15:51:20,417:INFO:Importing libraries
2022-12-18 15:51:20,417:INFO:Copying training dataset
2022-12-18 15:51:20,428:INFO:Defining folds
2022-12-18 15:51:20,428:INFO:Declaring metric variables
2022-12-18 15:51:20,439:INFO:Importing untrained model
2022-12-18 15:51:20,446:INFO:Ada Boost Classifier Imported successfully
2022-12-18 15:51:20,461:INFO:Starting cross validation
2022-12-18 15:51:20,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:21,210:INFO:Calculating mean and std
2022-12-18 15:51:21,212:INFO:Creating metrics dataframe
2022-12-18 15:51:21,224:INFO:Uploading results into container
2022-12-18 15:51:21,225:INFO:Uploading model into container now
2022-12-18 15:51:21,226:INFO:master_model_container: 23
2022-12-18 15:51:21,226:INFO:display_container: 3
2022-12-18 15:51:21,227:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6515)
2022-12-18 15:51:21,227:INFO:create_model() successfully completed......................................
2022-12-18 15:51:21,355:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:21,355:INFO:Creating metrics dataframe
2022-12-18 15:51:21,370:INFO:Initializing Gradient Boosting Classifier
2022-12-18 15:51:21,371:INFO:Total runtime is 0.11105221112569173 minutes
2022-12-18 15:51:21,374:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:21,375:INFO:Initializing create_model()
2022-12-18 15:51:21,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:21,376:INFO:Checking exceptions
2022-12-18 15:51:21,378:INFO:Importing libraries
2022-12-18 15:51:21,378:INFO:Copying training dataset
2022-12-18 15:51:21,382:INFO:Defining folds
2022-12-18 15:51:21,392:INFO:Declaring metric variables
2022-12-18 15:51:21,396:INFO:Importing untrained model
2022-12-18 15:51:21,404:INFO:Gradient Boosting Classifier Imported successfully
2022-12-18 15:51:21,414:INFO:Starting cross validation
2022-12-18 15:51:21,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:22,243:INFO:Calculating mean and std
2022-12-18 15:51:22,245:INFO:Creating metrics dataframe
2022-12-18 15:51:22,249:INFO:Uploading results into container
2022-12-18 15:51:22,249:INFO:Uploading model into container now
2022-12-18 15:51:22,251:INFO:master_model_container: 24
2022-12-18 15:51:22,254:INFO:display_container: 3
2022-12-18 15:51:22,255:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6515, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-18 15:51:22,255:INFO:create_model() successfully completed......................................
2022-12-18 15:51:22,395:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:22,395:INFO:Creating metrics dataframe
2022-12-18 15:51:22,412:INFO:Initializing Linear Discriminant Analysis
2022-12-18 15:51:22,413:INFO:Total runtime is 0.1284348964691162 minutes
2022-12-18 15:51:22,416:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:22,420:INFO:Initializing create_model()
2022-12-18 15:51:22,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:22,420:INFO:Checking exceptions
2022-12-18 15:51:22,423:INFO:Importing libraries
2022-12-18 15:51:22,424:INFO:Copying training dataset
2022-12-18 15:51:22,429:INFO:Defining folds
2022-12-18 15:51:22,429:INFO:Declaring metric variables
2022-12-18 15:51:22,439:INFO:Importing untrained model
2022-12-18 15:51:22,448:INFO:Linear Discriminant Analysis Imported successfully
2022-12-18 15:51:22,465:INFO:Starting cross validation
2022-12-18 15:51:22,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:22,888:INFO:Calculating mean and std
2022-12-18 15:51:22,904:INFO:Creating metrics dataframe
2022-12-18 15:51:22,911:INFO:Uploading results into container
2022-12-18 15:51:22,912:INFO:Uploading model into container now
2022-12-18 15:51:22,913:INFO:master_model_container: 25
2022-12-18 15:51:22,913:INFO:display_container: 3
2022-12-18 15:51:22,914:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-12-18 15:51:22,914:INFO:create_model() successfully completed......................................
2022-12-18 15:51:23,064:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:23,064:INFO:Creating metrics dataframe
2022-12-18 15:51:23,086:INFO:Initializing Extra Trees Classifier
2022-12-18 15:51:23,086:INFO:Total runtime is 0.13965619802474977 minutes
2022-12-18 15:51:23,091:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:23,092:INFO:Initializing create_model()
2022-12-18 15:51:23,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:23,092:INFO:Checking exceptions
2022-12-18 15:51:23,095:INFO:Importing libraries
2022-12-18 15:51:23,095:INFO:Copying training dataset
2022-12-18 15:51:23,099:INFO:Defining folds
2022-12-18 15:51:23,101:INFO:Declaring metric variables
2022-12-18 15:51:23,108:INFO:Importing untrained model
2022-12-18 15:51:23,116:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:51:23,135:INFO:Starting cross validation
2022-12-18 15:51:23,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:24,702:INFO:Calculating mean and std
2022-12-18 15:51:24,703:INFO:Creating metrics dataframe
2022-12-18 15:51:24,707:INFO:Uploading results into container
2022-12-18 15:51:24,708:INFO:Uploading model into container now
2022-12-18 15:51:24,708:INFO:master_model_container: 26
2022-12-18 15:51:24,708:INFO:display_container: 3
2022-12-18 15:51:24,709:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:51:24,709:INFO:create_model() successfully completed......................................
2022-12-18 15:51:24,830:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:24,830:INFO:Creating metrics dataframe
2022-12-18 15:51:24,845:INFO:Initializing Light Gradient Boosting Machine
2022-12-18 15:51:24,845:INFO:Total runtime is 0.16897040605545044 minutes
2022-12-18 15:51:24,851:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:24,852:INFO:Initializing create_model()
2022-12-18 15:51:24,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:24,852:INFO:Checking exceptions
2022-12-18 15:51:24,855:INFO:Importing libraries
2022-12-18 15:51:24,855:INFO:Copying training dataset
2022-12-18 15:51:24,859:INFO:Defining folds
2022-12-18 15:51:24,859:INFO:Declaring metric variables
2022-12-18 15:51:24,863:INFO:Importing untrained model
2022-12-18 15:51:24,872:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-18 15:51:24,885:INFO:Starting cross validation
2022-12-18 15:51:24,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:25,360:INFO:Calculating mean and std
2022-12-18 15:51:25,362:INFO:Creating metrics dataframe
2022-12-18 15:51:25,367:INFO:Uploading results into container
2022-12-18 15:51:25,367:INFO:Uploading model into container now
2022-12-18 15:51:25,368:INFO:master_model_container: 27
2022-12-18 15:51:25,368:INFO:display_container: 3
2022-12-18 15:51:25,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6515, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-18 15:51:25,370:INFO:create_model() successfully completed......................................
2022-12-18 15:51:25,487:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:25,487:INFO:Creating metrics dataframe
2022-12-18 15:51:25,503:INFO:Initializing Dummy Classifier
2022-12-18 15:51:25,503:INFO:Total runtime is 0.17994203567504882 minutes
2022-12-18 15:51:25,507:INFO:SubProcess create_model() called ==================================
2022-12-18 15:51:25,508:INFO:Initializing create_model()
2022-12-18 15:51:25,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C443C32290>, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:25,508:INFO:Checking exceptions
2022-12-18 15:51:25,509:INFO:Importing libraries
2022-12-18 15:51:25,510:INFO:Copying training dataset
2022-12-18 15:51:25,513:INFO:Defining folds
2022-12-18 15:51:25,513:INFO:Declaring metric variables
2022-12-18 15:51:25,522:INFO:Importing untrained model
2022-12-18 15:51:25,527:INFO:Dummy Classifier Imported successfully
2022-12-18 15:51:25,549:INFO:Starting cross validation
2022-12-18 15:51:25,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:25,806:INFO:Calculating mean and std
2022-12-18 15:51:25,807:INFO:Creating metrics dataframe
2022-12-18 15:51:25,811:INFO:Uploading results into container
2022-12-18 15:51:25,812:INFO:Uploading model into container now
2022-12-18 15:51:25,812:INFO:master_model_container: 28
2022-12-18 15:51:25,812:INFO:display_container: 3
2022-12-18 15:51:25,812:INFO:DummyClassifier(constant=None, random_state=6515, strategy='prior')
2022-12-18 15:51:25,813:INFO:create_model() successfully completed......................................
2022-12-18 15:51:25,936:INFO:SubProcess create_model() end ==================================
2022-12-18 15:51:25,937:INFO:Creating metrics dataframe
2022-12-18 15:51:25,969:INFO:Initializing create_model()
2022-12-18 15:51:25,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:25,970:INFO:Checking exceptions
2022-12-18 15:51:25,976:INFO:Importing libraries
2022-12-18 15:51:25,977:INFO:Copying training dataset
2022-12-18 15:51:25,983:INFO:Defining folds
2022-12-18 15:51:25,983:INFO:Declaring metric variables
2022-12-18 15:51:25,983:INFO:Importing untrained model
2022-12-18 15:51:25,983:INFO:Declaring custom model
2022-12-18 15:51:25,984:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:51:25,986:INFO:Cross validation set to False
2022-12-18 15:51:25,986:INFO:Fitting Model
2022-12-18 15:51:26,022:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:51:26,022:INFO:create_model() successfully completed......................................
2022-12-18 15:51:26,227:INFO:master_model_container: 28
2022-12-18 15:51:26,227:INFO:display_container: 3
2022-12-18 15:51:26,228:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:51:26,228:INFO:compare_models() successfully completed......................................
2022-12-18 15:51:51,374:INFO:Initializing create_model()
2022-12-18 15:51:51,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=et, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:51:51,374:INFO:Checking exceptions
2022-12-18 15:51:51,442:INFO:Importing libraries
2022-12-18 15:51:51,442:INFO:Copying training dataset
2022-12-18 15:51:51,446:INFO:Defining folds
2022-12-18 15:51:51,446:INFO:Declaring metric variables
2022-12-18 15:51:51,450:INFO:Importing untrained model
2022-12-18 15:51:51,459:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:51:51,486:INFO:Starting cross validation
2022-12-18 15:51:51,488:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:51:56,305:INFO:Calculating mean and std
2022-12-18 15:51:56,307:INFO:Creating metrics dataframe
2022-12-18 15:51:56,313:INFO:Finalizing model
2022-12-18 15:51:56,489:INFO:Uploading results into container
2022-12-18 15:51:56,490:INFO:Uploading model into container now
2022-12-18 15:51:56,506:INFO:master_model_container: 29
2022-12-18 15:51:56,507:INFO:display_container: 4
2022-12-18 15:51:56,509:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:51:56,509:INFO:create_model() successfully completed......................................
2022-12-18 15:52:11,440:INFO:Initializing plot_model()
2022-12-18 15:52:11,440:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, system=True)
2022-12-18 15:52:11,440:INFO:Checking exceptions
2022-12-18 15:52:11,490:INFO:Preloading libraries
2022-12-18 15:52:11,516:INFO:Copying training dataset
2022-12-18 15:52:11,516:INFO:Plot type: auc
2022-12-18 15:52:11,694:INFO:Fitting Model
2022-12-18 15:52:11,695:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2022-12-18 15:52:11,695:INFO:Scoring test/hold-out set
2022-12-18 15:52:12,060:INFO:Visual Rendered Successfully
2022-12-18 15:52:12,287:INFO:plot_model() successfully completed......................................
2022-12-18 15:52:19,923:INFO:Initializing plot_model()
2022-12-18 15:52:19,924:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, system=True)
2022-12-18 15:52:19,924:INFO:Checking exceptions
2022-12-18 15:52:19,973:INFO:Preloading libraries
2022-12-18 15:52:19,998:INFO:Copying training dataset
2022-12-18 15:52:19,998:INFO:Plot type: learning
2022-12-18 15:52:20,122:INFO:Fitting Model
2022-12-18 15:52:31,123:INFO:Visual Rendered Successfully
2022-12-18 15:52:31,241:INFO:plot_model() successfully completed......................................
2022-12-18 15:52:33,809:INFO:Initializing tune_model()
2022-12-18 15:52:33,810:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>)
2022-12-18 15:52:33,810:INFO:Checking exceptions
2022-12-18 15:52:33,876:INFO:Copying training dataset
2022-12-18 15:52:33,883:INFO:Checking base model
2022-12-18 15:52:33,884:INFO:Base model : Extra Trees Classifier
2022-12-18 15:52:33,891:INFO:Declaring metric variables
2022-12-18 15:52:33,899:INFO:Defining Hyperparameters
2022-12-18 15:52:34,113:INFO:Tuning with n_jobs=-1
2022-12-18 15:52:34,113:INFO:Initializing RandomizedSearchCV
2022-12-18 15:52:47,743:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2022-12-18 15:52:47,745:INFO:Hyperparameter search completed
2022-12-18 15:52:47,745:INFO:SubProcess create_model() called ==================================
2022-12-18 15:52:47,745:INFO:Initializing create_model()
2022-12-18 15:52:47,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C865D50>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2022-12-18 15:52:47,746:INFO:Checking exceptions
2022-12-18 15:52:47,749:INFO:Importing libraries
2022-12-18 15:52:47,749:INFO:Copying training dataset
2022-12-18 15:52:47,755:INFO:Defining folds
2022-12-18 15:52:47,755:INFO:Declaring metric variables
2022-12-18 15:52:47,758:INFO:Importing untrained model
2022-12-18 15:52:47,759:INFO:Declaring custom model
2022-12-18 15:52:47,763:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:52:47,776:INFO:Starting cross validation
2022-12-18 15:52:47,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:52:49,362:INFO:Calculating mean and std
2022-12-18 15:52:49,363:INFO:Creating metrics dataframe
2022-12-18 15:52:49,372:INFO:Finalizing model
2022-12-18 15:52:49,645:INFO:Uploading results into container
2022-12-18 15:52:49,646:INFO:Uploading model into container now
2022-12-18 15:52:49,650:INFO:master_model_container: 30
2022-12-18 15:52:49,650:INFO:display_container: 5
2022-12-18 15:52:49,651:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=7, max_features='sqrt', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=3, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=6515, verbose=0,
                     warm_start=False)
2022-12-18 15:52:49,651:INFO:create_model() successfully completed......................................
2022-12-18 15:52:49,788:INFO:SubProcess create_model() end ==================================
2022-12-18 15:52:49,788:INFO:choose_better activated
2022-12-18 15:52:49,792:INFO:SubProcess create_model() called ==================================
2022-12-18 15:52:49,793:INFO:Initializing create_model()
2022-12-18 15:52:49,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:52:49,793:INFO:Checking exceptions
2022-12-18 15:52:49,800:INFO:Importing libraries
2022-12-18 15:52:49,800:INFO:Copying training dataset
2022-12-18 15:52:49,804:INFO:Defining folds
2022-12-18 15:52:49,804:INFO:Declaring metric variables
2022-12-18 15:52:49,804:INFO:Importing untrained model
2022-12-18 15:52:49,804:INFO:Declaring custom model
2022-12-18 15:52:49,805:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:52:49,805:INFO:Starting cross validation
2022-12-18 15:52:49,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:52:51,135:INFO:Calculating mean and std
2022-12-18 15:52:51,135:INFO:Creating metrics dataframe
2022-12-18 15:52:51,137:INFO:Finalizing model
2022-12-18 15:52:51,300:INFO:Uploading results into container
2022-12-18 15:52:51,301:INFO:Uploading model into container now
2022-12-18 15:52:51,301:INFO:master_model_container: 31
2022-12-18 15:52:51,301:INFO:display_container: 6
2022-12-18 15:52:51,302:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:52:51,302:INFO:create_model() successfully completed......................................
2022-12-18 15:52:51,421:INFO:SubProcess create_model() end ==================================
2022-12-18 15:52:51,422:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False) result for Accuracy is 0.579
2022-12-18 15:52:51,422:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=7, max_features='sqrt', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=3, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=6515, verbose=0,
                     warm_start=False) result for Accuracy is 0.5595
2022-12-18 15:52:51,423:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False) is best model
2022-12-18 15:52:51,423:INFO:choose_better completed
2022-12-18 15:52:51,423:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-12-18 15:52:51,438:INFO:master_model_container: 31
2022-12-18 15:52:51,438:INFO:display_container: 5
2022-12-18 15:52:51,438:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:52:51,439:INFO:tune_model() successfully completed......................................
2022-12-18 15:52:53,480:INFO:Initializing tune_model()
2022-12-18 15:52:53,480:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>)
2022-12-18 15:52:53,480:INFO:Checking exceptions
2022-12-18 15:52:53,541:INFO:Copying training dataset
2022-12-18 15:52:53,554:INFO:Checking base model
2022-12-18 15:52:53,555:INFO:Base model : Extra Trees Classifier
2022-12-18 15:52:53,561:INFO:Declaring metric variables
2022-12-18 15:52:53,568:INFO:Defining Hyperparameters
2022-12-18 15:52:53,767:INFO:Tuning with n_jobs=-1
2022-12-18 15:52:53,767:INFO:Initializing RandomizedSearchCV
2022-12-18 15:53:06,614:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2022-12-18 15:53:06,617:INFO:Hyperparameter search completed
2022-12-18 15:53:06,618:INFO:SubProcess create_model() called ==================================
2022-12-18 15:53:06,619:INFO:Initializing create_model()
2022-12-18 15:53:06,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C43C21ED70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2022-12-18 15:53:06,619:INFO:Checking exceptions
2022-12-18 15:53:06,625:INFO:Importing libraries
2022-12-18 15:53:06,625:INFO:Copying training dataset
2022-12-18 15:53:06,628:INFO:Defining folds
2022-12-18 15:53:06,628:INFO:Declaring metric variables
2022-12-18 15:53:06,633:INFO:Importing untrained model
2022-12-18 15:53:06,633:INFO:Declaring custom model
2022-12-18 15:53:06,640:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:53:06,653:INFO:Starting cross validation
2022-12-18 15:53:06,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:53:08,236:INFO:Calculating mean and std
2022-12-18 15:53:08,238:INFO:Creating metrics dataframe
2022-12-18 15:53:08,245:INFO:Finalizing model
2022-12-18 15:53:08,504:INFO:Uploading results into container
2022-12-18 15:53:08,505:INFO:Uploading model into container now
2022-12-18 15:53:08,506:INFO:master_model_container: 32
2022-12-18 15:53:08,507:INFO:display_container: 6
2022-12-18 15:53:08,507:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=7, max_features='sqrt', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=3, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=6515, verbose=0,
                     warm_start=False)
2022-12-18 15:53:08,508:INFO:create_model() successfully completed......................................
2022-12-18 15:53:08,631:INFO:SubProcess create_model() end ==================================
2022-12-18 15:53:08,631:INFO:choose_better activated
2022-12-18 15:53:08,635:INFO:SubProcess create_model() called ==================================
2022-12-18 15:53:08,636:INFO:Initializing create_model()
2022-12-18 15:53:08,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:53:08,636:INFO:Checking exceptions
2022-12-18 15:53:08,640:INFO:Importing libraries
2022-12-18 15:53:08,641:INFO:Copying training dataset
2022-12-18 15:53:08,643:INFO:Defining folds
2022-12-18 15:53:08,643:INFO:Declaring metric variables
2022-12-18 15:53:08,644:INFO:Importing untrained model
2022-12-18 15:53:08,644:INFO:Declaring custom model
2022-12-18 15:53:08,645:INFO:Extra Trees Classifier Imported successfully
2022-12-18 15:53:08,645:INFO:Starting cross validation
2022-12-18 15:53:08,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:53:09,891:INFO:Calculating mean and std
2022-12-18 15:53:09,891:INFO:Creating metrics dataframe
2022-12-18 15:53:09,893:INFO:Finalizing model
2022-12-18 15:53:10,073:INFO:Uploading results into container
2022-12-18 15:53:10,074:INFO:Uploading model into container now
2022-12-18 15:53:10,074:INFO:master_model_container: 33
2022-12-18 15:53:10,074:INFO:display_container: 7
2022-12-18 15:53:10,074:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:53:10,075:INFO:create_model() successfully completed......................................
2022-12-18 15:53:10,207:INFO:SubProcess create_model() end ==================================
2022-12-18 15:53:10,208:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False) result for Accuracy is 0.579
2022-12-18 15:53:10,210:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=7, max_features='sqrt', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=3, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=6515, verbose=0,
                     warm_start=False) result for Accuracy is 0.5595
2022-12-18 15:53:10,210:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False) is best model
2022-12-18 15:53:10,210:INFO:choose_better completed
2022-12-18 15:53:10,210:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-12-18 15:53:10,226:INFO:master_model_container: 33
2022-12-18 15:53:10,227:INFO:display_container: 6
2022-12-18 15:53:10,229:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False)
2022-12-18 15:53:10,229:INFO:tune_model() successfully completed......................................
2022-12-18 15:53:17,088:INFO:Initializing plot_model()
2022-12-18 15:53:17,089:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, system=True)
2022-12-18 15:53:17,090:INFO:Checking exceptions
2022-12-18 15:53:17,133:INFO:Preloading libraries
2022-12-18 15:53:17,158:INFO:Copying training dataset
2022-12-18 15:53:17,158:INFO:Plot type: learning
2022-12-18 15:53:17,342:INFO:Fitting Model
2022-12-18 15:53:28,666:INFO:Visual Rendered Successfully
2022-12-18 15:53:28,823:INFO:plot_model() successfully completed......................................
2022-12-18 15:53:30,880:INFO:Initializing save_model()
2022-12-18 15:53:30,880:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6515, verbose=0, warm_start=False), model_name=forestfiremodel, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-12-18 15:53:30,880:INFO:Adding model into prep_pipe
2022-12-18 15:53:31,031:INFO:forestfiremodel.pkl saved in current working directory
2022-12-18 15:53:31,046:INFO:Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Trans...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=6515,
                                      verbose=0, warm_start=False))],
         verbose=False)
2022-12-18 15:53:31,046:INFO:save_model() successfully completed......................................
2022-12-18 15:54:25,357:INFO:Initializing create_model()
2022-12-18 15:54:25,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=knn, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:54:25,358:INFO:Checking exceptions
2022-12-18 15:54:25,420:INFO:Importing libraries
2022-12-18 15:54:25,420:INFO:Copying training dataset
2022-12-18 15:54:25,428:INFO:Defining folds
2022-12-18 15:54:25,429:INFO:Declaring metric variables
2022-12-18 15:54:25,435:INFO:Importing untrained model
2022-12-18 15:54:25,443:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:54:25,463:INFO:Starting cross validation
2022-12-18 15:54:25,465:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:54:26,544:INFO:Calculating mean and std
2022-12-18 15:54:26,545:INFO:Creating metrics dataframe
2022-12-18 15:54:26,552:INFO:Finalizing model
2022-12-18 15:54:26,578:INFO:Uploading results into container
2022-12-18 15:54:26,579:INFO:Uploading model into container now
2022-12-18 15:54:26,632:INFO:master_model_container: 34
2022-12-18 15:54:26,633:INFO:display_container: 7
2022-12-18 15:54:26,634:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:54:26,634:INFO:create_model() successfully completed......................................
2022-12-18 15:54:28,841:INFO:Initializing plot_model()
2022-12-18 15:54:28,841:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, system=True)
2022-12-18 15:54:28,841:INFO:Checking exceptions
2022-12-18 15:54:28,850:INFO:Preloading libraries
2022-12-18 15:54:28,853:INFO:Copying training dataset
2022-12-18 15:54:28,854:INFO:Plot type: auc
2022-12-18 15:54:28,938:INFO:Fitting Model
2022-12-18 15:54:28,939:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(

2022-12-18 15:54:28,939:INFO:Scoring test/hold-out set
2022-12-18 15:54:29,305:INFO:Visual Rendered Successfully
2022-12-18 15:54:29,523:INFO:plot_model() successfully completed......................................
2022-12-18 15:54:32,188:INFO:Initializing tune_model()
2022-12-18 15:54:32,188:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>)
2022-12-18 15:54:32,189:INFO:Checking exceptions
2022-12-18 15:54:32,255:INFO:Copying training dataset
2022-12-18 15:54:32,262:INFO:Checking base model
2022-12-18 15:54:32,263:INFO:Base model : K Neighbors Classifier
2022-12-18 15:54:32,270:INFO:Declaring metric variables
2022-12-18 15:54:32,277:INFO:Defining Hyperparameters
2022-12-18 15:54:32,545:INFO:Tuning with n_jobs=-1
2022-12-18 15:54:32,545:INFO:Initializing RandomizedSearchCV
2022-12-18 15:54:34,606:INFO:best_params: {'actual_estimator__weights': 'distance', 'actual_estimator__n_neighbors': 49, 'actual_estimator__metric': 'euclidean'}
2022-12-18 15:54:34,607:INFO:Hyperparameter search completed
2022-12-18 15:54:34,607:INFO:SubProcess create_model() called ==================================
2022-12-18 15:54:34,608:INFO:Initializing create_model()
2022-12-18 15:54:34,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C42711C400>, model_only=True, return_train_score=False, kwargs={'weights': 'distance', 'n_neighbors': 49, 'metric': 'euclidean'})
2022-12-18 15:54:34,609:INFO:Checking exceptions
2022-12-18 15:54:34,612:INFO:Importing libraries
2022-12-18 15:54:34,613:INFO:Copying training dataset
2022-12-18 15:54:34,617:INFO:Defining folds
2022-12-18 15:54:34,617:INFO:Declaring metric variables
2022-12-18 15:54:34,622:INFO:Importing untrained model
2022-12-18 15:54:34,622:INFO:Declaring custom model
2022-12-18 15:54:34,627:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:54:34,638:INFO:Starting cross validation
2022-12-18 15:54:34,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:54:34,940:INFO:Calculating mean and std
2022-12-18 15:54:34,942:INFO:Creating metrics dataframe
2022-12-18 15:54:34,951:INFO:Finalizing model
2022-12-18 15:54:34,976:INFO:Uploading results into container
2022-12-18 15:54:34,977:INFO:Uploading model into container now
2022-12-18 15:54:34,979:INFO:master_model_container: 35
2022-12-18 15:54:34,979:INFO:display_container: 8
2022-12-18 15:54:34,980:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',
                     metric_params=None, n_jobs=-1, n_neighbors=49, p=2,
                     weights='distance')
2022-12-18 15:54:34,980:INFO:create_model() successfully completed......................................
2022-12-18 15:54:35,107:INFO:SubProcess create_model() end ==================================
2022-12-18 15:54:35,107:INFO:choose_better activated
2022-12-18 15:54:35,110:INFO:SubProcess create_model() called ==================================
2022-12-18 15:54:35,111:INFO:Initializing create_model()
2022-12-18 15:54:35,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-18 15:54:35,113:INFO:Checking exceptions
2022-12-18 15:54:35,119:INFO:Importing libraries
2022-12-18 15:54:35,119:INFO:Copying training dataset
2022-12-18 15:54:35,123:INFO:Defining folds
2022-12-18 15:54:35,123:INFO:Declaring metric variables
2022-12-18 15:54:35,124:INFO:Importing untrained model
2022-12-18 15:54:35,124:INFO:Declaring custom model
2022-12-18 15:54:35,125:INFO:K Neighbors Classifier Imported successfully
2022-12-18 15:54:35,125:INFO:Starting cross validation
2022-12-18 15:54:35,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-18 15:54:35,417:INFO:Calculating mean and std
2022-12-18 15:54:35,418:INFO:Creating metrics dataframe
2022-12-18 15:54:35,420:INFO:Finalizing model
2022-12-18 15:54:35,438:INFO:Uploading results into container
2022-12-18 15:54:35,439:INFO:Uploading model into container now
2022-12-18 15:54:35,439:INFO:master_model_container: 36
2022-12-18 15:54:35,439:INFO:display_container: 9
2022-12-18 15:54:35,440:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-18 15:54:35,440:INFO:create_model() successfully completed......................................
2022-12-18 15:54:35,556:INFO:SubProcess create_model() end ==================================
2022-12-18 15:54:35,557:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for Accuracy is 0.6207
2022-12-18 15:54:35,557:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',
                     metric_params=None, n_jobs=-1, n_neighbors=49, p=2,
                     weights='distance') result for Accuracy is 0.6233
2022-12-18 15:54:35,558:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',
                     metric_params=None, n_jobs=-1, n_neighbors=49, p=2,
                     weights='distance') is best model
2022-12-18 15:54:35,558:INFO:choose_better completed
2022-12-18 15:54:35,570:INFO:master_model_container: 36
2022-12-18 15:54:35,571:INFO:display_container: 8
2022-12-18 15:54:35,571:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',
                     metric_params=None, n_jobs=-1, n_neighbors=49, p=2,
                     weights='distance')
2022-12-18 15:54:35,572:INFO:tune_model() successfully completed......................................
2022-12-18 15:54:37,933:INFO:Initializing plot_model()
2022-12-18 15:54:37,933:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',
                     metric_params=None, n_jobs=-1, n_neighbors=49, p=2,
                     weights='distance'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C444264580>, system=True)
2022-12-18 15:54:37,933:INFO:Checking exceptions
2022-12-18 15:54:37,940:INFO:Preloading libraries
2022-12-18 15:54:37,941:INFO:Copying training dataset
2022-12-18 15:54:37,942:INFO:Plot type: learning
2022-12-18 15:54:38,027:INFO:Fitting Model
2022-12-18 15:54:39,470:INFO:Visual Rendered Successfully
2022-12-18 15:54:39,619:INFO:plot_model() successfully completed......................................
2022-12-18 15:54:42,450:INFO:Initializing save_model()
2022-12-18 15:54:42,450:INFO:save_model(model=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',
                     metric_params=None, n_jobs=-1, n_neighbors=49, p=2,
                     weights='distance'), model_name=forestfiremodel, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-12-18 15:54:42,451:INFO:Adding model into prep_pipe
2022-12-18 15:54:42,463:INFO:forestfiremodel.pkl saved in current working directory
2022-12-18 15:54:42,469:INFO:Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Trans...
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='euclidean', metric_params=None,
                                      n_jobs=-1, n_neighbors=49, p=2,
                                      weights='distance'))],
         verbose=False)
2022-12-18 15:54:42,470:INFO:save_model() successfully completed......................................
