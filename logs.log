2022-11-08 11:25:57,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:25:57,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:25:57,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:25:57,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-08 11:26:01,647:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-08 11:26:02,124:INFO:PyCaret RegressionExperiment
2022-11-08 11:26:02,124:INFO:Logging name: reg-default-name
2022-11-08 11:26:02,124:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-08 11:26:02,124:INFO:version 3.0.0.rc4
2022-11-08 11:26:02,124:INFO:Initializing setup()
2022-11-08 11:26:02,124:INFO:self.USI: c859
2022-11-08 11:26:02,124:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'transform_target_method_param', 'master_model_container', 'y_test', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:26:02,124:INFO:Checking environment
2022-11-08 11:26:02,124:INFO:python_version: 3.10.4
2022-11-08 11:26:02,125:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:26:02,125:INFO:machine: AMD64
2022-11-08 11:26:02,125:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:26:02,126:INFO:Memory: svmem(total=8503136256, available=1656168448, percent=80.5, used=6846967808, free=1656168448)
2022-11-08 11:26:02,126:INFO:Physical Core: 2
2022-11-08 11:26:02,126:INFO:Logical Core: 4
2022-11-08 11:26:02,126:INFO:Checking libraries
2022-11-08 11:26:02,126:INFO:System:
2022-11-08 11:26:02,126:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:26:02,127:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:26:02,127:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:26:02,127:INFO:PyCaret required dependencies:
2022-11-08 11:26:02,127:INFO:                 pip: 22.2.2
2022-11-08 11:26:02,127:INFO:          setuptools: 58.1.0
2022-11-08 11:26:02,127:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:26:02,127:INFO:             IPython: 8.4.0
2022-11-08 11:26:02,127:INFO:          ipywidgets: 8.0.2
2022-11-08 11:26:02,127:INFO:                tqdm: 4.64.0
2022-11-08 11:26:02,127:INFO:               numpy: 1.22.3
2022-11-08 11:26:02,127:INFO:              pandas: 1.4.2
2022-11-08 11:26:02,127:INFO:              jinja2: 3.1.2
2022-11-08 11:26:02,127:INFO:               scipy: 1.8.1
2022-11-08 11:26:02,127:INFO:              joblib: 1.2.0
2022-11-08 11:26:02,127:INFO:             sklearn: 1.1.2
2022-11-08 11:26:02,127:INFO:                pyod: 1.0.6
2022-11-08 11:26:02,127:INFO:            imblearn: 0.9.1
2022-11-08 11:26:02,127:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:26:02,129:INFO:            lightgbm: 3.3.3
2022-11-08 11:26:02,129:INFO:               numba: 0.55.2
2022-11-08 11:26:02,129:INFO:            requests: 2.28.1
2022-11-08 11:26:02,129:INFO:          matplotlib: 3.5.1
2022-11-08 11:26:02,129:INFO:          scikitplot: 0.3.7
2022-11-08 11:26:02,129:INFO:         yellowbrick: 1.5
2022-11-08 11:26:02,129:INFO:              plotly: 5.11.0
2022-11-08 11:26:02,129:INFO:             kaleido: 0.2.1
2022-11-08 11:26:02,129:INFO:         statsmodels: 0.13.5
2022-11-08 11:26:02,129:INFO:              sktime: 0.13.4
2022-11-08 11:26:02,129:INFO:               tbats: 1.1.1
2022-11-08 11:26:02,129:INFO:            pmdarima: 1.8.5
2022-11-08 11:26:02,130:INFO:              psutil: 5.9.1
2022-11-08 11:26:02,130:INFO:PyCaret optional dependencies:
2022-11-08 11:26:02,157:INFO:                shap: Not installed
2022-11-08 11:26:02,157:INFO:           interpret: Not installed
2022-11-08 11:26:02,157:INFO:                umap: Not installed
2022-11-08 11:26:02,158:INFO:    pandas_profiling: Not installed
2022-11-08 11:26:02,158:INFO:  explainerdashboard: Not installed
2022-11-08 11:26:02,158:INFO:             autoviz: Not installed
2022-11-08 11:26:02,158:INFO:           fairlearn: Not installed
2022-11-08 11:26:02,158:INFO:             xgboost: Not installed
2022-11-08 11:26:02,158:INFO:            catboost: Not installed
2022-11-08 11:26:02,158:INFO:              kmodes: Not installed
2022-11-08 11:26:02,158:INFO:             mlxtend: Not installed
2022-11-08 11:26:02,158:INFO:       statsforecast: Not installed
2022-11-08 11:26:02,158:INFO:        tune_sklearn: Not installed
2022-11-08 11:26:02,158:INFO:                 ray: Not installed
2022-11-08 11:26:02,158:INFO:            hyperopt: Not installed
2022-11-08 11:26:02,158:INFO:              optuna: Not installed
2022-11-08 11:26:02,158:INFO:               skopt: Not installed
2022-11-08 11:26:02,158:INFO:              mlflow: Not installed
2022-11-08 11:26:02,158:INFO:              gradio: Not installed
2022-11-08 11:26:02,158:INFO:             fastapi: Not installed
2022-11-08 11:26:02,158:INFO:             uvicorn: Not installed
2022-11-08 11:26:02,158:INFO:              m2cgen: Not installed
2022-11-08 11:26:02,158:INFO:           evidently: Not installed
2022-11-08 11:26:02,158:INFO:                nltk: 3.7
2022-11-08 11:26:02,158:INFO:            pyLDAvis: Not installed
2022-11-08 11:26:02,158:INFO:              gensim: Not installed
2022-11-08 11:26:02,158:INFO:               spacy: Not installed
2022-11-08 11:26:02,158:INFO:           wordcloud: Not installed
2022-11-08 11:26:02,158:INFO:            textblob: Not installed
2022-11-08 11:26:02,158:INFO:               fugue: Not installed
2022-11-08 11:26:02,158:INFO:           streamlit: Not installed
2022-11-08 11:26:02,158:INFO:             prophet: Not installed
2022-11-08 11:26:02,158:INFO:None
2022-11-08 11:26:02,158:INFO:Set up data.
2022-11-08 11:26:02,186:INFO:Set up train/test split.
2022-11-08 11:26:02,217:INFO:Set up index.
2022-11-08 11:26:02,218:INFO:Set up folding strategy.
2022-11-08 11:26:02,218:INFO:Assigning column types.
2022-11-08 11:26:02,218:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:26:02,224:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,239:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,447:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,459:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,588:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-08 11:26:02,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,738:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,745:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:02,877:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-08 11:26:02,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:02,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,168:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-08 11:26:03,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,461:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:26:03,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:03,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,746:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-08 11:26:03,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:03,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,034:INFO:Preparing preprocessing pipeline...
2022-11-08 11:26:04,035:INFO:Set up simple imputation.
2022-11-08 11:26:04,035:INFO:Set up variance threshold.
2022-11-08 11:26:04,095:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:26:04,099:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-08 11:26:04,099:INFO:Creating final display dataframe.
2022-11-08 11:26:04,357:INFO:Setup display_container:                Description             Value
0               Session id              4545
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              c859
2022-11-08 11:26:04,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:04,716:INFO:setup() successfully completed in 2.6s...............
2022-11-08 11:26:35,568:INFO:PyCaret RegressionExperiment
2022-11-08 11:26:35,568:INFO:Logging name: reg-default-name
2022-11-08 11:26:35,568:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-08 11:26:35,568:INFO:version 3.0.0.rc4
2022-11-08 11:26:35,568:INFO:Initializing setup()
2022-11-08 11:26:35,568:INFO:self.USI: a163
2022-11-08 11:26:35,568:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'transform_target_method_param', 'master_model_container', 'y_test', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:26:35,568:INFO:Checking environment
2022-11-08 11:26:35,568:INFO:python_version: 3.10.4
2022-11-08 11:26:35,568:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:26:35,568:INFO:machine: AMD64
2022-11-08 11:26:35,568:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:26:35,576:INFO:Memory: svmem(total=8503136256, available=1827471360, percent=78.5, used=6675664896, free=1827471360)
2022-11-08 11:26:35,576:INFO:Physical Core: 2
2022-11-08 11:26:35,576:INFO:Logical Core: 4
2022-11-08 11:26:35,576:INFO:Checking libraries
2022-11-08 11:26:35,576:INFO:System:
2022-11-08 11:26:35,576:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:26:35,576:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:26:35,576:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:26:35,576:INFO:PyCaret required dependencies:
2022-11-08 11:26:35,576:INFO:                 pip: 22.2.2
2022-11-08 11:26:35,576:INFO:          setuptools: 58.1.0
2022-11-08 11:26:35,576:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:26:35,576:INFO:             IPython: 8.4.0
2022-11-08 11:26:35,576:INFO:          ipywidgets: 8.0.2
2022-11-08 11:26:35,576:INFO:                tqdm: 4.64.0
2022-11-08 11:26:35,576:INFO:               numpy: 1.22.3
2022-11-08 11:26:35,576:INFO:              pandas: 1.4.2
2022-11-08 11:26:35,576:INFO:              jinja2: 3.1.2
2022-11-08 11:26:35,576:INFO:               scipy: 1.8.1
2022-11-08 11:26:35,576:INFO:              joblib: 1.2.0
2022-11-08 11:26:35,581:INFO:             sklearn: 1.1.2
2022-11-08 11:26:35,581:INFO:                pyod: 1.0.6
2022-11-08 11:26:35,581:INFO:            imblearn: 0.9.1
2022-11-08 11:26:35,581:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:26:35,581:INFO:            lightgbm: 3.3.3
2022-11-08 11:26:35,581:INFO:               numba: 0.55.2
2022-11-08 11:26:35,581:INFO:            requests: 2.28.1
2022-11-08 11:26:35,581:INFO:          matplotlib: 3.5.1
2022-11-08 11:26:35,581:INFO:          scikitplot: 0.3.7
2022-11-08 11:26:35,581:INFO:         yellowbrick: 1.5
2022-11-08 11:26:35,581:INFO:              plotly: 5.11.0
2022-11-08 11:26:35,581:INFO:             kaleido: 0.2.1
2022-11-08 11:26:35,581:INFO:         statsmodels: 0.13.5
2022-11-08 11:26:35,581:INFO:              sktime: 0.13.4
2022-11-08 11:26:35,581:INFO:               tbats: 1.1.1
2022-11-08 11:26:35,581:INFO:            pmdarima: 1.8.5
2022-11-08 11:26:35,581:INFO:              psutil: 5.9.1
2022-11-08 11:26:35,581:INFO:PyCaret optional dependencies:
2022-11-08 11:26:35,581:INFO:                shap: Not installed
2022-11-08 11:26:35,581:INFO:           interpret: Not installed
2022-11-08 11:26:35,581:INFO:                umap: Not installed
2022-11-08 11:26:35,581:INFO:    pandas_profiling: Not installed
2022-11-08 11:26:35,581:INFO:  explainerdashboard: Not installed
2022-11-08 11:26:35,581:INFO:             autoviz: Not installed
2022-11-08 11:26:35,581:INFO:           fairlearn: Not installed
2022-11-08 11:26:35,581:INFO:             xgboost: Not installed
2022-11-08 11:26:35,581:INFO:            catboost: Not installed
2022-11-08 11:26:35,581:INFO:              kmodes: Not installed
2022-11-08 11:26:35,581:INFO:             mlxtend: Not installed
2022-11-08 11:26:35,581:INFO:       statsforecast: Not installed
2022-11-08 11:26:35,581:INFO:        tune_sklearn: Not installed
2022-11-08 11:26:35,581:INFO:                 ray: Not installed
2022-11-08 11:26:35,581:INFO:            hyperopt: Not installed
2022-11-08 11:26:35,581:INFO:              optuna: Not installed
2022-11-08 11:26:35,586:INFO:               skopt: Not installed
2022-11-08 11:26:35,586:INFO:              mlflow: Not installed
2022-11-08 11:26:35,586:INFO:              gradio: Not installed
2022-11-08 11:26:35,586:INFO:             fastapi: Not installed
2022-11-08 11:26:35,586:INFO:             uvicorn: Not installed
2022-11-08 11:26:35,586:INFO:              m2cgen: Not installed
2022-11-08 11:26:35,586:INFO:           evidently: Not installed
2022-11-08 11:26:35,586:INFO:                nltk: 3.7
2022-11-08 11:26:35,586:INFO:            pyLDAvis: Not installed
2022-11-08 11:26:35,586:INFO:              gensim: Not installed
2022-11-08 11:26:35,586:INFO:               spacy: Not installed
2022-11-08 11:26:35,586:INFO:           wordcloud: Not installed
2022-11-08 11:26:35,586:INFO:            textblob: Not installed
2022-11-08 11:26:35,586:INFO:               fugue: Not installed
2022-11-08 11:26:35,586:INFO:           streamlit: Not installed
2022-11-08 11:26:35,586:INFO:             prophet: Not installed
2022-11-08 11:26:35,586:INFO:None
2022-11-08 11:26:35,586:INFO:Set up data.
2022-11-08 11:26:35,601:INFO:Set up train/test split.
2022-11-08 11:26:35,610:INFO:Set up index.
2022-11-08 11:26:35,610:INFO:Set up folding strategy.
2022-11-08 11:26:35,612:INFO:Assigning column types.
2022-11-08 11:26:35,619:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:26:35,619:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,636:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,645:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:35,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:35,833:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,843:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:35,856:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,144:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-08 11:26:36,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,498:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-08 11:26:36,518:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,806:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-08 11:26:36,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:36,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:36,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,097:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:26:37,179:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:26:37,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,388:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-08 11:26:37,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:37,683:INFO:Preparing preprocessing pipeline...
2022-11-08 11:26:37,684:INFO:Set up simple imputation.
2022-11-08 11:26:37,684:INFO:Set up variance threshold.
2022-11-08 11:26:37,737:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:26:37,746:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-08 11:26:37,746:INFO:Creating final display dataframe.
2022-11-08 11:26:38,013:INFO:Setup display_container:                Description             Value
0               Session id              7997
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              a163
2022-11-08 11:26:38,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:26:38,368:INFO:setup() successfully completed in 2.8s...............
2022-11-08 11:26:56,151:INFO:Initializing compare_models()
2022-11-08 11:26:56,151:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-08 11:26:56,151:INFO:Checking exceptions
2022-11-08 11:26:56,151:INFO:Preparing display monitor
2022-11-08 11:26:56,243:INFO:Initializing Linear Regression
2022-11-08 11:26:56,243:INFO:Total runtime is 0.0 minutes
2022-11-08 11:26:56,249:INFO:SubProcess create_model() called ==================================
2022-11-08 11:26:56,249:INFO:Initializing create_model()
2022-11-08 11:26:56,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:26:56,250:INFO:Checking exceptions
2022-11-08 11:26:56,253:INFO:Importing libraries
2022-11-08 11:26:56,253:INFO:Copying training dataset
2022-11-08 11:26:56,259:INFO:Defining folds
2022-11-08 11:26:56,259:INFO:Declaring metric variables
2022-11-08 11:26:56,270:INFO:Importing untrained model
2022-11-08 11:26:56,280:INFO:Linear Regression Imported successfully
2022-11-08 11:26:56,293:INFO:Starting cross validation
2022-11-08 11:26:56,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:04,746:INFO:Calculating mean and std
2022-11-08 11:27:04,748:INFO:Creating metrics dataframe
2022-11-08 11:27:04,753:INFO:Uploading results into container
2022-11-08 11:27:04,753:INFO:Uploading model into container now
2022-11-08 11:27:04,754:INFO:master_model_container: 1
2022-11-08 11:27:04,754:INFO:display_container: 2
2022-11-08 11:27:04,754:INFO:LinearRegression(n_jobs=-1)
2022-11-08 11:27:04,754:INFO:create_model() successfully completed......................................
2022-11-08 11:27:04,870:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:04,870:INFO:Creating metrics dataframe
2022-11-08 11:27:04,890:INFO:Initializing Lasso Regression
2022-11-08 11:27:04,891:INFO:Total runtime is 0.14414142370223998 minutes
2022-11-08 11:27:04,896:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:04,898:INFO:Initializing create_model()
2022-11-08 11:27:04,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:04,898:INFO:Checking exceptions
2022-11-08 11:27:04,902:INFO:Importing libraries
2022-11-08 11:27:04,902:INFO:Copying training dataset
2022-11-08 11:27:04,912:INFO:Defining folds
2022-11-08 11:27:04,912:INFO:Declaring metric variables
2022-11-08 11:27:04,920:INFO:Importing untrained model
2022-11-08 11:27:04,928:INFO:Lasso Regression Imported successfully
2022-11-08 11:27:04,946:INFO:Starting cross validation
2022-11-08 11:27:04,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:05,257:INFO:Calculating mean and std
2022-11-08 11:27:05,259:INFO:Creating metrics dataframe
2022-11-08 11:27:05,262:INFO:Uploading results into container
2022-11-08 11:27:05,263:INFO:Uploading model into container now
2022-11-08 11:27:05,263:INFO:master_model_container: 2
2022-11-08 11:27:05,263:INFO:display_container: 2
2022-11-08 11:27:05,264:INFO:Lasso(random_state=7997)
2022-11-08 11:27:05,264:INFO:create_model() successfully completed......................................
2022-11-08 11:27:05,378:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:05,378:INFO:Creating metrics dataframe
2022-11-08 11:27:05,391:INFO:Initializing Ridge Regression
2022-11-08 11:27:05,391:INFO:Total runtime is 0.1524614373842875 minutes
2022-11-08 11:27:05,396:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:05,396:INFO:Initializing create_model()
2022-11-08 11:27:05,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:05,397:INFO:Checking exceptions
2022-11-08 11:27:05,401:INFO:Importing libraries
2022-11-08 11:27:05,402:INFO:Copying training dataset
2022-11-08 11:27:05,406:INFO:Defining folds
2022-11-08 11:27:05,406:INFO:Declaring metric variables
2022-11-08 11:27:05,410:INFO:Importing untrained model
2022-11-08 11:27:05,419:INFO:Ridge Regression Imported successfully
2022-11-08 11:27:05,438:INFO:Starting cross validation
2022-11-08 11:27:05,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:05,639:INFO:Calculating mean and std
2022-11-08 11:27:05,641:INFO:Creating metrics dataframe
2022-11-08 11:27:05,645:INFO:Uploading results into container
2022-11-08 11:27:05,646:INFO:Uploading model into container now
2022-11-08 11:27:05,647:INFO:master_model_container: 3
2022-11-08 11:27:05,647:INFO:display_container: 2
2022-11-08 11:27:05,648:INFO:Ridge(random_state=7997)
2022-11-08 11:27:05,649:INFO:create_model() successfully completed......................................
2022-11-08 11:27:05,756:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:05,756:INFO:Creating metrics dataframe
2022-11-08 11:27:05,769:INFO:Initializing Elastic Net
2022-11-08 11:27:05,769:INFO:Total runtime is 0.15877500375111897 minutes
2022-11-08 11:27:05,774:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:05,775:INFO:Initializing create_model()
2022-11-08 11:27:05,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:05,775:INFO:Checking exceptions
2022-11-08 11:27:05,777:INFO:Importing libraries
2022-11-08 11:27:05,778:INFO:Copying training dataset
2022-11-08 11:27:05,783:INFO:Defining folds
2022-11-08 11:27:05,783:INFO:Declaring metric variables
2022-11-08 11:27:05,789:INFO:Importing untrained model
2022-11-08 11:27:05,797:INFO:Elastic Net Imported successfully
2022-11-08 11:27:05,812:INFO:Starting cross validation
2022-11-08 11:27:05,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:06,019:INFO:Calculating mean and std
2022-11-08 11:27:06,021:INFO:Creating metrics dataframe
2022-11-08 11:27:06,025:INFO:Uploading results into container
2022-11-08 11:27:06,026:INFO:Uploading model into container now
2022-11-08 11:27:06,026:INFO:master_model_container: 4
2022-11-08 11:27:06,026:INFO:display_container: 2
2022-11-08 11:27:06,027:INFO:ElasticNet(random_state=7997)
2022-11-08 11:27:06,027:INFO:create_model() successfully completed......................................
2022-11-08 11:27:06,133:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:06,134:INFO:Creating metrics dataframe
2022-11-08 11:27:06,147:INFO:Initializing Least Angle Regression
2022-11-08 11:27:06,147:INFO:Total runtime is 0.16507114966710407 minutes
2022-11-08 11:27:06,153:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:06,154:INFO:Initializing create_model()
2022-11-08 11:27:06,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:06,154:INFO:Checking exceptions
2022-11-08 11:27:06,157:INFO:Importing libraries
2022-11-08 11:27:06,157:INFO:Copying training dataset
2022-11-08 11:27:06,161:INFO:Defining folds
2022-11-08 11:27:06,162:INFO:Declaring metric variables
2022-11-08 11:27:06,173:INFO:Importing untrained model
2022-11-08 11:27:06,180:INFO:Least Angle Regression Imported successfully
2022-11-08 11:27:06,197:INFO:Starting cross validation
2022-11-08 11:27:06,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:06,266:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,271:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,285:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,296:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,328:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,336:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,351:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,358:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,389:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,389:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:06,411:INFO:Calculating mean and std
2022-11-08 11:27:06,412:INFO:Creating metrics dataframe
2022-11-08 11:27:06,417:INFO:Uploading results into container
2022-11-08 11:27:06,418:INFO:Uploading model into container now
2022-11-08 11:27:06,418:INFO:master_model_container: 5
2022-11-08 11:27:06,418:INFO:display_container: 2
2022-11-08 11:27:06,419:INFO:Lars(random_state=7997)
2022-11-08 11:27:06,419:INFO:create_model() successfully completed......................................
2022-11-08 11:27:06,524:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:06,525:INFO:Creating metrics dataframe
2022-11-08 11:27:06,540:INFO:Initializing Lasso Least Angle Regression
2022-11-08 11:27:06,541:INFO:Total runtime is 0.1716353933016459 minutes
2022-11-08 11:27:06,546:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:06,547:INFO:Initializing create_model()
2022-11-08 11:27:06,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:06,547:INFO:Checking exceptions
2022-11-08 11:27:06,551:INFO:Importing libraries
2022-11-08 11:27:06,551:INFO:Copying training dataset
2022-11-08 11:27:06,556:INFO:Defining folds
2022-11-08 11:27:06,556:INFO:Declaring metric variables
2022-11-08 11:27:06,561:INFO:Importing untrained model
2022-11-08 11:27:06,568:INFO:Lasso Least Angle Regression Imported successfully
2022-11-08 11:27:06,586:INFO:Starting cross validation
2022-11-08 11:27:06,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:06,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,661:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,672:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,686:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,716:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,726:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,738:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,746:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,755:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,769:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:27:06,787:INFO:Calculating mean and std
2022-11-08 11:27:06,788:INFO:Creating metrics dataframe
2022-11-08 11:27:06,792:INFO:Uploading results into container
2022-11-08 11:27:06,792:INFO:Uploading model into container now
2022-11-08 11:27:06,793:INFO:master_model_container: 6
2022-11-08 11:27:06,793:INFO:display_container: 2
2022-11-08 11:27:06,794:INFO:LassoLars(random_state=7997)
2022-11-08 11:27:06,794:INFO:create_model() successfully completed......................................
2022-11-08 11:27:06,901:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:06,901:INFO:Creating metrics dataframe
2022-11-08 11:27:06,917:INFO:Initializing Orthogonal Matching Pursuit
2022-11-08 11:27:06,917:INFO:Total runtime is 0.17789403200149534 minutes
2022-11-08 11:27:06,923:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:06,923:INFO:Initializing create_model()
2022-11-08 11:27:06,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:06,923:INFO:Checking exceptions
2022-11-08 11:27:06,925:INFO:Importing libraries
2022-11-08 11:27:06,925:INFO:Copying training dataset
2022-11-08 11:27:06,933:INFO:Defining folds
2022-11-08 11:27:06,933:INFO:Declaring metric variables
2022-11-08 11:27:06,939:INFO:Importing untrained model
2022-11-08 11:27:06,950:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-08 11:27:06,967:INFO:Starting cross validation
2022-11-08 11:27:06,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:07,026:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,042:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,056:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,086:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,101:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,116:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,126:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,151:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,158:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,168:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:27:07,184:INFO:Calculating mean and std
2022-11-08 11:27:07,186:INFO:Creating metrics dataframe
2022-11-08 11:27:07,190:INFO:Uploading results into container
2022-11-08 11:27:07,191:INFO:Uploading model into container now
2022-11-08 11:27:07,191:INFO:master_model_container: 7
2022-11-08 11:27:07,191:INFO:display_container: 2
2022-11-08 11:27:07,192:INFO:OrthogonalMatchingPursuit()
2022-11-08 11:27:07,192:INFO:create_model() successfully completed......................................
2022-11-08 11:27:07,297:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:07,297:INFO:Creating metrics dataframe
2022-11-08 11:27:07,311:INFO:Initializing Bayesian Ridge
2022-11-08 11:27:07,312:INFO:Total runtime is 0.18449139992396035 minutes
2022-11-08 11:27:07,318:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:07,319:INFO:Initializing create_model()
2022-11-08 11:27:07,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:07,320:INFO:Checking exceptions
2022-11-08 11:27:07,323:INFO:Importing libraries
2022-11-08 11:27:07,323:INFO:Copying training dataset
2022-11-08 11:27:07,328:INFO:Defining folds
2022-11-08 11:27:07,328:INFO:Declaring metric variables
2022-11-08 11:27:07,334:INFO:Importing untrained model
2022-11-08 11:27:07,344:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:27:07,361:INFO:Starting cross validation
2022-11-08 11:27:07,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:07,581:INFO:Calculating mean and std
2022-11-08 11:27:07,583:INFO:Creating metrics dataframe
2022-11-08 11:27:07,586:INFO:Uploading results into container
2022-11-08 11:27:07,587:INFO:Uploading model into container now
2022-11-08 11:27:07,588:INFO:master_model_container: 8
2022-11-08 11:27:07,588:INFO:display_container: 2
2022-11-08 11:27:07,589:INFO:BayesianRidge()
2022-11-08 11:27:07,589:INFO:create_model() successfully completed......................................
2022-11-08 11:27:07,687:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:07,695:INFO:Creating metrics dataframe
2022-11-08 11:27:07,710:INFO:Initializing Passive Aggressive Regressor
2022-11-08 11:27:07,710:INFO:Total runtime is 0.1911191940307617 minutes
2022-11-08 11:27:07,717:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:07,717:INFO:Initializing create_model()
2022-11-08 11:27:07,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:07,718:INFO:Checking exceptions
2022-11-08 11:27:07,721:INFO:Importing libraries
2022-11-08 11:27:07,721:INFO:Copying training dataset
2022-11-08 11:27:07,727:INFO:Defining folds
2022-11-08 11:27:07,727:INFO:Declaring metric variables
2022-11-08 11:27:07,733:INFO:Importing untrained model
2022-11-08 11:27:07,742:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:27:07,759:INFO:Starting cross validation
2022-11-08 11:27:07,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:07,959:INFO:Calculating mean and std
2022-11-08 11:27:07,961:INFO:Creating metrics dataframe
2022-11-08 11:27:07,965:INFO:Uploading results into container
2022-11-08 11:27:07,966:INFO:Uploading model into container now
2022-11-08 11:27:07,967:INFO:master_model_container: 9
2022-11-08 11:27:07,967:INFO:display_container: 2
2022-11-08 11:27:07,968:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:27:07,968:INFO:create_model() successfully completed......................................
2022-11-08 11:27:08,075:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:08,075:INFO:Creating metrics dataframe
2022-11-08 11:27:08,090:INFO:Initializing Huber Regressor
2022-11-08 11:27:08,090:INFO:Total runtime is 0.19745233853658037 minutes
2022-11-08 11:27:08,095:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:08,096:INFO:Initializing create_model()
2022-11-08 11:27:08,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:08,096:INFO:Checking exceptions
2022-11-08 11:27:08,100:INFO:Importing libraries
2022-11-08 11:27:08,100:INFO:Copying training dataset
2022-11-08 11:27:08,105:INFO:Defining folds
2022-11-08 11:27:08,106:INFO:Declaring metric variables
2022-11-08 11:27:08,111:INFO:Importing untrained model
2022-11-08 11:27:08,119:INFO:Huber Regressor Imported successfully
2022-11-08 11:27:08,135:INFO:Starting cross validation
2022-11-08 11:27:08,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:08,275:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,286:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,291:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,386:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,386:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,397:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,411:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,470:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,470:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:08,491:INFO:Calculating mean and std
2022-11-08 11:27:08,492:INFO:Creating metrics dataframe
2022-11-08 11:27:08,498:INFO:Uploading results into container
2022-11-08 11:27:08,499:INFO:Uploading model into container now
2022-11-08 11:27:08,499:INFO:master_model_container: 10
2022-11-08 11:27:08,499:INFO:display_container: 2
2022-11-08 11:27:08,500:INFO:HuberRegressor()
2022-11-08 11:27:08,500:INFO:create_model() successfully completed......................................
2022-11-08 11:27:08,602:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:08,602:INFO:Creating metrics dataframe
2022-11-08 11:27:08,620:INFO:Initializing K Neighbors Regressor
2022-11-08 11:27:08,621:INFO:Total runtime is 0.20630602041880286 minutes
2022-11-08 11:27:08,625:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:08,625:INFO:Initializing create_model()
2022-11-08 11:27:08,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:08,626:INFO:Checking exceptions
2022-11-08 11:27:08,631:INFO:Importing libraries
2022-11-08 11:27:08,632:INFO:Copying training dataset
2022-11-08 11:27:08,636:INFO:Defining folds
2022-11-08 11:27:08,636:INFO:Declaring metric variables
2022-11-08 11:27:08,643:INFO:Importing untrained model
2022-11-08 11:27:08,649:INFO:K Neighbors Regressor Imported successfully
2022-11-08 11:27:08,671:INFO:Starting cross validation
2022-11-08 11:27:08,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:08,924:INFO:Calculating mean and std
2022-11-08 11:27:08,926:INFO:Creating metrics dataframe
2022-11-08 11:27:08,933:INFO:Uploading results into container
2022-11-08 11:27:08,934:INFO:Uploading model into container now
2022-11-08 11:27:08,934:INFO:master_model_container: 11
2022-11-08 11:27:08,934:INFO:display_container: 2
2022-11-08 11:27:08,935:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-08 11:27:08,935:INFO:create_model() successfully completed......................................
2022-11-08 11:27:09,053:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:09,053:INFO:Creating metrics dataframe
2022-11-08 11:27:09,073:INFO:Initializing Decision Tree Regressor
2022-11-08 11:27:09,073:INFO:Total runtime is 0.213830022017161 minutes
2022-11-08 11:27:09,078:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:09,078:INFO:Initializing create_model()
2022-11-08 11:27:09,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:09,079:INFO:Checking exceptions
2022-11-08 11:27:09,083:INFO:Importing libraries
2022-11-08 11:27:09,083:INFO:Copying training dataset
2022-11-08 11:27:09,088:INFO:Defining folds
2022-11-08 11:27:09,088:INFO:Declaring metric variables
2022-11-08 11:27:09,092:INFO:Importing untrained model
2022-11-08 11:27:09,102:INFO:Decision Tree Regressor Imported successfully
2022-11-08 11:27:09,116:INFO:Starting cross validation
2022-11-08 11:27:09,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:09,334:INFO:Calculating mean and std
2022-11-08 11:27:09,337:INFO:Creating metrics dataframe
2022-11-08 11:27:09,341:INFO:Uploading results into container
2022-11-08 11:27:09,342:INFO:Uploading model into container now
2022-11-08 11:27:09,342:INFO:master_model_container: 12
2022-11-08 11:27:09,343:INFO:display_container: 2
2022-11-08 11:27:09,343:INFO:DecisionTreeRegressor(random_state=7997)
2022-11-08 11:27:09,343:INFO:create_model() successfully completed......................................
2022-11-08 11:27:09,451:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:09,451:INFO:Creating metrics dataframe
2022-11-08 11:27:09,468:INFO:Initializing Random Forest Regressor
2022-11-08 11:27:09,469:INFO:Total runtime is 0.22043606042861932 minutes
2022-11-08 11:27:09,474:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:09,474:INFO:Initializing create_model()
2022-11-08 11:27:09,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:09,474:INFO:Checking exceptions
2022-11-08 11:27:09,477:INFO:Importing libraries
2022-11-08 11:27:09,477:INFO:Copying training dataset
2022-11-08 11:27:09,485:INFO:Defining folds
2022-11-08 11:27:09,485:INFO:Declaring metric variables
2022-11-08 11:27:09,494:INFO:Importing untrained model
2022-11-08 11:27:09,502:INFO:Random Forest Regressor Imported successfully
2022-11-08 11:27:09,521:INFO:Starting cross validation
2022-11-08 11:27:09,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:10,958:INFO:Calculating mean and std
2022-11-08 11:27:10,960:INFO:Creating metrics dataframe
2022-11-08 11:27:10,966:INFO:Uploading results into container
2022-11-08 11:27:10,967:INFO:Uploading model into container now
2022-11-08 11:27:10,967:INFO:master_model_container: 13
2022-11-08 11:27:10,967:INFO:display_container: 2
2022-11-08 11:27:10,968:INFO:RandomForestRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:27:10,969:INFO:create_model() successfully completed......................................
2022-11-08 11:27:11,088:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:11,088:INFO:Creating metrics dataframe
2022-11-08 11:27:11,110:INFO:Initializing Extra Trees Regressor
2022-11-08 11:27:11,110:INFO:Total runtime is 0.24777800639470413 minutes
2022-11-08 11:27:11,120:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:11,121:INFO:Initializing create_model()
2022-11-08 11:27:11,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:11,122:INFO:Checking exceptions
2022-11-08 11:27:11,125:INFO:Importing libraries
2022-11-08 11:27:11,125:INFO:Copying training dataset
2022-11-08 11:27:11,133:INFO:Defining folds
2022-11-08 11:27:11,134:INFO:Declaring metric variables
2022-11-08 11:27:11,141:INFO:Importing untrained model
2022-11-08 11:27:11,155:INFO:Extra Trees Regressor Imported successfully
2022-11-08 11:27:11,171:INFO:Starting cross validation
2022-11-08 11:27:11,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:12,166:INFO:Calculating mean and std
2022-11-08 11:27:12,167:INFO:Creating metrics dataframe
2022-11-08 11:27:12,171:INFO:Uploading results into container
2022-11-08 11:27:12,171:INFO:Uploading model into container now
2022-11-08 11:27:12,172:INFO:master_model_container: 14
2022-11-08 11:27:12,172:INFO:display_container: 2
2022-11-08 11:27:12,172:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:27:12,172:INFO:create_model() successfully completed......................................
2022-11-08 11:27:12,291:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:12,291:INFO:Creating metrics dataframe
2022-11-08 11:27:12,312:INFO:Initializing AdaBoost Regressor
2022-11-08 11:27:12,312:INFO:Total runtime is 0.26781946023305253 minutes
2022-11-08 11:27:12,317:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:12,317:INFO:Initializing create_model()
2022-11-08 11:27:12,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:12,318:INFO:Checking exceptions
2022-11-08 11:27:12,321:INFO:Importing libraries
2022-11-08 11:27:12,322:INFO:Copying training dataset
2022-11-08 11:27:12,330:INFO:Defining folds
2022-11-08 11:27:12,330:INFO:Declaring metric variables
2022-11-08 11:27:12,337:INFO:Importing untrained model
2022-11-08 11:27:12,344:INFO:AdaBoost Regressor Imported successfully
2022-11-08 11:27:12,359:INFO:Starting cross validation
2022-11-08 11:27:12,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:12,895:INFO:Calculating mean and std
2022-11-08 11:27:12,896:INFO:Creating metrics dataframe
2022-11-08 11:27:12,900:INFO:Uploading results into container
2022-11-08 11:27:12,900:INFO:Uploading model into container now
2022-11-08 11:27:12,901:INFO:master_model_container: 15
2022-11-08 11:27:12,901:INFO:display_container: 2
2022-11-08 11:27:12,901:INFO:AdaBoostRegressor(random_state=7997)
2022-11-08 11:27:12,901:INFO:create_model() successfully completed......................................
2022-11-08 11:27:13,006:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:13,006:INFO:Creating metrics dataframe
2022-11-08 11:27:13,045:INFO:Initializing Gradient Boosting Regressor
2022-11-08 11:27:13,045:INFO:Total runtime is 0.2800426681836446 minutes
2022-11-08 11:27:13,051:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:13,056:INFO:Initializing create_model()
2022-11-08 11:27:13,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:13,056:INFO:Checking exceptions
2022-11-08 11:27:13,056:INFO:Importing libraries
2022-11-08 11:27:13,061:INFO:Copying training dataset
2022-11-08 11:27:13,069:INFO:Defining folds
2022-11-08 11:27:13,069:INFO:Declaring metric variables
2022-11-08 11:27:13,076:INFO:Importing untrained model
2022-11-08 11:27:13,101:INFO:Gradient Boosting Regressor Imported successfully
2022-11-08 11:27:13,111:INFO:Starting cross validation
2022-11-08 11:27:13,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:13,847:INFO:Calculating mean and std
2022-11-08 11:27:13,848:INFO:Creating metrics dataframe
2022-11-08 11:27:13,859:INFO:Uploading results into container
2022-11-08 11:27:13,862:INFO:Uploading model into container now
2022-11-08 11:27:13,862:INFO:master_model_container: 16
2022-11-08 11:27:13,863:INFO:display_container: 2
2022-11-08 11:27:13,864:INFO:GradientBoostingRegressor(random_state=7997)
2022-11-08 11:27:13,864:INFO:create_model() successfully completed......................................
2022-11-08 11:27:14,011:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:14,011:INFO:Creating metrics dataframe
2022-11-08 11:27:14,060:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:27:14,060:INFO:Total runtime is 0.2969590703646342 minutes
2022-11-08 11:27:14,077:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:14,077:INFO:Initializing create_model()
2022-11-08 11:27:14,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:14,077:INFO:Checking exceptions
2022-11-08 11:27:14,088:INFO:Importing libraries
2022-11-08 11:27:14,088:INFO:Copying training dataset
2022-11-08 11:27:14,111:INFO:Defining folds
2022-11-08 11:27:14,111:INFO:Declaring metric variables
2022-11-08 11:27:14,128:INFO:Importing untrained model
2022-11-08 11:27:14,146:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:27:14,177:INFO:Starting cross validation
2022-11-08 11:27:14,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:14,698:INFO:Calculating mean and std
2022-11-08 11:27:14,708:INFO:Creating metrics dataframe
2022-11-08 11:27:14,718:INFO:Uploading results into container
2022-11-08 11:27:14,718:INFO:Uploading model into container now
2022-11-08 11:27:14,718:INFO:master_model_container: 17
2022-11-08 11:27:14,718:INFO:display_container: 2
2022-11-08 11:27:14,718:INFO:LGBMRegressor(random_state=7997)
2022-11-08 11:27:14,718:INFO:create_model() successfully completed......................................
2022-11-08 11:27:14,875:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:14,875:INFO:Creating metrics dataframe
2022-11-08 11:27:14,899:INFO:Initializing Dummy Regressor
2022-11-08 11:27:14,899:INFO:Total runtime is 0.31092872222264606 minutes
2022-11-08 11:27:14,917:INFO:SubProcess create_model() called ==================================
2022-11-08 11:27:14,917:INFO:Initializing create_model()
2022-11-08 11:27:14,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2CEA9E050>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:14,918:INFO:Checking exceptions
2022-11-08 11:27:14,927:INFO:Importing libraries
2022-11-08 11:27:14,927:INFO:Copying training dataset
2022-11-08 11:27:14,938:INFO:Defining folds
2022-11-08 11:27:14,938:INFO:Declaring metric variables
2022-11-08 11:27:14,948:INFO:Importing untrained model
2022-11-08 11:27:14,964:INFO:Dummy Regressor Imported successfully
2022-11-08 11:27:14,988:INFO:Starting cross validation
2022-11-08 11:27:14,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:27:15,328:INFO:Calculating mean and std
2022-11-08 11:27:15,330:INFO:Creating metrics dataframe
2022-11-08 11:27:15,344:INFO:Uploading results into container
2022-11-08 11:27:15,347:INFO:Uploading model into container now
2022-11-08 11:27:15,348:INFO:master_model_container: 18
2022-11-08 11:27:15,348:INFO:display_container: 2
2022-11-08 11:27:15,348:INFO:DummyRegressor()
2022-11-08 11:27:15,348:INFO:create_model() successfully completed......................................
2022-11-08 11:27:15,510:INFO:SubProcess create_model() end ==================================
2022-11-08 11:27:15,511:INFO:Creating metrics dataframe
2022-11-08 11:27:15,576:INFO:Initializing create_model()
2022-11-08 11:27:15,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:15,578:INFO:Checking exceptions
2022-11-08 11:27:15,578:INFO:Importing libraries
2022-11-08 11:27:15,578:INFO:Copying training dataset
2022-11-08 11:27:15,591:INFO:Defining folds
2022-11-08 11:27:15,591:INFO:Declaring metric variables
2022-11-08 11:27:15,591:INFO:Importing untrained model
2022-11-08 11:27:15,591:INFO:Declaring custom model
2022-11-08 11:27:15,591:INFO:Huber Regressor Imported successfully
2022-11-08 11:27:15,597:INFO:Cross validation set to False
2022-11-08 11:27:15,597:INFO:Fitting Model
2022-11-08 11:27:15,748:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:27:15,748:INFO:HuberRegressor()
2022-11-08 11:27:15,748:INFO:create_model() successfully completed......................................
2022-11-08 11:27:15,916:INFO:Initializing create_model()
2022-11-08 11:27:15,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=PassiveAggressiveRegressor(random_state=7997), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:15,916:INFO:Checking exceptions
2022-11-08 11:27:15,926:INFO:Importing libraries
2022-11-08 11:27:15,926:INFO:Copying training dataset
2022-11-08 11:27:15,928:INFO:Defining folds
2022-11-08 11:27:15,928:INFO:Declaring metric variables
2022-11-08 11:27:15,928:INFO:Importing untrained model
2022-11-08 11:27:15,928:INFO:Declaring custom model
2022-11-08 11:27:15,928:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:27:15,928:INFO:Cross validation set to False
2022-11-08 11:27:15,928:INFO:Fitting Model
2022-11-08 11:27:15,976:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:27:15,976:INFO:create_model() successfully completed......................................
2022-11-08 11:27:16,156:INFO:Initializing create_model()
2022-11-08 11:27:16,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:27:16,159:INFO:Checking exceptions
2022-11-08 11:27:16,168:INFO:Importing libraries
2022-11-08 11:27:16,168:INFO:Copying training dataset
2022-11-08 11:27:16,175:INFO:Defining folds
2022-11-08 11:27:16,176:INFO:Declaring metric variables
2022-11-08 11:27:16,177:INFO:Importing untrained model
2022-11-08 11:27:16,178:INFO:Declaring custom model
2022-11-08 11:27:16,180:INFO:Dummy Regressor Imported successfully
2022-11-08 11:27:16,182:INFO:Cross validation set to False
2022-11-08 11:27:16,182:INFO:Fitting Model
2022-11-08 11:27:16,209:INFO:DummyRegressor()
2022-11-08 11:27:16,210:INFO:create_model() successfully completed......................................
2022-11-08 11:27:16,448:INFO:master_model_container: 18
2022-11-08 11:27:16,456:INFO:display_container: 2
2022-11-08 11:27:16,458:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=7997), DummyRegressor()]
2022-11-08 11:27:16,458:INFO:compare_models() successfully completed......................................
2022-11-08 11:28:46,645:INFO:Initializing compare_models()
2022-11-08 11:28:46,645:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-08 11:28:46,645:INFO:Checking exceptions
2022-11-08 11:28:46,650:INFO:Preparing display monitor
2022-11-08 11:28:46,726:INFO:Initializing Linear Regression
2022-11-08 11:28:46,726:INFO:Total runtime is 0.0 minutes
2022-11-08 11:28:46,736:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:46,736:INFO:Initializing create_model()
2022-11-08 11:28:46,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:46,740:INFO:Checking exceptions
2022-11-08 11:28:46,742:INFO:Importing libraries
2022-11-08 11:28:46,742:INFO:Copying training dataset
2022-11-08 11:28:46,745:INFO:Defining folds
2022-11-08 11:28:46,745:INFO:Declaring metric variables
2022-11-08 11:28:46,756:INFO:Importing untrained model
2022-11-08 11:28:46,766:INFO:Linear Regression Imported successfully
2022-11-08 11:28:46,777:INFO:Starting cross validation
2022-11-08 11:28:46,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:47,027:INFO:Calculating mean and std
2022-11-08 11:28:47,027:INFO:Creating metrics dataframe
2022-11-08 11:28:47,028:INFO:Uploading results into container
2022-11-08 11:28:47,028:INFO:Uploading model into container now
2022-11-08 11:28:47,028:INFO:master_model_container: 19
2022-11-08 11:28:47,028:INFO:display_container: 3
2022-11-08 11:28:47,028:INFO:LinearRegression(n_jobs=-1)
2022-11-08 11:28:47,028:INFO:create_model() successfully completed......................................
2022-11-08 11:28:47,191:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:47,191:INFO:Creating metrics dataframe
2022-11-08 11:28:47,206:INFO:Initializing Lasso Regression
2022-11-08 11:28:47,206:INFO:Total runtime is 0.008009803295135499 minutes
2022-11-08 11:28:47,211:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:47,212:INFO:Initializing create_model()
2022-11-08 11:28:47,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:47,213:INFO:Checking exceptions
2022-11-08 11:28:47,215:INFO:Importing libraries
2022-11-08 11:28:47,215:INFO:Copying training dataset
2022-11-08 11:28:47,222:INFO:Defining folds
2022-11-08 11:28:47,222:INFO:Declaring metric variables
2022-11-08 11:28:47,229:INFO:Importing untrained model
2022-11-08 11:28:47,244:INFO:Lasso Regression Imported successfully
2022-11-08 11:28:47,261:INFO:Starting cross validation
2022-11-08 11:28:47,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:47,527:INFO:Calculating mean and std
2022-11-08 11:28:47,527:INFO:Creating metrics dataframe
2022-11-08 11:28:47,531:INFO:Uploading results into container
2022-11-08 11:28:47,535:INFO:Uploading model into container now
2022-11-08 11:28:47,535:INFO:master_model_container: 20
2022-11-08 11:28:47,535:INFO:display_container: 3
2022-11-08 11:28:47,537:INFO:Lasso(random_state=7997)
2022-11-08 11:28:47,537:INFO:create_model() successfully completed......................................
2022-11-08 11:28:47,688:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:47,688:INFO:Creating metrics dataframe
2022-11-08 11:28:47,709:INFO:Initializing Ridge Regression
2022-11-08 11:28:47,709:INFO:Total runtime is 0.01638394594192505 minutes
2022-11-08 11:28:47,713:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:47,713:INFO:Initializing create_model()
2022-11-08 11:28:47,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:47,713:INFO:Checking exceptions
2022-11-08 11:28:47,719:INFO:Importing libraries
2022-11-08 11:28:47,720:INFO:Copying training dataset
2022-11-08 11:28:47,729:INFO:Defining folds
2022-11-08 11:28:47,730:INFO:Declaring metric variables
2022-11-08 11:28:47,740:INFO:Importing untrained model
2022-11-08 11:28:47,749:INFO:Ridge Regression Imported successfully
2022-11-08 11:28:47,768:INFO:Starting cross validation
2022-11-08 11:28:47,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:47,976:INFO:Calculating mean and std
2022-11-08 11:28:47,978:INFO:Creating metrics dataframe
2022-11-08 11:28:47,983:INFO:Uploading results into container
2022-11-08 11:28:47,984:INFO:Uploading model into container now
2022-11-08 11:28:47,985:INFO:master_model_container: 21
2022-11-08 11:28:47,985:INFO:display_container: 3
2022-11-08 11:28:47,985:INFO:Ridge(random_state=7997)
2022-11-08 11:28:47,986:INFO:create_model() successfully completed......................................
2022-11-08 11:28:48,108:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:48,108:INFO:Creating metrics dataframe
2022-11-08 11:28:48,125:INFO:Initializing Elastic Net
2022-11-08 11:28:48,126:INFO:Total runtime is 0.023335512479146323 minutes
2022-11-08 11:28:48,131:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:48,132:INFO:Initializing create_model()
2022-11-08 11:28:48,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:48,132:INFO:Checking exceptions
2022-11-08 11:28:48,137:INFO:Importing libraries
2022-11-08 11:28:48,137:INFO:Copying training dataset
2022-11-08 11:28:48,142:INFO:Defining folds
2022-11-08 11:28:48,142:INFO:Declaring metric variables
2022-11-08 11:28:48,150:INFO:Importing untrained model
2022-11-08 11:28:48,170:INFO:Elastic Net Imported successfully
2022-11-08 11:28:48,192:INFO:Starting cross validation
2022-11-08 11:28:48,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:48,430:INFO:Calculating mean and std
2022-11-08 11:28:48,434:INFO:Creating metrics dataframe
2022-11-08 11:28:48,438:INFO:Uploading results into container
2022-11-08 11:28:48,439:INFO:Uploading model into container now
2022-11-08 11:28:48,439:INFO:master_model_container: 22
2022-11-08 11:28:48,440:INFO:display_container: 3
2022-11-08 11:28:48,440:INFO:ElasticNet(random_state=7997)
2022-11-08 11:28:48,441:INFO:create_model() successfully completed......................................
2022-11-08 11:28:48,568:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:48,568:INFO:Creating metrics dataframe
2022-11-08 11:28:48,583:INFO:Initializing Least Angle Regression
2022-11-08 11:28:48,584:INFO:Total runtime is 0.03096684217453003 minutes
2022-11-08 11:28:48,588:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:48,589:INFO:Initializing create_model()
2022-11-08 11:28:48,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:48,590:INFO:Checking exceptions
2022-11-08 11:28:48,591:INFO:Importing libraries
2022-11-08 11:28:48,591:INFO:Copying training dataset
2022-11-08 11:28:48,596:INFO:Defining folds
2022-11-08 11:28:48,597:INFO:Declaring metric variables
2022-11-08 11:28:48,604:INFO:Importing untrained model
2022-11-08 11:28:48,613:INFO:Least Angle Regression Imported successfully
2022-11-08 11:28:48,630:INFO:Starting cross validation
2022-11-08 11:28:48,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:48,691:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,706:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,710:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,725:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,755:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,765:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,781:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,785:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,817:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,818:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:48,836:INFO:Calculating mean and std
2022-11-08 11:28:48,838:INFO:Creating metrics dataframe
2022-11-08 11:28:48,841:INFO:Uploading results into container
2022-11-08 11:28:48,842:INFO:Uploading model into container now
2022-11-08 11:28:48,842:INFO:master_model_container: 23
2022-11-08 11:28:48,843:INFO:display_container: 3
2022-11-08 11:28:48,843:INFO:Lars(random_state=7997)
2022-11-08 11:28:48,843:INFO:create_model() successfully completed......................................
2022-11-08 11:28:48,967:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:48,967:INFO:Creating metrics dataframe
2022-11-08 11:28:48,983:INFO:Initializing Lasso Least Angle Regression
2022-11-08 11:28:48,983:INFO:Total runtime is 0.037631022930145266 minutes
2022-11-08 11:28:48,989:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:48,990:INFO:Initializing create_model()
2022-11-08 11:28:48,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:48,990:INFO:Checking exceptions
2022-11-08 11:28:48,993:INFO:Importing libraries
2022-11-08 11:28:48,994:INFO:Copying training dataset
2022-11-08 11:28:49,001:INFO:Defining folds
2022-11-08 11:28:49,002:INFO:Declaring metric variables
2022-11-08 11:28:49,011:INFO:Importing untrained model
2022-11-08 11:28:49,020:INFO:Lasso Least Angle Regression Imported successfully
2022-11-08 11:28:49,036:INFO:Starting cross validation
2022-11-08 11:28:49,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:49,110:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,120:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,130:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,141:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,166:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,175:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,196:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,212:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,220:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,220:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:28:49,240:INFO:Calculating mean and std
2022-11-08 11:28:49,242:INFO:Creating metrics dataframe
2022-11-08 11:28:49,245:INFO:Uploading results into container
2022-11-08 11:28:49,246:INFO:Uploading model into container now
2022-11-08 11:28:49,246:INFO:master_model_container: 24
2022-11-08 11:28:49,246:INFO:display_container: 3
2022-11-08 11:28:49,247:INFO:LassoLars(random_state=7997)
2022-11-08 11:28:49,247:INFO:create_model() successfully completed......................................
2022-11-08 11:28:49,367:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:49,367:INFO:Creating metrics dataframe
2022-11-08 11:28:49,384:INFO:Initializing Orthogonal Matching Pursuit
2022-11-08 11:28:49,384:INFO:Total runtime is 0.044314014911651614 minutes
2022-11-08 11:28:49,389:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:49,390:INFO:Initializing create_model()
2022-11-08 11:28:49,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:49,390:INFO:Checking exceptions
2022-11-08 11:28:49,394:INFO:Importing libraries
2022-11-08 11:28:49,394:INFO:Copying training dataset
2022-11-08 11:28:49,400:INFO:Defining folds
2022-11-08 11:28:49,401:INFO:Declaring metric variables
2022-11-08 11:28:49,406:INFO:Importing untrained model
2022-11-08 11:28:49,413:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-08 11:28:49,428:INFO:Starting cross validation
2022-11-08 11:28:49,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:49,486:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,496:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,545:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,550:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,618:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:28:49,645:INFO:Calculating mean and std
2022-11-08 11:28:49,649:INFO:Creating metrics dataframe
2022-11-08 11:28:49,653:INFO:Uploading results into container
2022-11-08 11:28:49,653:INFO:Uploading model into container now
2022-11-08 11:28:49,654:INFO:master_model_container: 25
2022-11-08 11:28:49,654:INFO:display_container: 3
2022-11-08 11:28:49,654:INFO:OrthogonalMatchingPursuit()
2022-11-08 11:28:49,654:INFO:create_model() successfully completed......................................
2022-11-08 11:28:49,778:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:49,778:INFO:Creating metrics dataframe
2022-11-08 11:28:49,795:INFO:Initializing Bayesian Ridge
2022-11-08 11:28:49,796:INFO:Total runtime is 0.051180652777353924 minutes
2022-11-08 11:28:49,804:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:49,805:INFO:Initializing create_model()
2022-11-08 11:28:49,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:49,805:INFO:Checking exceptions
2022-11-08 11:28:49,806:INFO:Importing libraries
2022-11-08 11:28:49,807:INFO:Copying training dataset
2022-11-08 11:28:49,812:INFO:Defining folds
2022-11-08 11:28:49,812:INFO:Declaring metric variables
2022-11-08 11:28:49,822:INFO:Importing untrained model
2022-11-08 11:28:49,829:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:28:49,846:INFO:Starting cross validation
2022-11-08 11:28:49,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:50,056:INFO:Calculating mean and std
2022-11-08 11:28:50,058:INFO:Creating metrics dataframe
2022-11-08 11:28:50,061:INFO:Uploading results into container
2022-11-08 11:28:50,061:INFO:Uploading model into container now
2022-11-08 11:28:50,063:INFO:master_model_container: 26
2022-11-08 11:28:50,063:INFO:display_container: 3
2022-11-08 11:28:50,063:INFO:BayesianRidge()
2022-11-08 11:28:50,063:INFO:create_model() successfully completed......................................
2022-11-08 11:28:50,186:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:50,186:INFO:Creating metrics dataframe
2022-11-08 11:28:50,202:INFO:Initializing Passive Aggressive Regressor
2022-11-08 11:28:50,202:INFO:Total runtime is 0.057942891120910646 minutes
2022-11-08 11:28:50,207:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:50,208:INFO:Initializing create_model()
2022-11-08 11:28:50,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:50,208:INFO:Checking exceptions
2022-11-08 11:28:50,211:INFO:Importing libraries
2022-11-08 11:28:50,212:INFO:Copying training dataset
2022-11-08 11:28:50,219:INFO:Defining folds
2022-11-08 11:28:50,219:INFO:Declaring metric variables
2022-11-08 11:28:50,225:INFO:Importing untrained model
2022-11-08 11:28:50,234:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:28:50,251:INFO:Starting cross validation
2022-11-08 11:28:50,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:50,451:INFO:Calculating mean and std
2022-11-08 11:28:50,453:INFO:Creating metrics dataframe
2022-11-08 11:28:50,457:INFO:Uploading results into container
2022-11-08 11:28:50,458:INFO:Uploading model into container now
2022-11-08 11:28:50,458:INFO:master_model_container: 27
2022-11-08 11:28:50,458:INFO:display_container: 3
2022-11-08 11:28:50,459:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:28:50,459:INFO:create_model() successfully completed......................................
2022-11-08 11:28:50,578:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:50,580:INFO:Creating metrics dataframe
2022-11-08 11:28:50,595:INFO:Initializing Huber Regressor
2022-11-08 11:28:50,596:INFO:Total runtime is 0.06450155178705852 minutes
2022-11-08 11:28:50,600:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:50,602:INFO:Initializing create_model()
2022-11-08 11:28:50,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:50,602:INFO:Checking exceptions
2022-11-08 11:28:50,605:INFO:Importing libraries
2022-11-08 11:28:50,606:INFO:Copying training dataset
2022-11-08 11:28:50,610:INFO:Defining folds
2022-11-08 11:28:50,610:INFO:Declaring metric variables
2022-11-08 11:28:50,618:INFO:Importing untrained model
2022-11-08 11:28:50,627:INFO:Huber Regressor Imported successfully
2022-11-08 11:28:50,642:INFO:Starting cross validation
2022-11-08 11:28:50,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:50,768:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,777:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,800:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,880:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,889:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,889:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,909:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,959:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,966:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:50,978:INFO:Calculating mean and std
2022-11-08 11:28:50,980:INFO:Creating metrics dataframe
2022-11-08 11:28:50,984:INFO:Uploading results into container
2022-11-08 11:28:50,984:INFO:Uploading model into container now
2022-11-08 11:28:50,985:INFO:master_model_container: 28
2022-11-08 11:28:50,985:INFO:display_container: 3
2022-11-08 11:28:50,986:INFO:HuberRegressor()
2022-11-08 11:28:50,986:INFO:create_model() successfully completed......................................
2022-11-08 11:28:51,106:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:51,106:INFO:Creating metrics dataframe
2022-11-08 11:28:51,124:INFO:Initializing K Neighbors Regressor
2022-11-08 11:28:51,124:INFO:Total runtime is 0.07330013513565065 minutes
2022-11-08 11:28:51,130:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:51,131:INFO:Initializing create_model()
2022-11-08 11:28:51,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:51,131:INFO:Checking exceptions
2022-11-08 11:28:51,133:INFO:Importing libraries
2022-11-08 11:28:51,133:INFO:Copying training dataset
2022-11-08 11:28:51,138:INFO:Defining folds
2022-11-08 11:28:51,139:INFO:Declaring metric variables
2022-11-08 11:28:51,148:INFO:Importing untrained model
2022-11-08 11:28:51,156:INFO:K Neighbors Regressor Imported successfully
2022-11-08 11:28:51,172:INFO:Starting cross validation
2022-11-08 11:28:51,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:51,395:INFO:Calculating mean and std
2022-11-08 11:28:51,397:INFO:Creating metrics dataframe
2022-11-08 11:28:51,401:INFO:Uploading results into container
2022-11-08 11:28:51,401:INFO:Uploading model into container now
2022-11-08 11:28:51,402:INFO:master_model_container: 29
2022-11-08 11:28:51,402:INFO:display_container: 3
2022-11-08 11:28:51,402:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-08 11:28:51,403:INFO:create_model() successfully completed......................................
2022-11-08 11:28:51,518:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:51,518:INFO:Creating metrics dataframe
2022-11-08 11:28:51,539:INFO:Initializing Decision Tree Regressor
2022-11-08 11:28:51,540:INFO:Total runtime is 0.08024451732635499 minutes
2022-11-08 11:28:51,544:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:51,546:INFO:Initializing create_model()
2022-11-08 11:28:51,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:51,547:INFO:Checking exceptions
2022-11-08 11:28:51,549:INFO:Importing libraries
2022-11-08 11:28:51,549:INFO:Copying training dataset
2022-11-08 11:28:51,554:INFO:Defining folds
2022-11-08 11:28:51,555:INFO:Declaring metric variables
2022-11-08 11:28:51,561:INFO:Importing untrained model
2022-11-08 11:28:51,574:INFO:Decision Tree Regressor Imported successfully
2022-11-08 11:28:51,592:INFO:Starting cross validation
2022-11-08 11:28:51,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:51,799:INFO:Calculating mean and std
2022-11-08 11:28:51,801:INFO:Creating metrics dataframe
2022-11-08 11:28:51,805:INFO:Uploading results into container
2022-11-08 11:28:51,805:INFO:Uploading model into container now
2022-11-08 11:28:51,806:INFO:master_model_container: 30
2022-11-08 11:28:51,806:INFO:display_container: 3
2022-11-08 11:28:51,806:INFO:DecisionTreeRegressor(random_state=7997)
2022-11-08 11:28:51,807:INFO:create_model() successfully completed......................................
2022-11-08 11:28:51,926:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:51,926:INFO:Creating metrics dataframe
2022-11-08 11:28:51,943:INFO:Initializing Random Forest Regressor
2022-11-08 11:28:51,943:INFO:Total runtime is 0.08695812622706096 minutes
2022-11-08 11:28:51,950:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:51,950:INFO:Initializing create_model()
2022-11-08 11:28:51,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:51,951:INFO:Checking exceptions
2022-11-08 11:28:51,953:INFO:Importing libraries
2022-11-08 11:28:51,953:INFO:Copying training dataset
2022-11-08 11:28:51,958:INFO:Defining folds
2022-11-08 11:28:51,958:INFO:Declaring metric variables
2022-11-08 11:28:51,964:INFO:Importing untrained model
2022-11-08 11:28:51,971:INFO:Random Forest Regressor Imported successfully
2022-11-08 11:28:51,983:INFO:Starting cross validation
2022-11-08 11:28:51,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:53,222:INFO:Calculating mean and std
2022-11-08 11:28:53,223:INFO:Creating metrics dataframe
2022-11-08 11:28:53,228:INFO:Uploading results into container
2022-11-08 11:28:53,229:INFO:Uploading model into container now
2022-11-08 11:28:53,229:INFO:master_model_container: 31
2022-11-08 11:28:53,230:INFO:display_container: 3
2022-11-08 11:28:53,230:INFO:RandomForestRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:28:53,231:INFO:create_model() successfully completed......................................
2022-11-08 11:28:53,348:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:53,348:INFO:Creating metrics dataframe
2022-11-08 11:28:53,367:INFO:Initializing Extra Trees Regressor
2022-11-08 11:28:53,367:INFO:Total runtime is 0.110696812470754 minutes
2022-11-08 11:28:53,372:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:53,373:INFO:Initializing create_model()
2022-11-08 11:28:53,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:53,373:INFO:Checking exceptions
2022-11-08 11:28:53,378:INFO:Importing libraries
2022-11-08 11:28:53,378:INFO:Copying training dataset
2022-11-08 11:28:53,383:INFO:Defining folds
2022-11-08 11:28:53,383:INFO:Declaring metric variables
2022-11-08 11:28:53,388:INFO:Importing untrained model
2022-11-08 11:28:53,397:INFO:Extra Trees Regressor Imported successfully
2022-11-08 11:28:53,410:INFO:Starting cross validation
2022-11-08 11:28:53,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:54,396:INFO:Calculating mean and std
2022-11-08 11:28:54,398:INFO:Creating metrics dataframe
2022-11-08 11:28:54,402:INFO:Uploading results into container
2022-11-08 11:28:54,402:INFO:Uploading model into container now
2022-11-08 11:28:54,403:INFO:master_model_container: 32
2022-11-08 11:28:54,403:INFO:display_container: 3
2022-11-08 11:28:54,403:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7997)
2022-11-08 11:28:54,403:INFO:create_model() successfully completed......................................
2022-11-08 11:28:54,616:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:54,616:INFO:Creating metrics dataframe
2022-11-08 11:28:54,637:INFO:Initializing AdaBoost Regressor
2022-11-08 11:28:54,637:INFO:Total runtime is 0.13185006380081177 minutes
2022-11-08 11:28:54,645:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:54,645:INFO:Initializing create_model()
2022-11-08 11:28:54,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:54,645:INFO:Checking exceptions
2022-11-08 11:28:54,647:INFO:Importing libraries
2022-11-08 11:28:54,647:INFO:Copying training dataset
2022-11-08 11:28:54,651:INFO:Defining folds
2022-11-08 11:28:54,652:INFO:Declaring metric variables
2022-11-08 11:28:54,658:INFO:Importing untrained model
2022-11-08 11:28:54,668:INFO:AdaBoost Regressor Imported successfully
2022-11-08 11:28:54,685:INFO:Starting cross validation
2022-11-08 11:28:54,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:55,217:INFO:Calculating mean and std
2022-11-08 11:28:55,219:INFO:Creating metrics dataframe
2022-11-08 11:28:55,222:INFO:Uploading results into container
2022-11-08 11:28:55,222:INFO:Uploading model into container now
2022-11-08 11:28:55,223:INFO:master_model_container: 33
2022-11-08 11:28:55,223:INFO:display_container: 3
2022-11-08 11:28:55,223:INFO:AdaBoostRegressor(random_state=7997)
2022-11-08 11:28:55,223:INFO:create_model() successfully completed......................................
2022-11-08 11:28:55,344:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:55,344:INFO:Creating metrics dataframe
2022-11-08 11:28:55,363:INFO:Initializing Gradient Boosting Regressor
2022-11-08 11:28:55,364:INFO:Total runtime is 0.1439779837926229 minutes
2022-11-08 11:28:55,370:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:55,371:INFO:Initializing create_model()
2022-11-08 11:28:55,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:55,371:INFO:Checking exceptions
2022-11-08 11:28:55,373:INFO:Importing libraries
2022-11-08 11:28:55,374:INFO:Copying training dataset
2022-11-08 11:28:55,382:INFO:Defining folds
2022-11-08 11:28:55,382:INFO:Declaring metric variables
2022-11-08 11:28:55,388:INFO:Importing untrained model
2022-11-08 11:28:55,396:INFO:Gradient Boosting Regressor Imported successfully
2022-11-08 11:28:55,411:INFO:Starting cross validation
2022-11-08 11:28:55,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:55,886:INFO:Calculating mean and std
2022-11-08 11:28:55,888:INFO:Creating metrics dataframe
2022-11-08 11:28:55,892:INFO:Uploading results into container
2022-11-08 11:28:55,893:INFO:Uploading model into container now
2022-11-08 11:28:55,893:INFO:master_model_container: 34
2022-11-08 11:28:55,893:INFO:display_container: 3
2022-11-08 11:28:55,893:INFO:GradientBoostingRegressor(random_state=7997)
2022-11-08 11:28:55,893:INFO:create_model() successfully completed......................................
2022-11-08 11:28:56,011:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:56,011:INFO:Creating metrics dataframe
2022-11-08 11:28:56,033:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:28:56,034:INFO:Total runtime is 0.15513759454091391 minutes
2022-11-08 11:28:56,039:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:56,040:INFO:Initializing create_model()
2022-11-08 11:28:56,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:56,040:INFO:Checking exceptions
2022-11-08 11:28:56,044:INFO:Importing libraries
2022-11-08 11:28:56,044:INFO:Copying training dataset
2022-11-08 11:28:56,050:INFO:Defining folds
2022-11-08 11:28:56,050:INFO:Declaring metric variables
2022-11-08 11:28:56,056:INFO:Importing untrained model
2022-11-08 11:28:56,067:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:28:56,083:INFO:Starting cross validation
2022-11-08 11:28:56,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:56,389:INFO:Calculating mean and std
2022-11-08 11:28:56,391:INFO:Creating metrics dataframe
2022-11-08 11:28:56,395:INFO:Uploading results into container
2022-11-08 11:28:56,396:INFO:Uploading model into container now
2022-11-08 11:28:56,396:INFO:master_model_container: 35
2022-11-08 11:28:56,396:INFO:display_container: 3
2022-11-08 11:28:56,396:INFO:LGBMRegressor(random_state=7997)
2022-11-08 11:28:56,396:INFO:create_model() successfully completed......................................
2022-11-08 11:28:56,517:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:56,517:INFO:Creating metrics dataframe
2022-11-08 11:28:56,539:INFO:Initializing Dummy Regressor
2022-11-08 11:28:56,547:INFO:Total runtime is 0.16368584235509237 minutes
2022-11-08 11:28:56,553:INFO:SubProcess create_model() called ==================================
2022-11-08 11:28:56,554:INFO:Initializing create_model()
2022-11-08 11:28:56,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46AB430>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:56,554:INFO:Checking exceptions
2022-11-08 11:28:56,557:INFO:Importing libraries
2022-11-08 11:28:56,558:INFO:Copying training dataset
2022-11-08 11:28:56,563:INFO:Defining folds
2022-11-08 11:28:56,563:INFO:Declaring metric variables
2022-11-08 11:28:56,573:INFO:Importing untrained model
2022-11-08 11:28:56,581:INFO:Dummy Regressor Imported successfully
2022-11-08 11:28:56,597:INFO:Starting cross validation
2022-11-08 11:28:56,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:28:56,783:INFO:Calculating mean and std
2022-11-08 11:28:56,785:INFO:Creating metrics dataframe
2022-11-08 11:28:56,789:INFO:Uploading results into container
2022-11-08 11:28:56,789:INFO:Uploading model into container now
2022-11-08 11:28:56,790:INFO:master_model_container: 36
2022-11-08 11:28:56,790:INFO:display_container: 3
2022-11-08 11:28:56,790:INFO:DummyRegressor()
2022-11-08 11:28:56,790:INFO:create_model() successfully completed......................................
2022-11-08 11:28:56,909:INFO:SubProcess create_model() end ==================================
2022-11-08 11:28:56,909:INFO:Creating metrics dataframe
2022-11-08 11:28:56,946:INFO:Initializing create_model()
2022-11-08 11:28:56,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:56,946:INFO:Checking exceptions
2022-11-08 11:28:56,948:INFO:Importing libraries
2022-11-08 11:28:56,948:INFO:Copying training dataset
2022-11-08 11:28:56,948:INFO:Defining folds
2022-11-08 11:28:56,948:INFO:Declaring metric variables
2022-11-08 11:28:56,948:INFO:Importing untrained model
2022-11-08 11:28:56,955:INFO:Declaring custom model
2022-11-08 11:28:56,957:INFO:Huber Regressor Imported successfully
2022-11-08 11:28:56,958:INFO:Cross validation set to False
2022-11-08 11:28:56,959:INFO:Fitting Model
2022-11-08 11:28:57,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:28:57,017:INFO:HuberRegressor()
2022-11-08 11:28:57,017:INFO:create_model() successfully completed......................................
2022-11-08 11:28:57,149:INFO:Initializing create_model()
2022-11-08 11:28:57,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=PassiveAggressiveRegressor(random_state=7997), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:57,150:INFO:Checking exceptions
2022-11-08 11:28:57,155:INFO:Importing libraries
2022-11-08 11:28:57,157:INFO:Copying training dataset
2022-11-08 11:28:57,159:INFO:Defining folds
2022-11-08 11:28:57,159:INFO:Declaring metric variables
2022-11-08 11:28:57,159:INFO:Importing untrained model
2022-11-08 11:28:57,159:INFO:Declaring custom model
2022-11-08 11:28:57,159:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:28:57,159:INFO:Cross validation set to False
2022-11-08 11:28:57,159:INFO:Fitting Model
2022-11-08 11:28:57,177:INFO:PassiveAggressiveRegressor(random_state=7997)
2022-11-08 11:28:57,177:INFO:create_model() successfully completed......................................
2022-11-08 11:28:57,307:INFO:Initializing create_model()
2022-11-08 11:28:57,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:28:57,308:INFO:Checking exceptions
2022-11-08 11:28:57,312:INFO:Importing libraries
2022-11-08 11:28:57,312:INFO:Copying training dataset
2022-11-08 11:28:57,317:INFO:Defining folds
2022-11-08 11:28:57,317:INFO:Declaring metric variables
2022-11-08 11:28:57,317:INFO:Importing untrained model
2022-11-08 11:28:57,317:INFO:Declaring custom model
2022-11-08 11:28:57,317:INFO:Dummy Regressor Imported successfully
2022-11-08 11:28:57,321:INFO:Cross validation set to False
2022-11-08 11:28:57,321:INFO:Fitting Model
2022-11-08 11:28:57,338:INFO:DummyRegressor()
2022-11-08 11:28:57,338:INFO:create_model() successfully completed......................................
2022-11-08 11:28:57,514:INFO:master_model_container: 36
2022-11-08 11:28:57,514:INFO:display_container: 3
2022-11-08 11:28:57,515:INFO:[HuberRegressor(), PassiveAggressiveRegressor(random_state=7997), DummyRegressor()]
2022-11-08 11:28:57,515:INFO:compare_models() successfully completed......................................
2022-11-08 11:29:38,346:INFO:Initializing create_model()
2022-11-08 11:29:38,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:29:38,347:INFO:Checking exceptions
2022-11-08 11:29:38,411:INFO:Importing libraries
2022-11-08 11:29:38,411:INFO:Copying training dataset
2022-11-08 11:29:38,417:INFO:Defining folds
2022-11-08 11:29:38,417:INFO:Declaring metric variables
2022-11-08 11:29:38,447:INFO:Importing untrained model
2022-11-08 11:29:38,455:INFO:Huber Regressor Imported successfully
2022-11-08 11:29:38,466:INFO:Starting cross validation
2022-11-08 11:29:38,466:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:29:38,825:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:38,827:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:38,840:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:38,877:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,292:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,292:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,346:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,425:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,810:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,839:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,850:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:39,891:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,388:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,439:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,439:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,487:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,856:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:40,932:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:41,006:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:41,126:INFO:Calculating mean and std
2022-11-08 11:29:41,128:INFO:Creating metrics dataframe
2022-11-08 11:29:41,135:INFO:Finalizing model
2022-11-08 11:29:41,186:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:29:41,192:INFO:Uploading results into container
2022-11-08 11:29:41,193:INFO:Uploading model into container now
2022-11-08 11:29:41,210:INFO:master_model_container: 37
2022-11-08 11:29:41,211:INFO:display_container: 4
2022-11-08 11:29:41,211:INFO:HuberRegressor()
2022-11-08 11:29:41,211:INFO:create_model() successfully completed......................................
2022-11-08 11:29:58,884:INFO:Initializing plot_model()
2022-11-08 11:29:58,884:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2D6FE8370>, system=True)
2022-11-08 11:29:58,886:INFO:Checking exceptions
2022-11-08 11:29:58,890:INFO:Preloading libraries
2022-11-08 11:29:58,891:INFO:Copying training dataset
2022-11-08 11:29:58,891:INFO:Plot type: residuals
2022-11-08 11:29:59,087:INFO:Fitting Model
2022-11-08 11:29:59,087:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:29:59,166:INFO:Scoring test/hold-out set
2022-11-08 11:30:00,137:INFO:Visual Rendered Successfully
2022-11-08 11:30:00,290:INFO:plot_model() successfully completed......................................
2022-11-08 11:30:39,625:INFO:PyCaret RegressionExperiment
2022-11-08 11:30:39,625:INFO:Logging name: reg-default-name
2022-11-08 11:30:39,625:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-08 11:30:39,626:INFO:version 3.0.0.rc4
2022-11-08 11:30:39,626:INFO:Initializing setup()
2022-11-08 11:30:39,626:INFO:self.USI: f870
2022-11-08 11:30:39,626:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'transform_target_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'transform_target_method_param', 'master_model_container', 'y_test', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:30:39,626:INFO:Checking environment
2022-11-08 11:30:39,626:INFO:python_version: 3.10.4
2022-11-08 11:30:39,626:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:30:39,627:INFO:machine: AMD64
2022-11-08 11:30:39,627:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:30:39,627:INFO:Memory: svmem(total=8503136256, available=1445359616, percent=83.0, used=7057776640, free=1445359616)
2022-11-08 11:30:39,627:INFO:Physical Core: 2
2022-11-08 11:30:39,627:INFO:Logical Core: 4
2022-11-08 11:30:39,627:INFO:Checking libraries
2022-11-08 11:30:39,627:INFO:System:
2022-11-08 11:30:39,627:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:30:39,627:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:30:39,627:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:30:39,627:INFO:PyCaret required dependencies:
2022-11-08 11:30:39,627:INFO:                 pip: 22.2.2
2022-11-08 11:30:39,627:INFO:          setuptools: 58.1.0
2022-11-08 11:30:39,627:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:30:39,627:INFO:             IPython: 8.4.0
2022-11-08 11:30:39,627:INFO:          ipywidgets: 8.0.2
2022-11-08 11:30:39,627:INFO:                tqdm: 4.64.0
2022-11-08 11:30:39,627:INFO:               numpy: 1.22.3
2022-11-08 11:30:39,627:INFO:              pandas: 1.4.2
2022-11-08 11:30:39,627:INFO:              jinja2: 3.1.2
2022-11-08 11:30:39,627:INFO:               scipy: 1.8.1
2022-11-08 11:30:39,627:INFO:              joblib: 1.2.0
2022-11-08 11:30:39,627:INFO:             sklearn: 1.1.2
2022-11-08 11:30:39,627:INFO:                pyod: 1.0.6
2022-11-08 11:30:39,627:INFO:            imblearn: 0.9.1
2022-11-08 11:30:39,627:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:30:39,627:INFO:            lightgbm: 3.3.3
2022-11-08 11:30:39,627:INFO:               numba: 0.55.2
2022-11-08 11:30:39,627:INFO:            requests: 2.28.1
2022-11-08 11:30:39,631:INFO:          matplotlib: 3.5.1
2022-11-08 11:30:39,631:INFO:          scikitplot: 0.3.7
2022-11-08 11:30:39,631:INFO:         yellowbrick: 1.5
2022-11-08 11:30:39,631:INFO:              plotly: 5.11.0
2022-11-08 11:30:39,631:INFO:             kaleido: 0.2.1
2022-11-08 11:30:39,631:INFO:         statsmodels: 0.13.5
2022-11-08 11:30:39,631:INFO:              sktime: 0.13.4
2022-11-08 11:30:39,631:INFO:               tbats: 1.1.1
2022-11-08 11:30:39,631:INFO:            pmdarima: 1.8.5
2022-11-08 11:30:39,632:INFO:              psutil: 5.9.1
2022-11-08 11:30:39,632:INFO:PyCaret optional dependencies:
2022-11-08 11:30:39,632:INFO:                shap: Not installed
2022-11-08 11:30:39,632:INFO:           interpret: Not installed
2022-11-08 11:30:39,632:INFO:                umap: Not installed
2022-11-08 11:30:39,632:INFO:    pandas_profiling: Not installed
2022-11-08 11:30:39,632:INFO:  explainerdashboard: Not installed
2022-11-08 11:30:39,632:INFO:             autoviz: Not installed
2022-11-08 11:30:39,632:INFO:           fairlearn: Not installed
2022-11-08 11:30:39,632:INFO:             xgboost: Not installed
2022-11-08 11:30:39,632:INFO:            catboost: Not installed
2022-11-08 11:30:39,632:INFO:              kmodes: Not installed
2022-11-08 11:30:39,632:INFO:             mlxtend: Not installed
2022-11-08 11:30:39,632:INFO:       statsforecast: Not installed
2022-11-08 11:30:39,632:INFO:        tune_sklearn: Not installed
2022-11-08 11:30:39,632:INFO:                 ray: Not installed
2022-11-08 11:30:39,632:INFO:            hyperopt: Not installed
2022-11-08 11:30:39,632:INFO:              optuna: Not installed
2022-11-08 11:30:39,632:INFO:               skopt: Not installed
2022-11-08 11:30:39,632:INFO:              mlflow: Not installed
2022-11-08 11:30:39,632:INFO:              gradio: Not installed
2022-11-08 11:30:39,632:INFO:             fastapi: Not installed
2022-11-08 11:30:39,632:INFO:             uvicorn: Not installed
2022-11-08 11:30:39,632:INFO:              m2cgen: Not installed
2022-11-08 11:30:39,632:INFO:           evidently: Not installed
2022-11-08 11:30:39,632:INFO:                nltk: 3.7
2022-11-08 11:30:39,635:INFO:            pyLDAvis: Not installed
2022-11-08 11:30:39,635:INFO:              gensim: Not installed
2022-11-08 11:30:39,635:INFO:               spacy: Not installed
2022-11-08 11:30:39,635:INFO:           wordcloud: Not installed
2022-11-08 11:30:39,635:INFO:            textblob: Not installed
2022-11-08 11:30:39,635:INFO:               fugue: Not installed
2022-11-08 11:30:39,635:INFO:           streamlit: Not installed
2022-11-08 11:30:39,635:INFO:             prophet: Not installed
2022-11-08 11:30:39,635:INFO:None
2022-11-08 11:30:39,635:INFO:Set up data.
2022-11-08 11:30:39,645:INFO:Set up train/test split.
2022-11-08 11:30:39,653:INFO:Set up index.
2022-11-08 11:30:39,653:INFO:Set up folding strategy.
2022-11-08 11:30:39,653:INFO:Assigning column types.
2022-11-08 11:30:39,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:30:39,661:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,671:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:39,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:39,847:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,856:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:39,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,058:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-08 11:30:40,058:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,247:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,396:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-08 11:30:40,407:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:40,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:40,909:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-08 11:30:40,998:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,242:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:30:41,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-08 11:30:41,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,522:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-08 11:30:41,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:41,877:INFO:Preparing preprocessing pipeline...
2022-11-08 11:30:41,885:INFO:Set up simple imputation.
2022-11-08 11:30:41,885:INFO:Set up variance threshold.
2022-11-08 11:30:41,948:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:30:41,956:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-08 11:30:41,957:INFO:Creating final display dataframe.
2022-11-08 11:30:42,238:INFO:Setup display_container:                Description             Value
0               Session id               204
1                   Target              area
2              Target type        Regression
3               Data shape          (517, 9)
4         Train data shape          (361, 9)
5          Test data shape          (156, 9)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              f870
2022-11-08 11:30:42,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:30:42,549:INFO:setup() successfully completed in 2.93s...............
2022-11-08 11:30:42,609:INFO:Initializing compare_models()
2022-11-08 11:30:42,609:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-08 11:30:42,609:INFO:Checking exceptions
2022-11-08 11:30:42,613:INFO:Preparing display monitor
2022-11-08 11:30:42,668:INFO:Initializing Linear Regression
2022-11-08 11:30:42,669:INFO:Total runtime is 1.911322275797526e-05 minutes
2022-11-08 11:30:42,675:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:42,675:INFO:Initializing create_model()
2022-11-08 11:30:42,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:42,675:INFO:Checking exceptions
2022-11-08 11:30:42,680:INFO:Importing libraries
2022-11-08 11:30:42,680:INFO:Copying training dataset
2022-11-08 11:30:42,680:INFO:Defining folds
2022-11-08 11:30:42,680:INFO:Declaring metric variables
2022-11-08 11:30:42,694:INFO:Importing untrained model
2022-11-08 11:30:42,701:INFO:Linear Regression Imported successfully
2022-11-08 11:30:42,713:INFO:Starting cross validation
2022-11-08 11:30:42,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:43,815:INFO:Calculating mean and std
2022-11-08 11:30:43,818:INFO:Creating metrics dataframe
2022-11-08 11:30:43,825:INFO:Uploading results into container
2022-11-08 11:30:43,826:INFO:Uploading model into container now
2022-11-08 11:30:43,827:INFO:master_model_container: 1
2022-11-08 11:30:43,827:INFO:display_container: 2
2022-11-08 11:30:43,827:INFO:LinearRegression(n_jobs=-1)
2022-11-08 11:30:43,827:INFO:create_model() successfully completed......................................
2022-11-08 11:30:43,977:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:43,977:INFO:Creating metrics dataframe
2022-11-08 11:30:43,992:INFO:Initializing Lasso Regression
2022-11-08 11:30:43,992:INFO:Total runtime is 0.02206399440765381 minutes
2022-11-08 11:30:43,997:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:43,997:INFO:Initializing create_model()
2022-11-08 11:30:43,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:43,997:INFO:Checking exceptions
2022-11-08 11:30:44,000:INFO:Importing libraries
2022-11-08 11:30:44,000:INFO:Copying training dataset
2022-11-08 11:30:44,007:INFO:Defining folds
2022-11-08 11:30:44,007:INFO:Declaring metric variables
2022-11-08 11:30:44,013:INFO:Importing untrained model
2022-11-08 11:30:44,021:INFO:Lasso Regression Imported successfully
2022-11-08 11:30:44,032:INFO:Starting cross validation
2022-11-08 11:30:44,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:44,333:INFO:Calculating mean and std
2022-11-08 11:30:44,336:INFO:Creating metrics dataframe
2022-11-08 11:30:44,340:INFO:Uploading results into container
2022-11-08 11:30:44,340:INFO:Uploading model into container now
2022-11-08 11:30:44,341:INFO:master_model_container: 2
2022-11-08 11:30:44,341:INFO:display_container: 2
2022-11-08 11:30:44,341:INFO:Lasso(random_state=204)
2022-11-08 11:30:44,341:INFO:create_model() successfully completed......................................
2022-11-08 11:30:44,463:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:44,464:INFO:Creating metrics dataframe
2022-11-08 11:30:44,480:INFO:Initializing Ridge Regression
2022-11-08 11:30:44,480:INFO:Total runtime is 0.03020600477854411 minutes
2022-11-08 11:30:44,487:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:44,488:INFO:Initializing create_model()
2022-11-08 11:30:44,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:44,488:INFO:Checking exceptions
2022-11-08 11:30:44,491:INFO:Importing libraries
2022-11-08 11:30:44,491:INFO:Copying training dataset
2022-11-08 11:30:44,497:INFO:Defining folds
2022-11-08 11:30:44,498:INFO:Declaring metric variables
2022-11-08 11:30:44,506:INFO:Importing untrained model
2022-11-08 11:30:44,511:INFO:Ridge Regression Imported successfully
2022-11-08 11:30:44,524:INFO:Starting cross validation
2022-11-08 11:30:44,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:44,739:INFO:Calculating mean and std
2022-11-08 11:30:44,742:INFO:Creating metrics dataframe
2022-11-08 11:30:44,745:INFO:Uploading results into container
2022-11-08 11:30:44,746:INFO:Uploading model into container now
2022-11-08 11:30:44,746:INFO:master_model_container: 3
2022-11-08 11:30:44,746:INFO:display_container: 2
2022-11-08 11:30:44,746:INFO:Ridge(random_state=204)
2022-11-08 11:30:44,746:INFO:create_model() successfully completed......................................
2022-11-08 11:30:44,885:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:44,885:INFO:Creating metrics dataframe
2022-11-08 11:30:44,912:INFO:Initializing Elastic Net
2022-11-08 11:30:44,912:INFO:Total runtime is 0.03739255666732788 minutes
2022-11-08 11:30:44,920:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:44,921:INFO:Initializing create_model()
2022-11-08 11:30:44,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:44,922:INFO:Checking exceptions
2022-11-08 11:30:44,923:INFO:Importing libraries
2022-11-08 11:30:44,923:INFO:Copying training dataset
2022-11-08 11:30:44,928:INFO:Defining folds
2022-11-08 11:30:44,929:INFO:Declaring metric variables
2022-11-08 11:30:44,936:INFO:Importing untrained model
2022-11-08 11:30:44,942:INFO:Elastic Net Imported successfully
2022-11-08 11:30:44,954:INFO:Starting cross validation
2022-11-08 11:30:44,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:45,195:INFO:Calculating mean and std
2022-11-08 11:30:45,197:INFO:Creating metrics dataframe
2022-11-08 11:30:45,202:INFO:Uploading results into container
2022-11-08 11:30:45,204:INFO:Uploading model into container now
2022-11-08 11:30:45,205:INFO:master_model_container: 4
2022-11-08 11:30:45,205:INFO:display_container: 2
2022-11-08 11:30:45,206:INFO:ElasticNet(random_state=204)
2022-11-08 11:30:45,206:INFO:create_model() successfully completed......................................
2022-11-08 11:30:45,347:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:45,347:INFO:Creating metrics dataframe
2022-11-08 11:30:45,371:INFO:Initializing Least Angle Regression
2022-11-08 11:30:45,372:INFO:Total runtime is 0.04505216677983602 minutes
2022-11-08 11:30:45,378:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:45,379:INFO:Initializing create_model()
2022-11-08 11:30:45,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:45,379:INFO:Checking exceptions
2022-11-08 11:30:45,381:INFO:Importing libraries
2022-11-08 11:30:45,382:INFO:Copying training dataset
2022-11-08 11:30:45,390:INFO:Defining folds
2022-11-08 11:30:45,391:INFO:Declaring metric variables
2022-11-08 11:30:45,400:INFO:Importing untrained model
2022-11-08 11:30:45,409:INFO:Least Angle Regression Imported successfully
2022-11-08 11:30:45,428:INFO:Starting cross validation
2022-11-08 11:30:45,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:45,489:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,500:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,510:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,517:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,555:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,560:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,580:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,590:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,614:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,620:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:45,636:INFO:Calculating mean and std
2022-11-08 11:30:45,637:INFO:Creating metrics dataframe
2022-11-08 11:30:45,641:INFO:Uploading results into container
2022-11-08 11:30:45,641:INFO:Uploading model into container now
2022-11-08 11:30:45,642:INFO:master_model_container: 5
2022-11-08 11:30:45,642:INFO:display_container: 2
2022-11-08 11:30:45,642:INFO:Lars(random_state=204)
2022-11-08 11:30:45,643:INFO:create_model() successfully completed......................................
2022-11-08 11:30:45,769:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:45,769:INFO:Creating metrics dataframe
2022-11-08 11:30:45,781:INFO:Initializing Lasso Least Angle Regression
2022-11-08 11:30:45,781:INFO:Total runtime is 0.05188793341318766 minutes
2022-11-08 11:30:45,788:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:45,789:INFO:Initializing create_model()
2022-11-08 11:30:45,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:45,789:INFO:Checking exceptions
2022-11-08 11:30:45,792:INFO:Importing libraries
2022-11-08 11:30:45,792:INFO:Copying training dataset
2022-11-08 11:30:45,798:INFO:Defining folds
2022-11-08 11:30:45,798:INFO:Declaring metric variables
2022-11-08 11:30:45,804:INFO:Importing untrained model
2022-11-08 11:30:45,813:INFO:Lasso Least Angle Regression Imported successfully
2022-11-08 11:30:45,829:INFO:Starting cross validation
2022-11-08 11:30:45,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:45,905:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,910:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,917:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,935:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,958:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,976:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:45,985:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,005:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,017:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:46,037:INFO:Calculating mean and std
2022-11-08 11:30:46,038:INFO:Creating metrics dataframe
2022-11-08 11:30:46,042:INFO:Uploading results into container
2022-11-08 11:30:46,042:INFO:Uploading model into container now
2022-11-08 11:30:46,044:INFO:master_model_container: 6
2022-11-08 11:30:46,044:INFO:display_container: 2
2022-11-08 11:30:46,044:INFO:LassoLars(random_state=204)
2022-11-08 11:30:46,045:INFO:create_model() successfully completed......................................
2022-11-08 11:30:46,169:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:46,169:INFO:Creating metrics dataframe
2022-11-08 11:30:46,184:INFO:Initializing Orthogonal Matching Pursuit
2022-11-08 11:30:46,184:INFO:Total runtime is 0.05859781503677368 minutes
2022-11-08 11:30:46,189:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:46,190:INFO:Initializing create_model()
2022-11-08 11:30:46,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:46,191:INFO:Checking exceptions
2022-11-08 11:30:46,193:INFO:Importing libraries
2022-11-08 11:30:46,194:INFO:Copying training dataset
2022-11-08 11:30:46,198:INFO:Defining folds
2022-11-08 11:30:46,198:INFO:Declaring metric variables
2022-11-08 11:30:46,208:INFO:Importing untrained model
2022-11-08 11:30:46,217:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-08 11:30:46,232:INFO:Starting cross validation
2022-11-08 11:30:46,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:46,287:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,305:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,310:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,317:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,341:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,360:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,375:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,385:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,395:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,412:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-08 11:30:46,428:INFO:Calculating mean and std
2022-11-08 11:30:46,429:INFO:Creating metrics dataframe
2022-11-08 11:30:46,435:INFO:Uploading results into container
2022-11-08 11:30:46,435:INFO:Uploading model into container now
2022-11-08 11:30:46,436:INFO:master_model_container: 7
2022-11-08 11:30:46,436:INFO:display_container: 2
2022-11-08 11:30:46,436:INFO:OrthogonalMatchingPursuit()
2022-11-08 11:30:46,437:INFO:create_model() successfully completed......................................
2022-11-08 11:30:46,586:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:46,586:INFO:Creating metrics dataframe
2022-11-08 11:30:46,601:INFO:Initializing Bayesian Ridge
2022-11-08 11:30:46,602:INFO:Total runtime is 0.06556618611017863 minutes
2022-11-08 11:30:46,607:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:46,607:INFO:Initializing create_model()
2022-11-08 11:30:46,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:46,608:INFO:Checking exceptions
2022-11-08 11:30:46,610:INFO:Importing libraries
2022-11-08 11:30:46,610:INFO:Copying training dataset
2022-11-08 11:30:46,614:INFO:Defining folds
2022-11-08 11:30:46,614:INFO:Declaring metric variables
2022-11-08 11:30:46,619:INFO:Importing untrained model
2022-11-08 11:30:46,626:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:30:46,639:INFO:Starting cross validation
2022-11-08 11:30:46,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:46,846:INFO:Calculating mean and std
2022-11-08 11:30:46,850:INFO:Creating metrics dataframe
2022-11-08 11:30:46,855:INFO:Uploading results into container
2022-11-08 11:30:46,855:INFO:Uploading model into container now
2022-11-08 11:30:46,856:INFO:master_model_container: 8
2022-11-08 11:30:46,856:INFO:display_container: 2
2022-11-08 11:30:46,856:INFO:BayesianRidge()
2022-11-08 11:30:46,856:INFO:create_model() successfully completed......................................
2022-11-08 11:30:46,977:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:46,977:INFO:Creating metrics dataframe
2022-11-08 11:30:46,994:INFO:Initializing Passive Aggressive Regressor
2022-11-08 11:30:46,994:INFO:Total runtime is 0.07209986050923665 minutes
2022-11-08 11:30:47,000:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:47,001:INFO:Initializing create_model()
2022-11-08 11:30:47,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:47,001:INFO:Checking exceptions
2022-11-08 11:30:47,003:INFO:Importing libraries
2022-11-08 11:30:47,004:INFO:Copying training dataset
2022-11-08 11:30:47,007:INFO:Defining folds
2022-11-08 11:30:47,007:INFO:Declaring metric variables
2022-11-08 11:30:47,012:INFO:Importing untrained model
2022-11-08 11:30:47,020:INFO:Passive Aggressive Regressor Imported successfully
2022-11-08 11:30:47,036:INFO:Starting cross validation
2022-11-08 11:30:47,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:47,227:INFO:Calculating mean and std
2022-11-08 11:30:47,229:INFO:Creating metrics dataframe
2022-11-08 11:30:47,234:INFO:Uploading results into container
2022-11-08 11:30:47,234:INFO:Uploading model into container now
2022-11-08 11:30:47,235:INFO:master_model_container: 9
2022-11-08 11:30:47,235:INFO:display_container: 2
2022-11-08 11:30:47,235:INFO:PassiveAggressiveRegressor(random_state=204)
2022-11-08 11:30:47,235:INFO:create_model() successfully completed......................................
2022-11-08 11:30:47,357:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:47,357:INFO:Creating metrics dataframe
2022-11-08 11:30:47,377:INFO:Initializing Huber Regressor
2022-11-08 11:30:47,377:INFO:Total runtime is 0.07848465045293172 minutes
2022-11-08 11:30:47,384:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:47,385:INFO:Initializing create_model()
2022-11-08 11:30:47,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:47,385:INFO:Checking exceptions
2022-11-08 11:30:47,388:INFO:Importing libraries
2022-11-08 11:30:47,388:INFO:Copying training dataset
2022-11-08 11:30:47,393:INFO:Defining folds
2022-11-08 11:30:47,393:INFO:Declaring metric variables
2022-11-08 11:30:47,400:INFO:Importing untrained model
2022-11-08 11:30:47,408:INFO:Huber Regressor Imported successfully
2022-11-08 11:30:47,424:INFO:Starting cross validation
2022-11-08 11:30:47,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:47,550:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,558:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,575:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,585:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,655:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,667:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,694:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,704:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,755:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:47,767:INFO:Calculating mean and std
2022-11-08 11:30:47,769:INFO:Creating metrics dataframe
2022-11-08 11:30:47,773:INFO:Uploading results into container
2022-11-08 11:30:47,773:INFO:Uploading model into container now
2022-11-08 11:30:47,774:INFO:master_model_container: 10
2022-11-08 11:30:47,774:INFO:display_container: 2
2022-11-08 11:30:47,774:INFO:HuberRegressor()
2022-11-08 11:30:47,774:INFO:create_model() successfully completed......................................
2022-11-08 11:30:47,897:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:47,899:INFO:Creating metrics dataframe
2022-11-08 11:30:47,918:INFO:Initializing K Neighbors Regressor
2022-11-08 11:30:47,919:INFO:Total runtime is 0.08751900196075439 minutes
2022-11-08 11:30:47,924:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:47,924:INFO:Initializing create_model()
2022-11-08 11:30:47,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:47,925:INFO:Checking exceptions
2022-11-08 11:30:47,928:INFO:Importing libraries
2022-11-08 11:30:47,928:INFO:Copying training dataset
2022-11-08 11:30:47,934:INFO:Defining folds
2022-11-08 11:30:47,934:INFO:Declaring metric variables
2022-11-08 11:30:47,942:INFO:Importing untrained model
2022-11-08 11:30:47,949:INFO:K Neighbors Regressor Imported successfully
2022-11-08 11:30:47,965:INFO:Starting cross validation
2022-11-08 11:30:47,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:48,197:INFO:Calculating mean and std
2022-11-08 11:30:48,199:INFO:Creating metrics dataframe
2022-11-08 11:30:48,203:INFO:Uploading results into container
2022-11-08 11:30:48,203:INFO:Uploading model into container now
2022-11-08 11:30:48,204:INFO:master_model_container: 11
2022-11-08 11:30:48,204:INFO:display_container: 2
2022-11-08 11:30:48,204:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-08 11:30:48,204:INFO:create_model() successfully completed......................................
2022-11-08 11:30:48,325:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:48,325:INFO:Creating metrics dataframe
2022-11-08 11:30:48,344:INFO:Initializing Decision Tree Regressor
2022-11-08 11:30:48,344:INFO:Total runtime is 0.0946046233177185 minutes
2022-11-08 11:30:48,350:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:48,351:INFO:Initializing create_model()
2022-11-08 11:30:48,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:48,352:INFO:Checking exceptions
2022-11-08 11:30:48,355:INFO:Importing libraries
2022-11-08 11:30:48,355:INFO:Copying training dataset
2022-11-08 11:30:48,360:INFO:Defining folds
2022-11-08 11:30:48,360:INFO:Declaring metric variables
2022-11-08 11:30:48,367:INFO:Importing untrained model
2022-11-08 11:30:48,374:INFO:Decision Tree Regressor Imported successfully
2022-11-08 11:30:48,387:INFO:Starting cross validation
2022-11-08 11:30:48,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:48,592:INFO:Calculating mean and std
2022-11-08 11:30:48,593:INFO:Creating metrics dataframe
2022-11-08 11:30:48,599:INFO:Uploading results into container
2022-11-08 11:30:48,599:INFO:Uploading model into container now
2022-11-08 11:30:48,600:INFO:master_model_container: 12
2022-11-08 11:30:48,600:INFO:display_container: 2
2022-11-08 11:30:48,600:INFO:DecisionTreeRegressor(random_state=204)
2022-11-08 11:30:48,601:INFO:create_model() successfully completed......................................
2022-11-08 11:30:48,726:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:48,726:INFO:Creating metrics dataframe
2022-11-08 11:30:48,744:INFO:Initializing Random Forest Regressor
2022-11-08 11:30:48,745:INFO:Total runtime is 0.10127543210983277 minutes
2022-11-08 11:30:48,750:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:48,751:INFO:Initializing create_model()
2022-11-08 11:30:48,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:48,751:INFO:Checking exceptions
2022-11-08 11:30:48,754:INFO:Importing libraries
2022-11-08 11:30:48,754:INFO:Copying training dataset
2022-11-08 11:30:48,759:INFO:Defining folds
2022-11-08 11:30:48,759:INFO:Declaring metric variables
2022-11-08 11:30:48,769:INFO:Importing untrained model
2022-11-08 11:30:48,773:INFO:Random Forest Regressor Imported successfully
2022-11-08 11:30:48,791:INFO:Starting cross validation
2022-11-08 11:30:48,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:50,156:INFO:Calculating mean and std
2022-11-08 11:30:50,158:INFO:Creating metrics dataframe
2022-11-08 11:30:50,162:INFO:Uploading results into container
2022-11-08 11:30:50,163:INFO:Uploading model into container now
2022-11-08 11:30:50,164:INFO:master_model_container: 13
2022-11-08 11:30:50,164:INFO:display_container: 2
2022-11-08 11:30:50,164:INFO:RandomForestRegressor(n_jobs=-1, random_state=204)
2022-11-08 11:30:50,165:INFO:create_model() successfully completed......................................
2022-11-08 11:30:50,291:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:50,291:INFO:Creating metrics dataframe
2022-11-08 11:30:50,308:INFO:Initializing Extra Trees Regressor
2022-11-08 11:30:50,308:INFO:Total runtime is 0.1273256580034892 minutes
2022-11-08 11:30:50,314:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:50,314:INFO:Initializing create_model()
2022-11-08 11:30:50,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:50,315:INFO:Checking exceptions
2022-11-08 11:30:50,319:INFO:Importing libraries
2022-11-08 11:30:50,319:INFO:Copying training dataset
2022-11-08 11:30:50,323:INFO:Defining folds
2022-11-08 11:30:50,323:INFO:Declaring metric variables
2022-11-08 11:30:50,330:INFO:Importing untrained model
2022-11-08 11:30:50,337:INFO:Extra Trees Regressor Imported successfully
2022-11-08 11:30:50,353:INFO:Starting cross validation
2022-11-08 11:30:50,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:51,309:INFO:Calculating mean and std
2022-11-08 11:30:51,312:INFO:Creating metrics dataframe
2022-11-08 11:30:51,317:INFO:Uploading results into container
2022-11-08 11:30:51,318:INFO:Uploading model into container now
2022-11-08 11:30:51,319:INFO:master_model_container: 14
2022-11-08 11:30:51,319:INFO:display_container: 2
2022-11-08 11:30:51,319:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=204)
2022-11-08 11:30:51,319:INFO:create_model() successfully completed......................................
2022-11-08 11:30:51,441:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:51,442:INFO:Creating metrics dataframe
2022-11-08 11:30:51,461:INFO:Initializing AdaBoost Regressor
2022-11-08 11:30:51,461:INFO:Total runtime is 0.14655420382817588 minutes
2022-11-08 11:30:51,467:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:51,468:INFO:Initializing create_model()
2022-11-08 11:30:51,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:51,469:INFO:Checking exceptions
2022-11-08 11:30:51,471:INFO:Importing libraries
2022-11-08 11:30:51,471:INFO:Copying training dataset
2022-11-08 11:30:51,477:INFO:Defining folds
2022-11-08 11:30:51,477:INFO:Declaring metric variables
2022-11-08 11:30:51,482:INFO:Importing untrained model
2022-11-08 11:30:51,489:INFO:AdaBoost Regressor Imported successfully
2022-11-08 11:30:51,501:INFO:Starting cross validation
2022-11-08 11:30:51,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:52,026:INFO:Calculating mean and std
2022-11-08 11:30:52,029:INFO:Creating metrics dataframe
2022-11-08 11:30:52,032:INFO:Uploading results into container
2022-11-08 11:30:52,032:INFO:Uploading model into container now
2022-11-08 11:30:52,033:INFO:master_model_container: 15
2022-11-08 11:30:52,033:INFO:display_container: 2
2022-11-08 11:30:52,033:INFO:AdaBoostRegressor(random_state=204)
2022-11-08 11:30:52,033:INFO:create_model() successfully completed......................................
2022-11-08 11:30:52,153:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:52,153:INFO:Creating metrics dataframe
2022-11-08 11:30:52,175:INFO:Initializing Gradient Boosting Regressor
2022-11-08 11:30:52,175:INFO:Total runtime is 0.15844988425572715 minutes
2022-11-08 11:30:52,181:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:52,182:INFO:Initializing create_model()
2022-11-08 11:30:52,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:52,183:INFO:Checking exceptions
2022-11-08 11:30:52,186:INFO:Importing libraries
2022-11-08 11:30:52,186:INFO:Copying training dataset
2022-11-08 11:30:52,190:INFO:Defining folds
2022-11-08 11:30:52,190:INFO:Declaring metric variables
2022-11-08 11:30:52,197:INFO:Importing untrained model
2022-11-08 11:30:52,206:INFO:Gradient Boosting Regressor Imported successfully
2022-11-08 11:30:52,220:INFO:Starting cross validation
2022-11-08 11:30:52,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:52,795:INFO:Calculating mean and std
2022-11-08 11:30:52,797:INFO:Creating metrics dataframe
2022-11-08 11:30:52,801:INFO:Uploading results into container
2022-11-08 11:30:52,801:INFO:Uploading model into container now
2022-11-08 11:30:52,802:INFO:master_model_container: 16
2022-11-08 11:30:52,802:INFO:display_container: 2
2022-11-08 11:30:52,802:INFO:GradientBoostingRegressor(random_state=204)
2022-11-08 11:30:52,802:INFO:create_model() successfully completed......................................
2022-11-08 11:30:52,923:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:52,923:INFO:Creating metrics dataframe
2022-11-08 11:30:52,943:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:30:52,944:INFO:Total runtime is 0.17126728693644208 minutes
2022-11-08 11:30:52,948:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:52,949:INFO:Initializing create_model()
2022-11-08 11:30:52,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:52,950:INFO:Checking exceptions
2022-11-08 11:30:52,952:INFO:Importing libraries
2022-11-08 11:30:52,953:INFO:Copying training dataset
2022-11-08 11:30:52,958:INFO:Defining folds
2022-11-08 11:30:52,959:INFO:Declaring metric variables
2022-11-08 11:30:52,968:INFO:Importing untrained model
2022-11-08 11:30:52,977:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:30:52,992:INFO:Starting cross validation
2022-11-08 11:30:52,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:53,366:INFO:Calculating mean and std
2022-11-08 11:30:53,368:INFO:Creating metrics dataframe
2022-11-08 11:30:53,372:INFO:Uploading results into container
2022-11-08 11:30:53,373:INFO:Uploading model into container now
2022-11-08 11:30:53,373:INFO:master_model_container: 17
2022-11-08 11:30:53,374:INFO:display_container: 2
2022-11-08 11:30:53,374:INFO:LGBMRegressor(random_state=204)
2022-11-08 11:30:53,374:INFO:create_model() successfully completed......................................
2022-11-08 11:30:53,497:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:53,497:INFO:Creating metrics dataframe
2022-11-08 11:30:53,515:INFO:Initializing Dummy Regressor
2022-11-08 11:30:53,515:INFO:Total runtime is 0.1807864824930827 minutes
2022-11-08 11:30:53,520:INFO:SubProcess create_model() called ==================================
2022-11-08 11:30:53,521:INFO:Initializing create_model()
2022-11-08 11:30:53,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E46A86A0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:53,521:INFO:Checking exceptions
2022-11-08 11:30:53,524:INFO:Importing libraries
2022-11-08 11:30:53,524:INFO:Copying training dataset
2022-11-08 11:30:53,530:INFO:Defining folds
2022-11-08 11:30:53,530:INFO:Declaring metric variables
2022-11-08 11:30:53,535:INFO:Importing untrained model
2022-11-08 11:30:53,542:INFO:Dummy Regressor Imported successfully
2022-11-08 11:30:53,553:INFO:Starting cross validation
2022-11-08 11:30:53,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:53,738:INFO:Calculating mean and std
2022-11-08 11:30:53,739:INFO:Creating metrics dataframe
2022-11-08 11:30:53,744:INFO:Uploading results into container
2022-11-08 11:30:53,744:INFO:Uploading model into container now
2022-11-08 11:30:53,744:INFO:master_model_container: 18
2022-11-08 11:30:53,744:INFO:display_container: 2
2022-11-08 11:30:53,745:INFO:DummyRegressor()
2022-11-08 11:30:53,745:INFO:create_model() successfully completed......................................
2022-11-08 11:30:53,867:INFO:SubProcess create_model() end ==================================
2022-11-08 11:30:53,867:INFO:Creating metrics dataframe
2022-11-08 11:30:53,905:INFO:Initializing create_model()
2022-11-08 11:30:53,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=LassoLars(random_state=204), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:53,907:INFO:Checking exceptions
2022-11-08 11:30:53,950:INFO:Importing libraries
2022-11-08 11:30:53,950:INFO:Copying training dataset
2022-11-08 11:30:53,950:INFO:Defining folds
2022-11-08 11:30:53,950:INFO:Declaring metric variables
2022-11-08 11:30:53,950:INFO:Importing untrained model
2022-11-08 11:30:53,950:INFO:Declaring custom model
2022-11-08 11:30:53,955:INFO:Least Angle Regression Imported successfully
2022-11-08 11:30:53,955:INFO:Cross validation set to False
2022-11-08 11:30:53,955:INFO:Fitting Model
2022-11-08 11:30:54,056:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-08 11:30:54,057:INFO:LassoLars(random_state=204)
2022-11-08 11:30:54,057:INFO:create_model() successfully completed......................................
2022-11-08 11:30:54,190:INFO:Initializing create_model()
2022-11-08 11:30:54,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:54,190:INFO:Checking exceptions
2022-11-08 11:30:54,197:INFO:Importing libraries
2022-11-08 11:30:54,198:INFO:Copying training dataset
2022-11-08 11:30:54,198:INFO:Defining folds
2022-11-08 11:30:54,198:INFO:Declaring metric variables
2022-11-08 11:30:54,198:INFO:Importing untrained model
2022-11-08 11:30:54,198:INFO:Declaring custom model
2022-11-08 11:30:54,198:INFO:Dummy Regressor Imported successfully
2022-11-08 11:30:54,198:INFO:Cross validation set to False
2022-11-08 11:30:54,198:INFO:Fitting Model
2022-11-08 11:30:54,220:INFO:DummyRegressor()
2022-11-08 11:30:54,220:INFO:create_model() successfully completed......................................
2022-11-08 11:30:54,353:INFO:Initializing create_model()
2022-11-08 11:30:54,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:54,353:INFO:Checking exceptions
2022-11-08 11:30:54,359:INFO:Importing libraries
2022-11-08 11:30:54,360:INFO:Copying training dataset
2022-11-08 11:30:54,362:INFO:Defining folds
2022-11-08 11:30:54,362:INFO:Declaring metric variables
2022-11-08 11:30:54,362:INFO:Importing untrained model
2022-11-08 11:30:54,362:INFO:Declaring custom model
2022-11-08 11:30:54,365:INFO:Bayesian Ridge Imported successfully
2022-11-08 11:30:54,365:INFO:Cross validation set to False
2022-11-08 11:30:54,365:INFO:Fitting Model
2022-11-08 11:30:54,377:INFO:BayesianRidge()
2022-11-08 11:30:54,377:INFO:create_model() successfully completed......................................
2022-11-08 11:30:54,604:INFO:master_model_container: 18
2022-11-08 11:30:54,604:INFO:display_container: 2
2022-11-08 11:30:54,605:INFO:[LassoLars(random_state=204), DummyRegressor(), BayesianRidge()]
2022-11-08 11:30:54,606:INFO:compare_models() successfully completed......................................
2022-11-08 11:30:54,800:INFO:Initializing create_model()
2022-11-08 11:30:54,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:30:54,801:INFO:Checking exceptions
2022-11-08 11:30:54,864:INFO:Importing libraries
2022-11-08 11:30:54,865:INFO:Copying training dataset
2022-11-08 11:30:54,870:INFO:Defining folds
2022-11-08 11:30:54,871:INFO:Declaring metric variables
2022-11-08 11:30:54,875:INFO:Importing untrained model
2022-11-08 11:30:54,884:INFO:Huber Regressor Imported successfully
2022-11-08 11:30:54,897:INFO:Starting cross validation
2022-11-08 11:30:54,898:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:30:55,185:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,190:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,195:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,219:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,587:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,600:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,608:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:55,614:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,060:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,086:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,095:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,137:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,433:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,455:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,483:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,523:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,840:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,854:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:56,908:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:57,063:INFO:Calculating mean and std
2022-11-08 11:30:57,066:INFO:Creating metrics dataframe
2022-11-08 11:30:57,071:INFO:Finalizing model
2022-11-08 11:30:57,129:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:30:57,135:INFO:Uploading results into container
2022-11-08 11:30:57,136:INFO:Uploading model into container now
2022-11-08 11:30:57,157:INFO:master_model_container: 19
2022-11-08 11:30:57,157:INFO:display_container: 3
2022-11-08 11:30:57,158:INFO:HuberRegressor()
2022-11-08 11:30:57,158:INFO:create_model() successfully completed......................................
2022-11-08 11:30:57,413:INFO:Initializing plot_model()
2022-11-08 11:30:57,414:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:30:57,414:INFO:Checking exceptions
2022-11-08 11:30:57,418:INFO:Preloading libraries
2022-11-08 11:30:57,420:INFO:Copying training dataset
2022-11-08 11:30:57,420:INFO:Plot type: residuals
2022-11-08 11:30:57,519:INFO:Fitting Model
2022-11-08 11:30:57,519:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:30:57,579:INFO:Scoring test/hold-out set
2022-11-08 11:30:58,095:INFO:Visual Rendered Successfully
2022-11-08 11:30:58,249:INFO:plot_model() successfully completed......................................
2022-11-08 11:31:26,927:INFO:Initializing create_model()
2022-11-08 11:31:26,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, estimator=huber, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:31:26,927:INFO:Checking exceptions
2022-11-08 11:31:26,987:INFO:Importing libraries
2022-11-08 11:31:26,987:INFO:Copying training dataset
2022-11-08 11:31:26,997:INFO:Defining folds
2022-11-08 11:31:26,997:INFO:Declaring metric variables
2022-11-08 11:31:27,002:INFO:Importing untrained model
2022-11-08 11:31:27,008:INFO:Huber Regressor Imported successfully
2022-11-08 11:31:27,024:INFO:Starting cross validation
2022-11-08 11:31:27,026:INFO:Cross validating with KFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:31:27,221:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,223:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,247:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,275:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,463:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,474:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,493:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,619:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,771:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,797:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,873:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,905:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:27,986:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,016:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,098:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,137:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,193:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,261:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,277:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,300:INFO:Calculating mean and std
2022-11-08 11:31:28,301:INFO:Creating metrics dataframe
2022-11-08 11:31:28,309:INFO:Finalizing model
2022-11-08 11:31:28,369:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:31:28,376:INFO:Uploading results into container
2022-11-08 11:31:28,378:INFO:Uploading model into container now
2022-11-08 11:31:28,396:INFO:master_model_container: 20
2022-11-08 11:31:28,396:INFO:display_container: 4
2022-11-08 11:31:28,397:INFO:HuberRegressor()
2022-11-08 11:31:28,397:INFO:create_model() successfully completed......................................
2022-11-08 11:31:47,230:INFO:Initializing plot_model()
2022-11-08 11:31:47,230:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:31:47,230:INFO:Checking exceptions
2022-11-08 11:31:47,237:INFO:Preloading libraries
2022-11-08 11:31:47,237:INFO:Copying training dataset
2022-11-08 11:31:47,238:INFO:Plot type: residuals
2022-11-08 11:31:47,335:INFO:Fitting Model
2022-11-08 11:31:47,335:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:31:47,377:INFO:Scoring test/hold-out set
2022-11-08 11:31:48,341:INFO:Visual Rendered Successfully
2022-11-08 11:31:48,497:INFO:plot_model() successfully completed......................................
2022-11-08 11:31:54,928:INFO:Initializing plot_model()
2022-11-08 11:31:54,929:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:31:54,929:INFO:Checking exceptions
2022-11-08 11:31:54,936:INFO:Preloading libraries
2022-11-08 11:31:54,937:INFO:Copying training dataset
2022-11-08 11:31:54,937:INFO:Plot type: residuals
2022-11-08 11:31:55,046:INFO:Fitting Model
2022-11-08 11:31:55,046:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:31:55,087:INFO:Scoring test/hold-out set
2022-11-08 11:31:55,539:INFO:Visual Rendered Successfully
2022-11-08 11:31:55,688:INFO:plot_model() successfully completed......................................
2022-11-08 11:32:01,518:INFO:Initializing plot_model()
2022-11-08 11:32:01,518:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:32:01,518:INFO:Checking exceptions
2022-11-08 11:32:01,525:INFO:Preloading libraries
2022-11-08 11:32:01,525:INFO:Copying training dataset
2022-11-08 11:32:01,525:INFO:Plot type: residuals
2022-11-08 11:32:01,637:INFO:Fitting Model
2022-11-08 11:32:01,643:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:32:01,687:INFO:Scoring test/hold-out set
2022-11-08 11:32:02,137:INFO:Visual Rendered Successfully
2022-11-08 11:32:02,281:INFO:plot_model() successfully completed......................................
2022-11-08 11:33:40,757:INFO:Initializing plot_model()
2022-11-08 11:33:40,757:INFO:plot_model(plot=vc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:33:40,757:INFO:Checking exceptions
2022-11-08 11:33:40,760:INFO:Preloading libraries
2022-11-08 11:33:40,765:INFO:Copying training dataset
2022-11-08 11:33:40,765:INFO:Plot type: vc
2022-11-08 11:33:40,765:INFO:Determining param_name
2022-11-08 11:33:40,765:INFO:param_name: alpha
2022-11-08 11:33:40,872:INFO:Fitting Model
2022-11-08 11:33:41,090:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,099:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,117:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,153:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,236:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,257:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,270:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,270:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,379:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,399:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,399:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,399:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,520:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,545:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,552:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,565:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,651:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,666:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,671:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,681:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,785:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,826:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,826:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,831:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,925:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:41,950:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,006:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,007:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,040:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,097:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,115:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,133:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,155:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,170:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,185:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,200:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,216:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,241:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,256:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,266:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,276:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,306:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,318:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,328:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,349:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,370:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,378:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,397:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,415:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,436:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,448:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,458:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,478:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,498:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,511:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,518:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,538:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,569:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,569:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,580:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,599:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,630:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,638:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,650:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,665:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,698:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,705:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,729:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,761:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,771:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,785:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,795:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,827:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,840:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,852:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,852:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,886:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,901:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,913:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,921:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,964:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,972:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:42,985:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,012:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,045:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,073:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,090:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,095:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,107:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,136:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,150:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,154:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,167:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,205:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,215:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,218:WARNING:c:\Python3.10\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-08 11:33:43,397:INFO:Visual Rendered Successfully
2022-11-08 11:33:43,529:INFO:plot_model() successfully completed......................................
2022-11-08 11:34:24,000:INFO:Initializing plot_model()
2022-11-08 11:34:24,001:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C2E81591B0>, system=True)
2022-11-08 11:34:24,001:INFO:Checking exceptions
2022-11-08 11:34:24,009:INFO:Preloading libraries
2022-11-08 11:34:24,010:INFO:Copying training dataset
2022-11-08 11:34:24,010:INFO:Plot type: error
2022-11-08 11:34:24,080:INFO:Fitting Model
2022-11-08 11:34:24,080:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2022-11-08 11:34:24,080:INFO:Scoring test/hold-out set
2022-11-08 11:34:24,491:INFO:Visual Rendered Successfully
2022-11-08 11:34:24,638:INFO:plot_model() successfully completed......................................
2022-11-08 11:35:55,849:INFO:PyCaret ClassificationExperiment
2022-11-08 11:35:55,849:INFO:Logging name: clf-default-name
2022-11-08 11:35:55,851:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-11-08 11:35:55,851:INFO:version 3.0.0.rc4
2022-11-08 11:35:55,851:INFO:Initializing setup()
2022-11-08 11:35:55,851:INFO:self.USI: e41e
2022-11-08 11:35:55,851:INFO:self.variable_keys: {'display_container', 'y_train', 'logging_param', '_gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y', 'USI', 'idx', 'master_model_container', 'y_test', '_is_multiclass', '_all_models', '_ml_usecase', '_all_metrics', 'variable_keys', 'X', 'target_param', 'X_test', 'fix_imbalance', '_all_models_internal', 'n_jobs_param', 'html_param', 'data', 'memory', 'fold_generator', 'seed', 'exp_name_log', 'X_train', 'gpu_param', '_available_plots', 'pipeline', 'log_plots_param'}
2022-11-08 11:35:55,851:INFO:Checking environment
2022-11-08 11:35:55,851:INFO:python_version: 3.10.4
2022-11-08 11:35:55,851:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2022-11-08 11:35:55,851:INFO:machine: AMD64
2022-11-08 11:35:55,852:INFO:platform: Windows-10-10.0.19045-SP0
2022-11-08 11:35:55,852:INFO:Memory: svmem(total=8503136256, available=1455661056, percent=82.9, used=7047475200, free=1455661056)
2022-11-08 11:35:55,852:INFO:Physical Core: 2
2022-11-08 11:35:55,852:INFO:Logical Core: 4
2022-11-08 11:35:55,852:INFO:Checking libraries
2022-11-08 11:35:55,852:INFO:System:
2022-11-08 11:35:55,852:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2022-11-08 11:35:55,852:INFO:executable: c:\Python3.10\python.exe
2022-11-08 11:35:55,852:INFO:   machine: Windows-10-10.0.19045-SP0
2022-11-08 11:35:55,852:INFO:PyCaret required dependencies:
2022-11-08 11:35:55,852:INFO:                 pip: 22.2.2
2022-11-08 11:35:55,853:INFO:          setuptools: 58.1.0
2022-11-08 11:35:55,853:INFO:             pycaret: 3.0.0rc4
2022-11-08 11:35:55,853:INFO:             IPython: 8.4.0
2022-11-08 11:35:55,853:INFO:          ipywidgets: 8.0.2
2022-11-08 11:35:55,853:INFO:                tqdm: 4.64.0
2022-11-08 11:35:55,853:INFO:               numpy: 1.22.3
2022-11-08 11:35:55,853:INFO:              pandas: 1.4.2
2022-11-08 11:35:55,853:INFO:              jinja2: 3.1.2
2022-11-08 11:35:55,853:INFO:               scipy: 1.8.1
2022-11-08 11:35:55,853:INFO:              joblib: 1.2.0
2022-11-08 11:35:55,853:INFO:             sklearn: 1.1.2
2022-11-08 11:35:55,853:INFO:                pyod: 1.0.6
2022-11-08 11:35:55,853:INFO:            imblearn: 0.9.1
2022-11-08 11:35:55,853:INFO:   category_encoders: 2.5.1.post0
2022-11-08 11:35:55,853:INFO:            lightgbm: 3.3.3
2022-11-08 11:35:55,853:INFO:               numba: 0.55.2
2022-11-08 11:35:55,853:INFO:            requests: 2.28.1
2022-11-08 11:35:55,853:INFO:          matplotlib: 3.5.1
2022-11-08 11:35:55,854:INFO:          scikitplot: 0.3.7
2022-11-08 11:35:55,854:INFO:         yellowbrick: 1.5
2022-11-08 11:35:55,854:INFO:              plotly: 5.11.0
2022-11-08 11:35:55,854:INFO:             kaleido: 0.2.1
2022-11-08 11:35:55,854:INFO:         statsmodels: 0.13.5
2022-11-08 11:35:55,854:INFO:              sktime: 0.13.4
2022-11-08 11:35:55,854:INFO:               tbats: 1.1.1
2022-11-08 11:35:55,854:INFO:            pmdarima: 1.8.5
2022-11-08 11:35:55,854:INFO:              psutil: 5.9.1
2022-11-08 11:35:55,854:INFO:PyCaret optional dependencies:
2022-11-08 11:35:55,854:INFO:                shap: Not installed
2022-11-08 11:35:55,854:INFO:           interpret: Not installed
2022-11-08 11:35:55,854:INFO:                umap: Not installed
2022-11-08 11:35:55,854:INFO:    pandas_profiling: Not installed
2022-11-08 11:35:55,855:INFO:  explainerdashboard: Not installed
2022-11-08 11:35:55,855:INFO:             autoviz: Not installed
2022-11-08 11:35:55,855:INFO:           fairlearn: Not installed
2022-11-08 11:35:55,855:INFO:             xgboost: Not installed
2022-11-08 11:35:55,855:INFO:            catboost: Not installed
2022-11-08 11:35:55,855:INFO:              kmodes: Not installed
2022-11-08 11:35:55,855:INFO:             mlxtend: Not installed
2022-11-08 11:35:55,855:INFO:       statsforecast: Not installed
2022-11-08 11:35:55,856:INFO:        tune_sklearn: Not installed
2022-11-08 11:35:55,856:INFO:                 ray: Not installed
2022-11-08 11:35:55,856:INFO:            hyperopt: Not installed
2022-11-08 11:35:55,856:INFO:              optuna: Not installed
2022-11-08 11:35:55,856:INFO:               skopt: Not installed
2022-11-08 11:35:55,856:INFO:              mlflow: Not installed
2022-11-08 11:35:55,856:INFO:              gradio: Not installed
2022-11-08 11:35:55,856:INFO:             fastapi: Not installed
2022-11-08 11:35:55,856:INFO:             uvicorn: Not installed
2022-11-08 11:35:55,856:INFO:              m2cgen: Not installed
2022-11-08 11:35:55,857:INFO:           evidently: Not installed
2022-11-08 11:35:55,857:INFO:                nltk: 3.7
2022-11-08 11:35:55,857:INFO:            pyLDAvis: Not installed
2022-11-08 11:35:55,857:INFO:              gensim: Not installed
2022-11-08 11:35:55,857:INFO:               spacy: Not installed
2022-11-08 11:35:55,857:INFO:           wordcloud: Not installed
2022-11-08 11:35:55,857:INFO:            textblob: Not installed
2022-11-08 11:35:55,857:INFO:               fugue: Not installed
2022-11-08 11:35:55,857:INFO:           streamlit: Not installed
2022-11-08 11:35:55,857:INFO:             prophet: Not installed
2022-11-08 11:35:55,857:INFO:None
2022-11-08 11:35:55,857:INFO:Set up data.
2022-11-08 11:35:55,867:INFO:Set up train/test split.
2022-11-08 11:35:55,877:INFO:Set up index.
2022-11-08 11:35:55,877:INFO:Assigning column types.
2022-11-08 11:35:55,882:INFO:Set up folding strategy.
2022-11-08 11:35:55,884:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-08 11:35:55,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:35:55,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,179:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-08 11:35:56,412:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:56,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:56,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-11-08 11:35:57,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,005:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-11-08 11:35:57,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:57,616:INFO:Preparing preprocessing pipeline...
2022-11-08 11:35:57,620:INFO:Set up simple imputation.
2022-11-08 11:35:57,621:INFO:Set up variance threshold.
2022-11-08 11:35:57,698:INFO:Finished creating preprocessing pipeline.
2022-11-08 11:35:57,698:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-11-08 11:35:57,698:INFO:Creating final display dataframe.
2022-11-08 11:35:58,181:INFO:Setup display_container:                     Description             Value
0                    Session id              5092
1                        Target              area
2                   Target type            Binary
3           Original data shape          (517, 9)
4        Transformed data shape          (517, 9)
5   Transformed train set shape          (361, 9)
6    Transformed test set shape          (156, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation          constant
12       Low variance threshold                 0
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              e41e
2022-11-08 11:35:58,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-08 11:35:58,436:INFO:setup() successfully completed in 2.59s...............
2022-11-08 11:36:15,112:INFO:Initializing compare_models()
2022-11-08 11:36:15,113:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-11-08 11:36:15,113:INFO:Checking exceptions
2022-11-08 11:36:15,119:INFO:Preparing display monitor
2022-11-08 11:36:15,186:INFO:Initializing Logistic Regression
2022-11-08 11:36:15,186:INFO:Total runtime is 0.0 minutes
2022-11-08 11:36:15,191:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:15,192:INFO:Initializing create_model()
2022-11-08 11:36:15,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:15,193:INFO:Checking exceptions
2022-11-08 11:36:15,196:INFO:Importing libraries
2022-11-08 11:36:15,197:INFO:Copying training dataset
2022-11-08 11:36:15,203:INFO:Defining folds
2022-11-08 11:36:15,203:INFO:Declaring metric variables
2022-11-08 11:36:15,211:INFO:Importing untrained model
2022-11-08 11:36:15,218:INFO:Logistic Regression Imported successfully
2022-11-08 11:36:15,235:INFO:Starting cross validation
2022-11-08 11:36:15,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:17,190:INFO:Calculating mean and std
2022-11-08 11:36:17,197:INFO:Creating metrics dataframe
2022-11-08 11:36:17,199:INFO:Uploading results into container
2022-11-08 11:36:17,199:INFO:Uploading model into container now
2022-11-08 11:36:17,199:INFO:master_model_container: 1
2022-11-08 11:36:17,199:INFO:display_container: 2
2022-11-08 11:36:17,199:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5092, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-11-08 11:36:17,199:INFO:create_model() successfully completed......................................
2022-11-08 11:36:17,346:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:17,347:INFO:Creating metrics dataframe
2022-11-08 11:36:17,361:INFO:Initializing K Neighbors Classifier
2022-11-08 11:36:17,362:INFO:Total runtime is 0.03626526991526286 minutes
2022-11-08 11:36:17,367:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:17,367:INFO:Initializing create_model()
2022-11-08 11:36:17,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:17,368:INFO:Checking exceptions
2022-11-08 11:36:17,369:INFO:Importing libraries
2022-11-08 11:36:17,369:INFO:Copying training dataset
2022-11-08 11:36:17,380:INFO:Defining folds
2022-11-08 11:36:17,381:INFO:Declaring metric variables
2022-11-08 11:36:17,392:INFO:Importing untrained model
2022-11-08 11:36:17,401:INFO:K Neighbors Classifier Imported successfully
2022-11-08 11:36:17,429:INFO:Starting cross validation
2022-11-08 11:36:17,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:17,842:INFO:Calculating mean and std
2022-11-08 11:36:17,845:INFO:Creating metrics dataframe
2022-11-08 11:36:17,850:INFO:Uploading results into container
2022-11-08 11:36:17,850:INFO:Uploading model into container now
2022-11-08 11:36:17,851:INFO:master_model_container: 2
2022-11-08 11:36:17,851:INFO:display_container: 2
2022-11-08 11:36:17,851:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-11-08 11:36:17,851:INFO:create_model() successfully completed......................................
2022-11-08 11:36:17,985:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:17,985:INFO:Creating metrics dataframe
2022-11-08 11:36:18,001:INFO:Initializing Naive Bayes
2022-11-08 11:36:18,001:INFO:Total runtime is 0.046926466623942065 minutes
2022-11-08 11:36:18,006:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:18,008:INFO:Initializing create_model()
2022-11-08 11:36:18,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:18,010:INFO:Checking exceptions
2022-11-08 11:36:18,012:INFO:Importing libraries
2022-11-08 11:36:18,013:INFO:Copying training dataset
2022-11-08 11:36:18,018:INFO:Defining folds
2022-11-08 11:36:18,018:INFO:Declaring metric variables
2022-11-08 11:36:18,023:INFO:Importing untrained model
2022-11-08 11:36:18,032:INFO:Naive Bayes Imported successfully
2022-11-08 11:36:18,050:INFO:Starting cross validation
2022-11-08 11:36:18,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:18,302:INFO:Calculating mean and std
2022-11-08 11:36:18,304:INFO:Creating metrics dataframe
2022-11-08 11:36:18,313:INFO:Uploading results into container
2022-11-08 11:36:18,313:INFO:Uploading model into container now
2022-11-08 11:36:18,314:INFO:master_model_container: 3
2022-11-08 11:36:18,314:INFO:display_container: 2
2022-11-08 11:36:18,314:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-11-08 11:36:18,314:INFO:create_model() successfully completed......................................
2022-11-08 11:36:18,446:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:18,446:INFO:Creating metrics dataframe
2022-11-08 11:36:18,461:INFO:Initializing Decision Tree Classifier
2022-11-08 11:36:18,462:INFO:Total runtime is 0.05460441907246908 minutes
2022-11-08 11:36:18,468:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:18,469:INFO:Initializing create_model()
2022-11-08 11:36:18,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:18,469:INFO:Checking exceptions
2022-11-08 11:36:18,471:INFO:Importing libraries
2022-11-08 11:36:18,471:INFO:Copying training dataset
2022-11-08 11:36:18,480:INFO:Defining folds
2022-11-08 11:36:18,480:INFO:Declaring metric variables
2022-11-08 11:36:18,488:INFO:Importing untrained model
2022-11-08 11:36:18,499:INFO:Decision Tree Classifier Imported successfully
2022-11-08 11:36:18,517:INFO:Starting cross validation
2022-11-08 11:36:18,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:18,756:INFO:Calculating mean and std
2022-11-08 11:36:18,759:INFO:Creating metrics dataframe
2022-11-08 11:36:18,763:INFO:Uploading results into container
2022-11-08 11:36:18,764:INFO:Uploading model into container now
2022-11-08 11:36:18,765:INFO:master_model_container: 4
2022-11-08 11:36:18,765:INFO:display_container: 2
2022-11-08 11:36:18,766:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5092, splitter='best')
2022-11-08 11:36:18,767:INFO:create_model() successfully completed......................................
2022-11-08 11:36:18,887:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:18,887:INFO:Creating metrics dataframe
2022-11-08 11:36:18,903:INFO:Initializing SVM - Linear Kernel
2022-11-08 11:36:18,904:INFO:Total runtime is 0.06196676095326742 minutes
2022-11-08 11:36:18,909:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:18,910:INFO:Initializing create_model()
2022-11-08 11:36:18,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:18,910:INFO:Checking exceptions
2022-11-08 11:36:18,913:INFO:Importing libraries
2022-11-08 11:36:18,913:INFO:Copying training dataset
2022-11-08 11:36:18,917:INFO:Defining folds
2022-11-08 11:36:18,917:INFO:Declaring metric variables
2022-11-08 11:36:18,926:INFO:Importing untrained model
2022-11-08 11:36:18,934:INFO:SVM - Linear Kernel Imported successfully
2022-11-08 11:36:18,955:INFO:Starting cross validation
2022-11-08 11:36:18,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:19,096:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-11-08 11:36:19,153:INFO:Calculating mean and std
2022-11-08 11:36:19,154:INFO:Creating metrics dataframe
2022-11-08 11:36:19,156:INFO:Uploading results into container
2022-11-08 11:36:19,156:INFO:Uploading model into container now
2022-11-08 11:36:19,156:INFO:master_model_container: 5
2022-11-08 11:36:19,156:INFO:display_container: 2
2022-11-08 11:36:19,156:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5092, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-08 11:36:19,156:INFO:create_model() successfully completed......................................
2022-11-08 11:36:19,284:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:19,284:INFO:Creating metrics dataframe
2022-11-08 11:36:19,299:INFO:Initializing Ridge Classifier
2022-11-08 11:36:19,299:INFO:Total runtime is 0.06855111519495646 minutes
2022-11-08 11:36:19,305:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:19,306:INFO:Initializing create_model()
2022-11-08 11:36:19,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:19,306:INFO:Checking exceptions
2022-11-08 11:36:19,306:INFO:Importing libraries
2022-11-08 11:36:19,306:INFO:Copying training dataset
2022-11-08 11:36:19,314:INFO:Defining folds
2022-11-08 11:36:19,314:INFO:Declaring metric variables
2022-11-08 11:36:19,320:INFO:Importing untrained model
2022-11-08 11:36:19,329:INFO:Ridge Classifier Imported successfully
2022-11-08 11:36:19,343:INFO:Starting cross validation
2022-11-08 11:36:19,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:19,544:INFO:Calculating mean and std
2022-11-08 11:36:19,546:INFO:Creating metrics dataframe
2022-11-08 11:36:19,550:INFO:Uploading results into container
2022-11-08 11:36:19,550:INFO:Uploading model into container now
2022-11-08 11:36:19,551:INFO:master_model_container: 6
2022-11-08 11:36:19,551:INFO:display_container: 2
2022-11-08 11:36:19,551:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5092, solver='auto', tol=0.001)
2022-11-08 11:36:19,551:INFO:create_model() successfully completed......................................
2022-11-08 11:36:19,682:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:19,682:INFO:Creating metrics dataframe
2022-11-08 11:36:19,710:INFO:Initializing Random Forest Classifier
2022-11-08 11:36:19,710:INFO:Total runtime is 0.0754038135210673 minutes
2022-11-08 11:36:19,717:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:19,718:INFO:Initializing create_model()
2022-11-08 11:36:19,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:19,718:INFO:Checking exceptions
2022-11-08 11:36:19,719:INFO:Importing libraries
2022-11-08 11:36:19,719:INFO:Copying training dataset
2022-11-08 11:36:19,728:INFO:Defining folds
2022-11-08 11:36:19,729:INFO:Declaring metric variables
2022-11-08 11:36:19,737:INFO:Importing untrained model
2022-11-08 11:36:19,746:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:36:19,760:INFO:Starting cross validation
2022-11-08 11:36:19,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:21,147:INFO:Calculating mean and std
2022-11-08 11:36:21,148:INFO:Creating metrics dataframe
2022-11-08 11:36:21,152:INFO:Uploading results into container
2022-11-08 11:36:21,153:INFO:Uploading model into container now
2022-11-08 11:36:21,153:INFO:master_model_container: 7
2022-11-08 11:36:21,153:INFO:display_container: 2
2022-11-08 11:36:21,156:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:21,156:INFO:create_model() successfully completed......................................
2022-11-08 11:36:21,277:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:21,277:INFO:Creating metrics dataframe
2022-11-08 11:36:21,294:INFO:Initializing Quadratic Discriminant Analysis
2022-11-08 11:36:21,294:INFO:Total runtime is 0.10180829763412476 minutes
2022-11-08 11:36:21,300:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:21,301:INFO:Initializing create_model()
2022-11-08 11:36:21,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:21,301:INFO:Checking exceptions
2022-11-08 11:36:21,303:INFO:Importing libraries
2022-11-08 11:36:21,303:INFO:Copying training dataset
2022-11-08 11:36:21,309:INFO:Defining folds
2022-11-08 11:36:21,309:INFO:Declaring metric variables
2022-11-08 11:36:21,318:INFO:Importing untrained model
2022-11-08 11:36:21,325:INFO:Quadratic Discriminant Analysis Imported successfully
2022-11-08 11:36:21,341:INFO:Starting cross validation
2022-11-08 11:36:21,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:21,416:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-11-08 11:36:21,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,431:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:36:21,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:36:21,446:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:36:21,586:INFO:Calculating mean and std
2022-11-08 11:36:21,589:INFO:Creating metrics dataframe
2022-11-08 11:36:21,593:INFO:Uploading results into container
2022-11-08 11:36:21,593:INFO:Uploading model into container now
2022-11-08 11:36:21,594:INFO:master_model_container: 8
2022-11-08 11:36:21,594:INFO:display_container: 2
2022-11-08 11:36:21,594:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-11-08 11:36:21,595:INFO:create_model() successfully completed......................................
2022-11-08 11:36:21,716:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:21,716:INFO:Creating metrics dataframe
2022-11-08 11:36:21,735:INFO:Initializing Ada Boost Classifier
2022-11-08 11:36:21,735:INFO:Total runtime is 0.10916291475296021 minutes
2022-11-08 11:36:21,741:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:21,742:INFO:Initializing create_model()
2022-11-08 11:36:21,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:21,742:INFO:Checking exceptions
2022-11-08 11:36:21,745:INFO:Importing libraries
2022-11-08 11:36:21,746:INFO:Copying training dataset
2022-11-08 11:36:21,750:INFO:Defining folds
2022-11-08 11:36:21,750:INFO:Declaring metric variables
2022-11-08 11:36:21,756:INFO:Importing untrained model
2022-11-08 11:36:21,764:INFO:Ada Boost Classifier Imported successfully
2022-11-08 11:36:21,779:INFO:Starting cross validation
2022-11-08 11:36:21,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:22,458:INFO:Calculating mean and std
2022-11-08 11:36:22,460:INFO:Creating metrics dataframe
2022-11-08 11:36:22,464:INFO:Uploading results into container
2022-11-08 11:36:22,464:INFO:Uploading model into container now
2022-11-08 11:36:22,465:INFO:master_model_container: 9
2022-11-08 11:36:22,465:INFO:display_container: 2
2022-11-08 11:36:22,465:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092)
2022-11-08 11:36:22,465:INFO:create_model() successfully completed......................................
2022-11-08 11:36:22,588:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:22,588:INFO:Creating metrics dataframe
2022-11-08 11:36:22,608:INFO:Initializing Gradient Boosting Classifier
2022-11-08 11:36:22,608:INFO:Total runtime is 0.12370062271753947 minutes
2022-11-08 11:36:22,613:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:22,613:INFO:Initializing create_model()
2022-11-08 11:36:22,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:22,614:INFO:Checking exceptions
2022-11-08 11:36:22,617:INFO:Importing libraries
2022-11-08 11:36:22,617:INFO:Copying training dataset
2022-11-08 11:36:22,623:INFO:Defining folds
2022-11-08 11:36:22,623:INFO:Declaring metric variables
2022-11-08 11:36:22,626:INFO:Importing untrained model
2022-11-08 11:36:22,634:INFO:Gradient Boosting Classifier Imported successfully
2022-11-08 11:36:22,648:INFO:Starting cross validation
2022-11-08 11:36:22,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:23,413:INFO:Calculating mean and std
2022-11-08 11:36:23,415:INFO:Creating metrics dataframe
2022-11-08 11:36:23,421:INFO:Uploading results into container
2022-11-08 11:36:23,421:INFO:Uploading model into container now
2022-11-08 11:36:23,422:INFO:master_model_container: 10
2022-11-08 11:36:23,422:INFO:display_container: 2
2022-11-08 11:36:23,424:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5092, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-08 11:36:23,424:INFO:create_model() successfully completed......................................
2022-11-08 11:36:23,558:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:23,558:INFO:Creating metrics dataframe
2022-11-08 11:36:23,575:INFO:Initializing Linear Discriminant Analysis
2022-11-08 11:36:23,575:INFO:Total runtime is 0.1398259401321411 minutes
2022-11-08 11:36:23,579:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:23,580:INFO:Initializing create_model()
2022-11-08 11:36:23,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:23,582:INFO:Checking exceptions
2022-11-08 11:36:23,584:INFO:Importing libraries
2022-11-08 11:36:23,585:INFO:Copying training dataset
2022-11-08 11:36:23,590:INFO:Defining folds
2022-11-08 11:36:23,590:INFO:Declaring metric variables
2022-11-08 11:36:23,596:INFO:Importing untrained model
2022-11-08 11:36:23,604:INFO:Linear Discriminant Analysis Imported successfully
2022-11-08 11:36:23,620:INFO:Starting cross validation
2022-11-08 11:36:23,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:23,892:INFO:Calculating mean and std
2022-11-08 11:36:23,894:INFO:Creating metrics dataframe
2022-11-08 11:36:23,898:INFO:Uploading results into container
2022-11-08 11:36:23,898:INFO:Uploading model into container now
2022-11-08 11:36:23,899:INFO:master_model_container: 11
2022-11-08 11:36:23,899:INFO:display_container: 2
2022-11-08 11:36:23,899:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-11-08 11:36:23,899:INFO:create_model() successfully completed......................................
2022-11-08 11:36:24,025:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:24,025:INFO:Creating metrics dataframe
2022-11-08 11:36:24,044:INFO:Initializing Extra Trees Classifier
2022-11-08 11:36:24,045:INFO:Total runtime is 0.1476488471031189 minutes
2022-11-08 11:36:24,051:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:24,051:INFO:Initializing create_model()
2022-11-08 11:36:24,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:24,052:INFO:Checking exceptions
2022-11-08 11:36:24,054:INFO:Importing libraries
2022-11-08 11:36:24,054:INFO:Copying training dataset
2022-11-08 11:36:24,059:INFO:Defining folds
2022-11-08 11:36:24,059:INFO:Declaring metric variables
2022-11-08 11:36:24,064:INFO:Importing untrained model
2022-11-08 11:36:24,073:INFO:Extra Trees Classifier Imported successfully
2022-11-08 11:36:24,090:INFO:Starting cross validation
2022-11-08 11:36:24,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:25,414:INFO:Calculating mean and std
2022-11-08 11:36:25,417:INFO:Creating metrics dataframe
2022-11-08 11:36:25,422:INFO:Uploading results into container
2022-11-08 11:36:25,424:INFO:Uploading model into container now
2022-11-08 11:36:25,425:INFO:master_model_container: 12
2022-11-08 11:36:25,425:INFO:display_container: 2
2022-11-08 11:36:25,425:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:25,425:INFO:create_model() successfully completed......................................
2022-11-08 11:36:25,551:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:25,552:INFO:Creating metrics dataframe
2022-11-08 11:36:25,569:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:36:25,569:INFO:Total runtime is 0.17306079069773356 minutes
2022-11-08 11:36:25,575:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:25,576:INFO:Initializing create_model()
2022-11-08 11:36:25,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:25,577:INFO:Checking exceptions
2022-11-08 11:36:25,578:INFO:Importing libraries
2022-11-08 11:36:25,578:INFO:Copying training dataset
2022-11-08 11:36:25,585:INFO:Defining folds
2022-11-08 11:36:25,585:INFO:Declaring metric variables
2022-11-08 11:36:25,593:INFO:Importing untrained model
2022-11-08 11:36:25,601:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:36:25,615:INFO:Starting cross validation
2022-11-08 11:36:25,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:25,984:INFO:Calculating mean and std
2022-11-08 11:36:25,987:INFO:Creating metrics dataframe
2022-11-08 11:36:25,990:INFO:Uploading results into container
2022-11-08 11:36:25,990:INFO:Uploading model into container now
2022-11-08 11:36:25,991:INFO:master_model_container: 13
2022-11-08 11:36:25,991:INFO:display_container: 2
2022-11-08 11:36:25,991:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5092, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-08 11:36:25,991:INFO:create_model() successfully completed......................................
2022-11-08 11:36:26,114:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:26,114:INFO:Creating metrics dataframe
2022-11-08 11:36:26,134:INFO:Initializing Dummy Classifier
2022-11-08 11:36:26,135:INFO:Total runtime is 0.18249115943908692 minutes
2022-11-08 11:36:26,141:INFO:SubProcess create_model() called ==================================
2022-11-08 11:36:26,142:INFO:Initializing create_model()
2022-11-08 11:36:26,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314FA0>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:26,142:INFO:Checking exceptions
2022-11-08 11:36:26,144:INFO:Importing libraries
2022-11-08 11:36:26,145:INFO:Copying training dataset
2022-11-08 11:36:26,151:INFO:Defining folds
2022-11-08 11:36:26,152:INFO:Declaring metric variables
2022-11-08 11:36:26,159:INFO:Importing untrained model
2022-11-08 11:36:26,167:INFO:Dummy Classifier Imported successfully
2022-11-08 11:36:26,178:INFO:Starting cross validation
2022-11-08 11:36:26,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:36:26,421:INFO:Calculating mean and std
2022-11-08 11:36:26,423:INFO:Creating metrics dataframe
2022-11-08 11:36:26,427:INFO:Uploading results into container
2022-11-08 11:36:26,428:INFO:Uploading model into container now
2022-11-08 11:36:26,428:INFO:master_model_container: 14
2022-11-08 11:36:26,428:INFO:display_container: 2
2022-11-08 11:36:26,428:INFO:DummyClassifier(constant=None, random_state=5092, strategy='prior')
2022-11-08 11:36:26,428:INFO:create_model() successfully completed......................................
2022-11-08 11:36:26,551:INFO:SubProcess create_model() end ==================================
2022-11-08 11:36:26,552:INFO:Creating metrics dataframe
2022-11-08 11:36:26,590:INFO:Initializing create_model()
2022-11-08 11:36:26,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:36:26,590:INFO:Checking exceptions
2022-11-08 11:36:26,598:INFO:Importing libraries
2022-11-08 11:36:26,598:INFO:Copying training dataset
2022-11-08 11:36:26,601:INFO:Defining folds
2022-11-08 11:36:26,601:INFO:Declaring metric variables
2022-11-08 11:36:26,604:INFO:Importing untrained model
2022-11-08 11:36:26,604:INFO:Declaring custom model
2022-11-08 11:36:26,605:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:36:26,606:INFO:Cross validation set to False
2022-11-08 11:36:26,606:INFO:Fitting Model
2022-11-08 11:36:26,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:26,907:INFO:create_model() successfully completed......................................
2022-11-08 11:36:27,084:INFO:master_model_container: 14
2022-11-08 11:36:27,084:INFO:display_container: 2
2022-11-08 11:36:27,085:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:36:27,085:INFO:compare_models() successfully completed......................................
2022-11-08 11:37:01,164:INFO:Initializing create_model()
2022-11-08 11:37:01,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ada, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:37:01,166:INFO:Checking exceptions
2022-11-08 11:37:01,224:INFO:Importing libraries
2022-11-08 11:37:01,224:INFO:Copying training dataset
2022-11-08 11:37:01,230:INFO:Defining folds
2022-11-08 11:37:01,230:INFO:Declaring metric variables
2022-11-08 11:37:01,235:INFO:Importing untrained model
2022-11-08 11:37:01,248:INFO:Ada Boost Classifier Imported successfully
2022-11-08 11:37:01,264:INFO:Starting cross validation
2022-11-08 11:37:01,266:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:37:04,832:INFO:Calculating mean and std
2022-11-08 11:37:04,834:INFO:Creating metrics dataframe
2022-11-08 11:37:04,839:INFO:Finalizing model
2022-11-08 11:37:04,995:INFO:Uploading results into container
2022-11-08 11:37:04,997:INFO:Uploading model into container now
2022-11-08 11:37:05,020:INFO:master_model_container: 15
2022-11-08 11:37:05,020:INFO:display_container: 3
2022-11-08 11:37:05,022:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092)
2022-11-08 11:37:05,022:INFO:create_model() successfully completed......................................
2022-11-08 11:37:24,907:INFO:Initializing plot_model()
2022-11-08 11:37:24,907:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:37:24,907:INFO:Checking exceptions
2022-11-08 11:37:24,926:INFO:Preloading libraries
2022-11-08 11:37:24,936:INFO:Copying training dataset
2022-11-08 11:37:24,936:INFO:Plot type: auc
2022-11-08 11:37:24,997:INFO:Fitting Model
2022-11-08 11:37:24,997:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2022-11-08 11:37:24,997:INFO:Scoring test/hold-out set
2022-11-08 11:37:25,304:INFO:Visual Rendered Successfully
2022-11-08 11:37:25,516:INFO:plot_model() successfully completed......................................
2022-11-08 11:37:46,925:INFO:Initializing create_model()
2022-11-08 11:37:46,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:37:46,925:INFO:Checking exceptions
2022-11-08 11:37:46,979:INFO:Importing libraries
2022-11-08 11:37:46,979:INFO:Copying training dataset
2022-11-08 11:37:46,989:INFO:Defining folds
2022-11-08 11:37:46,989:INFO:Declaring metric variables
2022-11-08 11:37:46,994:INFO:Importing untrained model
2022-11-08 11:37:47,043:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:37:47,056:INFO:Starting cross validation
2022-11-08 11:37:47,056:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:37:50,276:INFO:Calculating mean and std
2022-11-08 11:37:50,280:INFO:Creating metrics dataframe
2022-11-08 11:37:50,289:INFO:Finalizing model
2022-11-08 11:37:50,502:INFO:Uploading results into container
2022-11-08 11:37:50,503:INFO:Uploading model into container now
2022-11-08 11:37:50,521:INFO:master_model_container: 16
2022-11-08 11:37:50,521:INFO:display_container: 4
2022-11-08 11:37:50,522:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:37:50,522:INFO:create_model() successfully completed......................................
2022-11-08 11:38:10,730:INFO:Initializing create_model()
2022-11-08 11:38:10,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=20, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:10,734:INFO:Checking exceptions
2022-11-08 11:38:10,794:INFO:Importing libraries
2022-11-08 11:38:10,794:INFO:Copying training dataset
2022-11-08 11:38:10,804:INFO:Defining folds
2022-11-08 11:38:10,804:INFO:Declaring metric variables
2022-11-08 11:38:10,811:INFO:Importing untrained model
2022-11-08 11:38:10,816:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:38:10,840:INFO:Starting cross validation
2022-11-08 11:38:10,840:INFO:Cross validating with StratifiedKFold(n_splits=20, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:14,135:INFO:Calculating mean and std
2022-11-08 11:38:14,137:INFO:Creating metrics dataframe
2022-11-08 11:38:14,143:INFO:Finalizing model
2022-11-08 11:38:14,386:INFO:Uploading results into container
2022-11-08 11:38:14,388:INFO:Uploading model into container now
2022-11-08 11:38:14,412:INFO:master_model_container: 17
2022-11-08 11:38:14,412:INFO:display_container: 5
2022-11-08 11:38:14,412:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:14,412:INFO:create_model() successfully completed......................................
2022-11-08 11:38:16,810:INFO:Initializing plot_model()
2022-11-08 11:38:16,810:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:38:16,814:INFO:Checking exceptions
2022-11-08 11:38:16,851:INFO:Preloading libraries
2022-11-08 11:38:16,870:INFO:Copying training dataset
2022-11-08 11:38:16,870:INFO:Plot type: auc
2022-11-08 11:38:16,956:INFO:Fitting Model
2022-11-08 11:38:16,956:WARNING:c:\Python3.10\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2022-11-08 11:38:16,956:INFO:Scoring test/hold-out set
2022-11-08 11:38:17,231:INFO:Visual Rendered Successfully
2022-11-08 11:38:17,400:INFO:plot_model() successfully completed......................................
2022-11-08 11:38:47,135:INFO:Initializing compare_models()
2022-11-08 11:38:47,135:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-11-08 11:38:47,136:INFO:Checking exceptions
2022-11-08 11:38:47,142:INFO:Preparing display monitor
2022-11-08 11:38:47,218:INFO:Initializing Logistic Regression
2022-11-08 11:38:47,218:INFO:Total runtime is 0.0 minutes
2022-11-08 11:38:47,228:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:47,228:INFO:Initializing create_model()
2022-11-08 11:38:47,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:47,229:INFO:Checking exceptions
2022-11-08 11:38:47,233:INFO:Importing libraries
2022-11-08 11:38:47,233:INFO:Copying training dataset
2022-11-08 11:38:47,237:INFO:Defining folds
2022-11-08 11:38:47,238:INFO:Declaring metric variables
2022-11-08 11:38:47,242:INFO:Importing untrained model
2022-11-08 11:38:47,251:INFO:Logistic Regression Imported successfully
2022-11-08 11:38:47,266:INFO:Starting cross validation
2022-11-08 11:38:47,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:47,637:INFO:Calculating mean and std
2022-11-08 11:38:47,637:INFO:Creating metrics dataframe
2022-11-08 11:38:47,638:INFO:Uploading results into container
2022-11-08 11:38:47,638:INFO:Uploading model into container now
2022-11-08 11:38:47,638:INFO:master_model_container: 18
2022-11-08 11:38:47,638:INFO:display_container: 6
2022-11-08 11:38:47,638:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5092, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-11-08 11:38:47,638:INFO:create_model() successfully completed......................................
2022-11-08 11:38:47,769:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:47,769:INFO:Creating metrics dataframe
2022-11-08 11:38:47,783:INFO:Initializing K Neighbors Classifier
2022-11-08 11:38:47,783:INFO:Total runtime is 0.009412264823913575 minutes
2022-11-08 11:38:47,788:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:47,789:INFO:Initializing create_model()
2022-11-08 11:38:47,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:47,789:INFO:Checking exceptions
2022-11-08 11:38:47,790:INFO:Importing libraries
2022-11-08 11:38:47,790:INFO:Copying training dataset
2022-11-08 11:38:47,795:INFO:Defining folds
2022-11-08 11:38:47,795:INFO:Declaring metric variables
2022-11-08 11:38:47,804:INFO:Importing untrained model
2022-11-08 11:38:47,812:INFO:K Neighbors Classifier Imported successfully
2022-11-08 11:38:47,825:INFO:Starting cross validation
2022-11-08 11:38:47,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:48,156:INFO:Calculating mean and std
2022-11-08 11:38:48,159:INFO:Creating metrics dataframe
2022-11-08 11:38:48,164:INFO:Uploading results into container
2022-11-08 11:38:48,165:INFO:Uploading model into container now
2022-11-08 11:38:48,165:INFO:master_model_container: 19
2022-11-08 11:38:48,165:INFO:display_container: 6
2022-11-08 11:38:48,165:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-11-08 11:38:48,165:INFO:create_model() successfully completed......................................
2022-11-08 11:38:48,307:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:48,308:INFO:Creating metrics dataframe
2022-11-08 11:38:48,328:INFO:Initializing Naive Bayes
2022-11-08 11:38:48,328:INFO:Total runtime is 0.018499350547790526 minutes
2022-11-08 11:38:48,337:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:48,337:INFO:Initializing create_model()
2022-11-08 11:38:48,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:48,339:INFO:Checking exceptions
2022-11-08 11:38:48,342:INFO:Importing libraries
2022-11-08 11:38:48,342:INFO:Copying training dataset
2022-11-08 11:38:48,350:INFO:Defining folds
2022-11-08 11:38:48,350:INFO:Declaring metric variables
2022-11-08 11:38:48,362:INFO:Importing untrained model
2022-11-08 11:38:48,372:INFO:Naive Bayes Imported successfully
2022-11-08 11:38:48,389:INFO:Starting cross validation
2022-11-08 11:38:48,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:48,620:INFO:Calculating mean and std
2022-11-08 11:38:48,622:INFO:Creating metrics dataframe
2022-11-08 11:38:48,627:INFO:Uploading results into container
2022-11-08 11:38:48,628:INFO:Uploading model into container now
2022-11-08 11:38:48,628:INFO:master_model_container: 20
2022-11-08 11:38:48,628:INFO:display_container: 6
2022-11-08 11:38:48,628:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-11-08 11:38:48,629:INFO:create_model() successfully completed......................................
2022-11-08 11:38:48,752:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:48,752:INFO:Creating metrics dataframe
2022-11-08 11:38:48,766:INFO:Initializing Decision Tree Classifier
2022-11-08 11:38:48,767:INFO:Total runtime is 0.02582291762034098 minutes
2022-11-08 11:38:48,773:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:48,774:INFO:Initializing create_model()
2022-11-08 11:38:48,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:48,774:INFO:Checking exceptions
2022-11-08 11:38:48,778:INFO:Importing libraries
2022-11-08 11:38:48,778:INFO:Copying training dataset
2022-11-08 11:38:48,782:INFO:Defining folds
2022-11-08 11:38:48,782:INFO:Declaring metric variables
2022-11-08 11:38:48,788:INFO:Importing untrained model
2022-11-08 11:38:48,796:INFO:Decision Tree Classifier Imported successfully
2022-11-08 11:38:48,815:INFO:Starting cross validation
2022-11-08 11:38:48,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:49,072:INFO:Calculating mean and std
2022-11-08 11:38:49,074:INFO:Creating metrics dataframe
2022-11-08 11:38:49,079:INFO:Uploading results into container
2022-11-08 11:38:49,079:INFO:Uploading model into container now
2022-11-08 11:38:49,080:INFO:master_model_container: 21
2022-11-08 11:38:49,080:INFO:display_container: 6
2022-11-08 11:38:49,080:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5092, splitter='best')
2022-11-08 11:38:49,080:INFO:create_model() successfully completed......................................
2022-11-08 11:38:49,203:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:49,204:INFO:Creating metrics dataframe
2022-11-08 11:38:49,221:INFO:Initializing SVM - Linear Kernel
2022-11-08 11:38:49,223:INFO:Total runtime is 0.033409122625986734 minutes
2022-11-08 11:38:49,230:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:49,230:INFO:Initializing create_model()
2022-11-08 11:38:49,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:49,230:INFO:Checking exceptions
2022-11-08 11:38:49,234:INFO:Importing libraries
2022-11-08 11:38:49,234:INFO:Copying training dataset
2022-11-08 11:38:49,239:INFO:Defining folds
2022-11-08 11:38:49,239:INFO:Declaring metric variables
2022-11-08 11:38:49,246:INFO:Importing untrained model
2022-11-08 11:38:49,255:INFO:SVM - Linear Kernel Imported successfully
2022-11-08 11:38:49,269:INFO:Starting cross validation
2022-11-08 11:38:49,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:49,414:WARNING:c:\Python3.10\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-11-08 11:38:49,467:INFO:Calculating mean and std
2022-11-08 11:38:49,468:INFO:Creating metrics dataframe
2022-11-08 11:38:49,472:INFO:Uploading results into container
2022-11-08 11:38:49,472:INFO:Uploading model into container now
2022-11-08 11:38:49,473:INFO:master_model_container: 22
2022-11-08 11:38:49,473:INFO:display_container: 6
2022-11-08 11:38:49,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5092, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-11-08 11:38:49,473:INFO:create_model() successfully completed......................................
2022-11-08 11:38:49,599:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:49,599:INFO:Creating metrics dataframe
2022-11-08 11:38:49,615:INFO:Initializing Ridge Classifier
2022-11-08 11:38:49,616:INFO:Total runtime is 0.0399705171585083 minutes
2022-11-08 11:38:49,622:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:49,623:INFO:Initializing create_model()
2022-11-08 11:38:49,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:49,623:INFO:Checking exceptions
2022-11-08 11:38:49,625:INFO:Importing libraries
2022-11-08 11:38:49,627:INFO:Copying training dataset
2022-11-08 11:38:49,634:INFO:Defining folds
2022-11-08 11:38:49,634:INFO:Declaring metric variables
2022-11-08 11:38:49,640:INFO:Importing untrained model
2022-11-08 11:38:49,650:INFO:Ridge Classifier Imported successfully
2022-11-08 11:38:49,664:INFO:Starting cross validation
2022-11-08 11:38:49,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:49,866:INFO:Calculating mean and std
2022-11-08 11:38:49,870:INFO:Creating metrics dataframe
2022-11-08 11:38:49,874:INFO:Uploading results into container
2022-11-08 11:38:49,875:INFO:Uploading model into container now
2022-11-08 11:38:49,876:INFO:master_model_container: 23
2022-11-08 11:38:49,876:INFO:display_container: 6
2022-11-08 11:38:49,876:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5092, solver='auto', tol=0.001)
2022-11-08 11:38:49,876:INFO:create_model() successfully completed......................................
2022-11-08 11:38:50,001:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:50,001:INFO:Creating metrics dataframe
2022-11-08 11:38:50,019:INFO:Initializing Random Forest Classifier
2022-11-08 11:38:50,019:INFO:Total runtime is 0.04668279488881429 minutes
2022-11-08 11:38:50,027:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:50,028:INFO:Initializing create_model()
2022-11-08 11:38:50,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:50,028:INFO:Checking exceptions
2022-11-08 11:38:50,031:INFO:Importing libraries
2022-11-08 11:38:50,031:INFO:Copying training dataset
2022-11-08 11:38:50,035:INFO:Defining folds
2022-11-08 11:38:50,035:INFO:Declaring metric variables
2022-11-08 11:38:50,042:INFO:Importing untrained model
2022-11-08 11:38:50,049:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:38:50,066:INFO:Starting cross validation
2022-11-08 11:38:50,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:51,365:INFO:Calculating mean and std
2022-11-08 11:38:51,367:INFO:Creating metrics dataframe
2022-11-08 11:38:51,372:INFO:Uploading results into container
2022-11-08 11:38:51,372:INFO:Uploading model into container now
2022-11-08 11:38:51,375:INFO:master_model_container: 24
2022-11-08 11:38:51,375:INFO:display_container: 6
2022-11-08 11:38:51,376:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:51,376:INFO:create_model() successfully completed......................................
2022-11-08 11:38:51,495:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:51,495:INFO:Creating metrics dataframe
2022-11-08 11:38:51,517:INFO:Initializing Quadratic Discriminant Analysis
2022-11-08 11:38:51,517:INFO:Total runtime is 0.07164777517318725 minutes
2022-11-08 11:38:51,522:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:51,523:INFO:Initializing create_model()
2022-11-08 11:38:51,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:51,524:INFO:Checking exceptions
2022-11-08 11:38:51,528:INFO:Importing libraries
2022-11-08 11:38:51,528:INFO:Copying training dataset
2022-11-08 11:38:51,532:INFO:Defining folds
2022-11-08 11:38:51,532:INFO:Declaring metric variables
2022-11-08 11:38:51,537:INFO:Importing untrained model
2022-11-08 11:38:51,548:INFO:Quadratic Discriminant Analysis Imported successfully
2022-11-08 11:38:51,564:INFO:Starting cross validation
2022-11-08 11:38:51,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:51,634:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-11-08 11:38:51,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,649:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:38:51,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:912: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2022-11-08 11:38:51,683:WARNING:c:\Python3.10\lib\site-packages\sklearn\discriminant_analysis.py:915: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2022-11-08 11:38:51,818:INFO:Calculating mean and std
2022-11-08 11:38:51,819:INFO:Creating metrics dataframe
2022-11-08 11:38:51,824:INFO:Uploading results into container
2022-11-08 11:38:51,825:INFO:Uploading model into container now
2022-11-08 11:38:51,826:INFO:master_model_container: 25
2022-11-08 11:38:51,826:INFO:display_container: 6
2022-11-08 11:38:51,826:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-11-08 11:38:51,827:INFO:create_model() successfully completed......................................
2022-11-08 11:38:51,951:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:51,951:INFO:Creating metrics dataframe
2022-11-08 11:38:51,968:INFO:Initializing Ada Boost Classifier
2022-11-08 11:38:51,969:INFO:Total runtime is 0.07918850580851236 minutes
2022-11-08 11:38:51,976:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:51,977:INFO:Initializing create_model()
2022-11-08 11:38:51,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:51,978:INFO:Checking exceptions
2022-11-08 11:38:51,980:INFO:Importing libraries
2022-11-08 11:38:51,980:INFO:Copying training dataset
2022-11-08 11:38:51,985:INFO:Defining folds
2022-11-08 11:38:51,985:INFO:Declaring metric variables
2022-11-08 11:38:51,992:INFO:Importing untrained model
2022-11-08 11:38:52,000:INFO:Ada Boost Classifier Imported successfully
2022-11-08 11:38:52,013:INFO:Starting cross validation
2022-11-08 11:38:52,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:52,680:INFO:Calculating mean and std
2022-11-08 11:38:52,681:INFO:Creating metrics dataframe
2022-11-08 11:38:52,685:INFO:Uploading results into container
2022-11-08 11:38:52,686:INFO:Uploading model into container now
2022-11-08 11:38:52,687:INFO:master_model_container: 26
2022-11-08 11:38:52,688:INFO:display_container: 6
2022-11-08 11:38:52,688:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5092)
2022-11-08 11:38:52,689:INFO:create_model() successfully completed......................................
2022-11-08 11:38:52,808:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:52,808:INFO:Creating metrics dataframe
2022-11-08 11:38:52,827:INFO:Initializing Gradient Boosting Classifier
2022-11-08 11:38:52,827:INFO:Total runtime is 0.09347862799962361 minutes
2022-11-08 11:38:52,832:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:52,832:INFO:Initializing create_model()
2022-11-08 11:38:52,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:52,833:INFO:Checking exceptions
2022-11-08 11:38:52,836:INFO:Importing libraries
2022-11-08 11:38:52,836:INFO:Copying training dataset
2022-11-08 11:38:52,842:INFO:Defining folds
2022-11-08 11:38:52,842:INFO:Declaring metric variables
2022-11-08 11:38:52,850:INFO:Importing untrained model
2022-11-08 11:38:52,857:INFO:Gradient Boosting Classifier Imported successfully
2022-11-08 11:38:52,878:INFO:Starting cross validation
2022-11-08 11:38:52,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:53,578:INFO:Calculating mean and std
2022-11-08 11:38:53,580:INFO:Creating metrics dataframe
2022-11-08 11:38:53,584:INFO:Uploading results into container
2022-11-08 11:38:53,584:INFO:Uploading model into container now
2022-11-08 11:38:53,585:INFO:master_model_container: 27
2022-11-08 11:38:53,585:INFO:display_container: 6
2022-11-08 11:38:53,586:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5092, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-11-08 11:38:53,586:INFO:create_model() successfully completed......................................
2022-11-08 11:38:53,711:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:53,711:INFO:Creating metrics dataframe
2022-11-08 11:38:53,728:INFO:Initializing Linear Discriminant Analysis
2022-11-08 11:38:53,728:INFO:Total runtime is 0.10849990049997965 minutes
2022-11-08 11:38:53,733:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:53,734:INFO:Initializing create_model()
2022-11-08 11:38:53,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:53,734:INFO:Checking exceptions
2022-11-08 11:38:53,739:INFO:Importing libraries
2022-11-08 11:38:53,739:INFO:Copying training dataset
2022-11-08 11:38:53,744:INFO:Defining folds
2022-11-08 11:38:53,744:INFO:Declaring metric variables
2022-11-08 11:38:53,752:INFO:Importing untrained model
2022-11-08 11:38:53,760:INFO:Linear Discriminant Analysis Imported successfully
2022-11-08 11:38:53,775:INFO:Starting cross validation
2022-11-08 11:38:53,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:54,034:INFO:Calculating mean and std
2022-11-08 11:38:54,036:INFO:Creating metrics dataframe
2022-11-08 11:38:54,040:INFO:Uploading results into container
2022-11-08 11:38:54,041:INFO:Uploading model into container now
2022-11-08 11:38:54,041:INFO:master_model_container: 28
2022-11-08 11:38:54,041:INFO:display_container: 6
2022-11-08 11:38:54,041:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-11-08 11:38:54,041:INFO:create_model() successfully completed......................................
2022-11-08 11:38:54,165:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:54,165:INFO:Creating metrics dataframe
2022-11-08 11:38:54,184:INFO:Initializing Extra Trees Classifier
2022-11-08 11:38:54,184:INFO:Total runtime is 0.11609896818796793 minutes
2022-11-08 11:38:54,190:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:54,191:INFO:Initializing create_model()
2022-11-08 11:38:54,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:54,191:INFO:Checking exceptions
2022-11-08 11:38:54,194:INFO:Importing libraries
2022-11-08 11:38:54,194:INFO:Copying training dataset
2022-11-08 11:38:54,198:INFO:Defining folds
2022-11-08 11:38:54,198:INFO:Declaring metric variables
2022-11-08 11:38:54,206:INFO:Importing untrained model
2022-11-08 11:38:54,213:INFO:Extra Trees Classifier Imported successfully
2022-11-08 11:38:54,225:INFO:Starting cross validation
2022-11-08 11:38:54,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:55,378:INFO:Calculating mean and std
2022-11-08 11:38:55,380:INFO:Creating metrics dataframe
2022-11-08 11:38:55,384:INFO:Uploading results into container
2022-11-08 11:38:55,384:INFO:Uploading model into container now
2022-11-08 11:38:55,385:INFO:master_model_container: 29
2022-11-08 11:38:55,385:INFO:display_container: 6
2022-11-08 11:38:55,386:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:55,387:INFO:create_model() successfully completed......................................
2022-11-08 11:38:55,510:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:55,510:INFO:Creating metrics dataframe
2022-11-08 11:38:55,528:INFO:Initializing Light Gradient Boosting Machine
2022-11-08 11:38:55,529:INFO:Total runtime is 0.13851706584294637 minutes
2022-11-08 11:38:55,533:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:55,534:INFO:Initializing create_model()
2022-11-08 11:38:55,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:55,534:INFO:Checking exceptions
2022-11-08 11:38:55,539:INFO:Importing libraries
2022-11-08 11:38:55,539:INFO:Copying training dataset
2022-11-08 11:38:55,543:INFO:Defining folds
2022-11-08 11:38:55,543:INFO:Declaring metric variables
2022-11-08 11:38:55,551:INFO:Importing untrained model
2022-11-08 11:38:55,557:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-08 11:38:55,574:INFO:Starting cross validation
2022-11-08 11:38:55,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:55,914:INFO:Calculating mean and std
2022-11-08 11:38:55,915:INFO:Creating metrics dataframe
2022-11-08 11:38:55,920:INFO:Uploading results into container
2022-11-08 11:38:55,921:INFO:Uploading model into container now
2022-11-08 11:38:55,921:INFO:master_model_container: 30
2022-11-08 11:38:55,921:INFO:display_container: 6
2022-11-08 11:38:55,922:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5092, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-11-08 11:38:55,922:INFO:create_model() successfully completed......................................
2022-11-08 11:38:56,044:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:56,045:INFO:Creating metrics dataframe
2022-11-08 11:38:56,063:INFO:Initializing Dummy Classifier
2022-11-08 11:38:56,063:INFO:Total runtime is 0.14742266337076823 minutes
2022-11-08 11:38:56,068:INFO:SubProcess create_model() called ==================================
2022-11-08 11:38:56,068:INFO:Initializing create_model()
2022-11-08 11:38:56,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E4314730>, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:56,068:INFO:Checking exceptions
2022-11-08 11:38:56,074:INFO:Importing libraries
2022-11-08 11:38:56,074:INFO:Copying training dataset
2022-11-08 11:38:56,078:INFO:Defining folds
2022-11-08 11:38:56,078:INFO:Declaring metric variables
2022-11-08 11:38:56,084:INFO:Importing untrained model
2022-11-08 11:38:56,093:INFO:Dummy Classifier Imported successfully
2022-11-08 11:38:56,104:INFO:Starting cross validation
2022-11-08 11:38:56,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:38:56,338:INFO:Calculating mean and std
2022-11-08 11:38:56,340:INFO:Creating metrics dataframe
2022-11-08 11:38:56,343:INFO:Uploading results into container
2022-11-08 11:38:56,344:INFO:Uploading model into container now
2022-11-08 11:38:56,344:INFO:master_model_container: 31
2022-11-08 11:38:56,344:INFO:display_container: 6
2022-11-08 11:38:56,344:INFO:DummyClassifier(constant=None, random_state=5092, strategy='prior')
2022-11-08 11:38:56,344:INFO:create_model() successfully completed......................................
2022-11-08 11:38:56,470:INFO:SubProcess create_model() end ==================================
2022-11-08 11:38:56,471:INFO:Creating metrics dataframe
2022-11-08 11:38:56,506:INFO:Initializing create_model()
2022-11-08 11:38:56,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:38:56,507:INFO:Checking exceptions
2022-11-08 11:38:56,512:INFO:Importing libraries
2022-11-08 11:38:56,513:INFO:Copying training dataset
2022-11-08 11:38:56,517:INFO:Defining folds
2022-11-08 11:38:56,517:INFO:Declaring metric variables
2022-11-08 11:38:56,518:INFO:Importing untrained model
2022-11-08 11:38:56,519:INFO:Declaring custom model
2022-11-08 11:38:56,520:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:38:56,520:INFO:Cross validation set to False
2022-11-08 11:38:56,520:INFO:Fitting Model
2022-11-08 11:38:56,747:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:56,747:INFO:create_model() successfully completed......................................
2022-11-08 11:38:56,920:INFO:master_model_container: 31
2022-11-08 11:38:56,920:INFO:display_container: 6
2022-11-08 11:38:56,921:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:38:56,921:INFO:compare_models() successfully completed......................................
2022-11-08 11:39:26,961:INFO:Initializing plot_model()
2022-11-08 11:39:26,961:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:39:26,962:INFO:Checking exceptions
2022-11-08 11:39:27,002:INFO:Preloading libraries
2022-11-08 11:39:27,028:INFO:Copying training dataset
2022-11-08 11:39:27,029:INFO:Plot type: learning
2022-11-08 11:39:27,092:INFO:Fitting Model
2022-11-08 11:39:40,196:INFO:Visual Rendered Successfully
2022-11-08 11:39:40,356:INFO:plot_model() successfully completed......................................
2022-11-08 11:40:20,936:INFO:Initializing tune_model()
2022-11-08 11:40:20,936:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>)
2022-11-08 11:40:20,936:INFO:Checking exceptions
2022-11-08 11:40:21,013:INFO:Copying training dataset
2022-11-08 11:40:21,018:INFO:Checking base model
2022-11-08 11:40:21,019:INFO:Base model : Random Forest Classifier
2022-11-08 11:40:21,027:INFO:Declaring metric variables
2022-11-08 11:40:21,035:INFO:Defining Hyperparameters
2022-11-08 11:40:21,205:INFO:Tuning with n_jobs=-1
2022-11-08 11:40:21,205:INFO:Initializing RandomizedSearchCV
2022-11-08 11:40:36,922:INFO:best_params: {'actual_estimator__n_estimators': 90, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2022-11-08 11:40:36,926:INFO:Hyperparameter search completed
2022-11-08 11:40:36,926:INFO:SubProcess create_model() called ==================================
2022-11-08 11:40:36,927:INFO:Initializing create_model()
2022-11-08 11:40:36,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C2E3F7CB50>, model_only=True, return_train_score=False, kwargs={'n_estimators': 90, 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.02, 'max_features': 'log2', 'max_depth': 9, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': True})
2022-11-08 11:40:36,928:INFO:Checking exceptions
2022-11-08 11:40:36,930:INFO:Importing libraries
2022-11-08 11:40:36,930:INFO:Copying training dataset
2022-11-08 11:40:36,937:INFO:Defining folds
2022-11-08 11:40:36,937:INFO:Declaring metric variables
2022-11-08 11:40:36,944:INFO:Importing untrained model
2022-11-08 11:40:36,945:INFO:Declaring custom model
2022-11-08 11:40:36,955:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:40:36,972:INFO:Starting cross validation
2022-11-08 11:40:36,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:40:38,181:INFO:Calculating mean and std
2022-11-08 11:40:38,185:INFO:Creating metrics dataframe
2022-11-08 11:40:38,198:INFO:Finalizing model
2022-11-08 11:40:38,469:INFO:Uploading results into container
2022-11-08 11:40:38,471:INFO:Uploading model into container now
2022-11-08 11:40:38,471:INFO:master_model_container: 32
2022-11-08 11:40:38,472:INFO:display_container: 7
2022-11-08 11:40:38,472:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=3,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=90, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:40:38,473:INFO:create_model() successfully completed......................................
2022-11-08 11:40:38,606:INFO:SubProcess create_model() end ==================================
2022-11-08 11:40:38,606:INFO:choose_better activated
2022-11-08 11:40:38,612:INFO:SubProcess create_model() called ==================================
2022-11-08 11:40:38,614:INFO:Initializing create_model()
2022-11-08 11:40:38,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-08 11:40:38,615:INFO:Checking exceptions
2022-11-08 11:40:38,620:INFO:Importing libraries
2022-11-08 11:40:38,620:INFO:Copying training dataset
2022-11-08 11:40:38,626:INFO:Defining folds
2022-11-08 11:40:38,626:INFO:Declaring metric variables
2022-11-08 11:40:38,626:INFO:Importing untrained model
2022-11-08 11:40:38,626:INFO:Declaring custom model
2022-11-08 11:40:38,626:INFO:Random Forest Classifier Imported successfully
2022-11-08 11:40:38,626:INFO:Starting cross validation
2022-11-08 11:40:38,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-08 11:40:39,930:INFO:Calculating mean and std
2022-11-08 11:40:39,931:INFO:Creating metrics dataframe
2022-11-08 11:40:39,934:INFO:Finalizing model
2022-11-08 11:40:40,450:INFO:Uploading results into container
2022-11-08 11:40:40,452:INFO:Uploading model into container now
2022-11-08 11:40:40,452:INFO:master_model_container: 33
2022-11-08 11:40:40,453:INFO:display_container: 8
2022-11-08 11:40:40,453:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:40:40,454:INFO:create_model() successfully completed......................................
2022-11-08 11:40:40,637:INFO:SubProcess create_model() end ==================================
2022-11-08 11:40:40,644:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False) result for Accuracy is 0.5404
2022-11-08 11:40:40,646:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=3,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=90, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False) result for Accuracy is 0.5318
2022-11-08 11:40:40,646:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False) is best model
2022-11-08 11:40:40,646:INFO:choose_better completed
2022-11-08 11:40:40,646:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2022-11-08 11:40:40,700:INFO:master_model_container: 33
2022-11-08 11:40:40,700:INFO:display_container: 7
2022-11-08 11:40:40,701:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False)
2022-11-08 11:40:40,701:INFO:tune_model() successfully completed......................................
2022-11-08 11:41:03,784:INFO:Initializing plot_model()
2022-11-08 11:41:03,784:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C2E070BFA0>, system=True)
2022-11-08 11:41:03,785:INFO:Checking exceptions
2022-11-08 11:41:03,818:INFO:Preloading libraries
2022-11-08 11:41:03,829:INFO:Copying training dataset
2022-11-08 11:41:03,829:INFO:Plot type: learning
2022-11-08 11:41:03,895:INFO:Fitting Model
2022-11-08 11:41:14,928:INFO:Visual Rendered Successfully
2022-11-08 11:41:15,086:INFO:plot_model() successfully completed......................................
2022-11-08 11:41:36,786:INFO:Initializing save_model()
2022-11-08 11:41:36,786:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5092, verbose=0, warm_start=False), model_name=forestfiremodel, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value='constant',
                                                              missing_values=nan,
                                                              strategy='constant',
                                                              verbose='deprecated'))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-11-08 11:41:36,786:INFO:Adding model into prep_pipe
2022-11-08 11:41:36,870:INFO:forestfiremodel.pkl saved in current working directory
2022-11-08 11:41:36,876:INFO:Pipeline(memory=Memory(location=C:\Users\Hp\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['FFMC', 'DMC', 'DC', 'ISI', 'temp',
                                             'RH', 'wind', 'rain'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Trans...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=5092,
                                        verbose=0, warm_start=False))],
         verbose=False)
2022-11-08 11:41:36,876:INFO:save_model() successfully completed......................................
